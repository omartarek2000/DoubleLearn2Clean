{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) To set up your own data cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the datasets\n",
    "def read_dataset(name): #when only one dataset is provided as input\n",
    "    import pandas as pd\n",
    "    if name == \"gpsa\":\n",
    "        df = pd.read_csv('../datasets/googleplaystore.csv', sep=',', encoding ='ISO-8859-1')\n",
    "    elif name == \"gpsu\":\n",
    "        df = pd.read_csv('../datasets/googleplaystore_reviews.csv', sep=',',encoding = 'ISO-8859-1')  \n",
    "    elif name == \"titanic\":\n",
    "        df = pd.read_csv('../datasets/titanic/titanic_train.csv', sep=',', encoding ='ISO-8859-1')\n",
    "    elif name == \"house\":\n",
    "        df = pd.read_csv('../datasets/house/house_train.csv', sep=',', encoding ='ISO-8859-1')\n",
    "    else: \n",
    "        raise ValueError('Invalid dataset name')               \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     App                                  Translated_Review  \\\n",
       "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "2  10 Best Foods for You                                                NaN   \n",
       "3  10 Best Foods for You         Works great especially going grocery store   \n",
       "4  10 Best Foods for You                                       Best idea us   \n",
       "\n",
       "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0  Positive                1.00                0.533333  \n",
       "1  Positive                0.25                0.288462  \n",
       "2       NaN                 NaN                     NaN  \n",
       "3  Positive                0.40                0.875000  \n",
       "4  Positive                1.00                0.300000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataset(\"gpsu\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Loading your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling datasets\n",
      "                Attribute     Type  Num. Missing Values  Num. Unique Values             Sknewness  Kurtosis\n",
      "0      Sentiment_Polarity  float64              26863.0              6196.0  -0.10457655084633158  0.646756\n",
      "1  Sentiment_Subjectivity  float64              26863.0              4531.0   -0.3063336025424886 -0.282853\n",
      "2                     App   object                  0.0              1074.0                   N/A       N/A\n",
      "3       Translated_Review   object              26868.0             27995.0                   N/A       N/A\n",
      "4               Sentiment   object              26863.0                 4.0                   N/A       N/A\n"
     ]
    }
   ],
   "source": [
    "import learn2clean.loading.reader as rd \n",
    "import learn2clean.normalization.normalizer as nl \n",
    "import pandas as pd\n",
    "\n",
    "# executing profiling function for one dataset as input\n",
    "rd.profile_summary(read_dataset('gpsu'), plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Positive\n",
       "1    Positive\n",
       "2         NaN\n",
       "3    Positive\n",
       "4    Positive\n",
       "Name: Sentiment, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "read_dataset('gpsu')['Sentiment'].head() # the target variable is numerical \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading csv : googleplaystore_reviews.csv ...\n",
      "Reading data ...\n",
      "CPU time: 4.710262060165405 seconds\n",
      "Profiling datasets\n",
      "                Attribute     Type  Num. Missing Values  Num. Unique Values             Sknewness  Kurtosis\n",
      "0      Sentiment_Polarity  float64              26863.0              6196.0  -0.10457655084633158  0.646756\n",
      "1  Sentiment_Subjectivity  float64              26863.0              4531.0   -0.3063336025424886 -0.282853\n",
      "2                     App   object                  0.0              1074.0                   N/A       N/A\n",
      "3       Translated_Review   object              26868.0             27995.0                   N/A       N/A\n",
      "4               Sentiment   object              26863.0                 4.0                   N/A       N/A\n",
      "\n",
      "> Number of categorical features in the training set: 3\n",
      "> Number of numerical features in the training set: 2\n",
      "> Number of data samples : 64295\n",
      "\n",
      "> Top sparse features (% missing values on dataset set):\n",
      "Translated_Review         41.7\n",
      "Sentiment_Subjectivity    41.7\n",
      "Sentiment_Polarity        41.7\n",
      "Sentiment                 41.7\n",
      "dtype: float64\n",
      "\n",
      "> Task : classification\n",
      "Positive    16125\n",
      "Negative     5501\n",
      "Neutral      3478\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Encoding target...\n",
      "Encoding target done...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>Angry Birds 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>BIG Launcher</td>\n",
       "      <td>Great Great I cannot delete recent calls even paid version.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62550</th>\n",
       "      <td>Hola Launcher- Theme,Wallpaper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42242</th>\n",
       "      <td>FOX</td>\n",
       "      <td>From bad to worse, after the last update I can already stream, start for 5 seconds then turn off...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.275000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22985</th>\n",
       "      <td>Camera360: Selfie Photo Editor with Funny Sticker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     App  \\\n",
       "7334                                       Angry Birds 2   \n",
       "10900                                       BIG Launcher   \n",
       "62550                     Hola Launcher- Theme,Wallpaper   \n",
       "42242                                                FOX   \n",
       "22985  Camera360: Selfie Photo Editor with Funny Sticker   \n",
       "\n",
       "                                                                                         Translated_Review  \\\n",
       "7334                                                                                                   NaN   \n",
       "10900                                          Great Great I cannot delete recent calls even paid version.   \n",
       "62550                                                                                                  NaN   \n",
       "42242  From bad to worse, after the last update I can already stream, start for 5 seconds then turn off...   \n",
       "22985                                                                                                  NaN   \n",
       "\n",
       "       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "7334           3                 NaN                     NaN  \n",
       "10900          2            0.533333                0.583333  \n",
       "62550          3                 NaN                     NaN  \n",
       "42242          0           -0.275000                0.583333  \n",
       "22985          3                 NaN                     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding of the target variable\n",
    "import learn2clean.loading.reader as rd \n",
    "d_enc = rd.Reader(sep=',',verbose=True, encoding=True) \n",
    "\n",
    "gpsu  = [\"../datasets/googleplaystore_reviews.csv\"]\n",
    "gpsu_encoded = d_enc.train_test_split(gpsu, 'Sentiment')\n",
    "gpsu_encoded['train'].head()\n",
    "gpsu_encoded['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Normalize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.07133197784423828 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking food myself, case \"10 Best Foods\" helps lot, also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Looking forward app,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
       "0          2               1.000                0.533333   \n",
       "1          2               0.625                0.288462   \n",
       "4          2               1.000                0.300000   \n",
       "6          2               0.800                0.900000   \n",
       "8          1               0.500                0.000000   \n",
       "\n",
       "                     App  \\\n",
       "0  10 Best Foods for You   \n",
       "1  10 Best Foods for You   \n",
       "4  10 Best Foods for You   \n",
       "6  10 Best Foods for You   \n",
       "8  10 Best Foods for You   \n",
       "\n",
       "                                                                                     Translated_Review  \n",
       "0  I like eat delicious food. That's I'm cooking food myself, case \"10 Best Foods\" helps lot, also ...  \n",
       "1                                                      This help eating healthy exercise regular basis  \n",
       "4                                                                                         Best idea us  \n",
       "6                                                                                              Amazing  \n",
       "8                                                                                 Looking forward app,  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >> Examples of normalization\n",
    "# The choice for the normalizer : 'ZS', 'MM','DS' or 'Log10'\n",
    "#    Available strategies=\n",
    "#       - 'ZS' z-score normalization\n",
    "#       - 'MM' MinMax scaling\n",
    "#       - 'DS' decimal scaling\n",
    "#       - 'Log10 log10 scaling\n",
    "\n",
    "import learn2clean.normalization.normalizer as nl \n",
    "\n",
    "# MM normalization with exclude = None, all numeric variables will be normalized\n",
    "n1= nl.Normalizer(gpsu_encoded.copy(),strategy='MM',exclude='Sentiment')\n",
    "\n",
    "n1.transform()['train'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.05700802803039551 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.06347107887268066 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking food myself, case \"10 Best Foods\" helps lot, also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.603865</td>\n",
       "      <td>0.209730</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Looking forward app,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
       "0          2            1.000000                0.518519   \n",
       "1          2            0.603865                0.209730   \n",
       "4          2            1.000000                0.213675   \n",
       "6          2            0.888889                0.946667   \n",
       "8          1            0.277778                0.000000   \n",
       "\n",
       "                     App  \\\n",
       "0  10 Best Foods for You   \n",
       "1  10 Best Foods for You   \n",
       "4  10 Best Foods for You   \n",
       "6  10 Best Foods for You   \n",
       "8  10 Best Foods for You   \n",
       "\n",
       "                                                                                     Translated_Review  \n",
       "0  I like eat delicious food. That's I'm cooking food myself, case \"10 Best Foods\" helps lot, also ...  \n",
       "1                                                      This help eating healthy exercise regular basis  \n",
       "4                                                                                         Best idea us  \n",
       "6                                                                                              Amazing  \n",
       "8                                                                                 Looking forward app,  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#ZS normalization\n",
    "n1= nl.Normalizer(gpsu_encoded.copy(),strategy='ZS',exclude='Sentiment', verbose = False)\n",
    "n1.transform()['train'].head()\n",
    "\n",
    "#DS scaling\n",
    "n2= nl.Normalizer(gpsu_encoded.copy(),strategy='DS',exclude='Sentiment', verbose = False)\n",
    "n2.transform()['train'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Imputation \n",
      "* For train dataset\n",
      "Before imputation:\n",
      "Total 53923 missing values in ['Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 35946 numerical missing values in ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 17977 non-numerical missing values in ['Translated_Review']\n",
      "Most frequent value for  App is: Angry Birds Classic\n",
      "Most frequent value for  Translated_Review is: Good\n",
      "Most frequent value for  Sentiment is: 3\n",
      "Most frequent value for  Sentiment_Polarity is: 0.0\n",
      "Most frequent value for  Sentiment_Subjectivity is: 0.0\n",
      "After imputation:\n",
      "Total 0 missing values\n",
      "- 0 numerical missing values\n",
      "- 0 non-numerical missing values\n",
      "* For test dataset\n",
      "Before imputation:\n",
      "Total 26671 missing values in ['Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 17780 numerical missing values in ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 8891 non-numerical missing values in ['Translated_Review']\n",
      "Most frequent value for  App is: Bowmasters\n",
      "Most frequent value for  Translated_Review is: Good\n",
      "Most frequent value for  Sentiment is: 3\n",
      "Most frequent value for  Sentiment_Polarity is: 0.0\n",
      "Most frequent value for  Sentiment_Subjectivity is: 0.0\n",
      "After imputation:\n",
      "Total 0 missing values\n",
      "- 0 numerical missing values\n",
      "- 0 non-numerical missing values\n",
      "Imputation done -- CPU time: 0.16412019729614258 seconds\n",
      "\n",
      ">>Imputation \n",
      "* For train dataset\n",
      "Before imputation:\n",
      "Total 53923 missing values in ['Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 35946 numerical missing values in ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 17977 non-numerical missing values in ['Translated_Review']\n",
      "After imputation:\n",
      "Total 40619 missing values\n",
      "- 0 numerical missing values\n",
      "- 40619 non-numerical missing values\n",
      "* For test dataset\n",
      "Before imputation:\n",
      "Total 26671 missing values in ['Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 17780 numerical missing values in ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 8891 non-numerical missing values in ['Translated_Review']\n",
      "After imputation:\n",
      "Total 31193 missing values\n",
      "- 0 numerical missing values\n",
      "- 31193 non-numerical missing values\n",
      "Imputation done -- CPU time: 0.10115599632263184 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27559</th>\n",
       "      <td>Clover Dating App</td>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60204</th>\n",
       "      <td>Harry Potter: Hogwarts Mystery</td>\n",
       "      <td>I'm enjoying gameplay, story &amp; mechanics. The latest updates introduced fun ways earn in-game co...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15160</th>\n",
       "      <td>Black Wallpaper, AMOLED, Dark Background: Darkify</td>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19450</th>\n",
       "      <td>CBS News</td>\n",
       "      <td>Good</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54880</th>\n",
       "      <td>Google Ads</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     App  \\\n",
       "27559                                  Clover Dating App   \n",
       "60204                     Harry Potter: Hogwarts Mystery   \n",
       "15160  Black Wallpaper, AMOLED, Dark Background: Darkify   \n",
       "19450                                           CBS News   \n",
       "54880                                         Google Ads   \n",
       "\n",
       "                                                                                         Translated_Review  \\\n",
       "27559                                                                                                 Good   \n",
       "60204  I'm enjoying gameplay, story & mechanics. The latest updates introduced fun ways earn in-game co...   \n",
       "15160                                                                                                 Good   \n",
       "19450                                                                                                 Good   \n",
       "54880                                                                                               Thanks   \n",
       "\n",
       "       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "27559          3                 0.0                     0.0  \n",
       "60204          2                 0.1                     0.5  \n",
       "15160          3                 0.0                     0.0  \n",
       "19450          3                 0.0                     0.0  \n",
       "54880          2                 0.2                     0.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#>> Examples for missing value imputation\n",
    "# Available strategies:\n",
    "#            - 'EM': only for numerical variables; imputation based on\n",
    "#                expectation maximization\n",
    "#            - 'MICE': only for numerical variables  missing at random (MAR);\n",
    "#                Multivariate Imputation by Chained Equations\n",
    "#            - 'KNN', only for numerical variables; k-nearest neighbor\n",
    "#                imputation (k=4) which weights samples using the mean squared\n",
    "#                difference on features for which two rows both have observed\n",
    "#                data\n",
    "#            - 'RAND', 'MF': both for numerical and categorical variables;\n",
    "#                replace missing values by randomly selected value in the \n",
    "#                variable domain or by the most frequent value in the variable\n",
    "#                domain respectively\n",
    "#            - 'MEAN', 'MEDIAN': only for numerical variables; replace missing\n",
    "#                values by mean or median of the numerical variable respectvely\n",
    "#            - or 'DROP' remove the row with at least one missing value\n",
    "\n",
    "import learn2clean.imputation.imputer as imp\n",
    "\n",
    "# replace missing values by the most frequent ones in the training and testing datasets\n",
    "\n",
    "imp1 = imp.Imputer(gpsu_encoded.copy(),strategy='MF', verbose=True).transform()\n",
    "\n",
    "imp2 = imp.Imputer(gpsu_encoded.copy(),strategy='MEDIAN', verbose=True).transform()\n",
    "imp1['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Detect outliers and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed:\n",
      "* For test dataset\n",
      "0 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.06672310829162598 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "43077 outlying rows have been removed\n",
      "* For test dataset\n",
      "21218 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.06291770935058594 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "LOF requires no missing values, so missing values have been removed using DROP.\n",
      "40 outlying rows have been removed\n",
      "* For test dataset\n",
      "LOF requires no missing values, so missing values have been removed using DROP.\n",
      "40 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.49387598037719727 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60204</th>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Harry Potter: Hogwarts Mystery</td>\n",
       "      <td>I'm enjoying gameplay, story &amp; mechanics. The latest updates introduced fun ways earn in-game co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54880</th>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Google Ads</td>\n",
       "      <td>Thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>All Events in City</td>\n",
       "      <td>Great app...90% accurate information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53098</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.108333</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>Gboard - the Google Keyboard</td>\n",
       "      <td>It's got zillions emojis gifs national keyboards, shame. Long press slide unusable words. Not su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17076</th>\n",
       "      <td>2</td>\n",
       "      <td>0.044792</td>\n",
       "      <td>0.398958</td>\n",
       "      <td>Bowmasters</td>\n",
       "      <td>Cool game! And really fun play. Edit: hey Miniclip, game fun But problem. The game lagging On de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
       "60204          2            0.100000                0.500000   \n",
       "54880          2            0.200000                0.200000   \n",
       "5540           2            0.600000                0.691667   \n",
       "53098          0           -0.108333                0.383333   \n",
       "17076          2            0.044792                0.398958   \n",
       "\n",
       "                                  App  \\\n",
       "60204  Harry Potter: Hogwarts Mystery   \n",
       "54880                      Google Ads   \n",
       "5540               All Events in City   \n",
       "53098    Gboard - the Google Keyboard   \n",
       "17076                      Bowmasters   \n",
       "\n",
       "                                                                                         Translated_Review  \n",
       "60204  I'm enjoying gameplay, story & mechanics. The latest updates introduced fun ways earn in-game co...  \n",
       "54880                                                                                               Thanks  \n",
       "5540                                                                  Great app...90% accurate information  \n",
       "53098  It's got zillions emojis gifs national keyboards, shame. Long press slide unusable words. Not su...  \n",
       "17076  Cool game! And really fun play. Edit: hey Miniclip, game fun But problem. The game lagging On de...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >> Examples for outlier detection and removal\n",
    "# Available strategies =\n",
    "#            'ZS': detects outliers using the robust Zscore as a function\n",
    "#            of median and median absolute deviation (MAD)\n",
    "#            'IQR': detects outliers using Q1 and Q3 +/- 1.5*InterQuartile Range\n",
    "#            'LOF': detects outliers using Local Outlier Factor\n",
    "\n",
    "                \n",
    "import learn2clean.outlier_detection.outlier_detector as out\n",
    "\n",
    "#to remove rows having 30% and more ZSB-based outling values among the numerical variables\n",
    "out1=out.Outlier_detector(gpsu_encoded.copy(), strategy='ZSB', threshold = 0.3, verbose=True)\n",
    "out1.transform()\n",
    "\n",
    "#to remove rows having at least one IQR-based outlying value using threshold '-1'\n",
    "out2=out.Outlier_detector(gpsu_encoded.copy(), strategy='IQR', threshold = -1, verbose=False)\n",
    "out2.transform()\n",
    "\n",
    "#to remove rows having 40% and more ZSB-based outling values among the numerical variables; \n",
    "# since LOF requires non missing values, rows with NaN are also removed\n",
    "out3=out.Outlier_detector(gpsu_encoded.copy(), strategy='LOF', threshold = .4, verbose=False)\n",
    "out3.transform()['train'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Detect duplicates and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 43077\n",
      "After deduplication: Number of rows: 22119\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 21218\n",
      "After deduplication: Number of rows: 12215\n",
      "Deduplication done -- CPU time: 0.0423281192779541 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 14\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 3\n",
      "Deduplication done -- CPU time: 1.89493989944458 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27559</th>\n",
       "      <td>Clover Dating App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60204</th>\n",
       "      <td>Harry Potter: Hogwarts Mystery</td>\n",
       "      <td>I'm enjoying gameplay, story &amp; mechanics. The latest updates introduced fun ways earn in-game co...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15160</th>\n",
       "      <td>Black Wallpaper, AMOLED, Dark Background: Darkify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19450</th>\n",
       "      <td>CBS News</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54880</th>\n",
       "      <td>Google Ads</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46861</th>\n",
       "      <td>Flickr</td>\n",
       "      <td>This awful It wants auto upload photos. I find way upload image pc Mac.</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33416</th>\n",
       "      <td>Davis's Drug Guide</td>\n",
       "      <td>Terrible customer Unbound Medicine (developer) Google issues app. I'd give 0 stars I could.</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50777</th>\n",
       "      <td>Funny Alarm Clock Ringtones</td>\n",
       "      <td>Pretty cool ringtones. Even makes u laugh times.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29367</th>\n",
       "      <td>Cookpad</td>\n",
       "      <td>Make cooking easier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>Aprender inglÃ©s con Wlingua</td>\n",
       "      <td>It works as if it were a game ... Very easy to use ... And brings good results.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     App  \\\n",
       "27559                                  Clover Dating App   \n",
       "60204                     Harry Potter: Hogwarts Mystery   \n",
       "15160  Black Wallpaper, AMOLED, Dark Background: Darkify   \n",
       "19450                                           CBS News   \n",
       "54880                                         Google Ads   \n",
       "...                                                  ...   \n",
       "46861                                             Flickr   \n",
       "33416                                 Davis's Drug Guide   \n",
       "50777                        Funny Alarm Clock Ringtones   \n",
       "29367                                            Cookpad   \n",
       "8961                        Aprender inglÃ©s con Wlingua   \n",
       "\n",
       "                                                                                         Translated_Review  \\\n",
       "27559                                                                                                  NaN   \n",
       "60204  I'm enjoying gameplay, story & mechanics. The latest updates introduced fun ways earn in-game co...   \n",
       "15160                                                                                                  NaN   \n",
       "19450                                                                                                  NaN   \n",
       "54880                                                                                               Thanks   \n",
       "...                                                                                                    ...   \n",
       "46861                              This awful It wants auto upload photos. I find way upload image pc Mac.   \n",
       "33416          Terrible customer Unbound Medicine (developer) Google issues app. I'd give 0 stars I could.   \n",
       "50777                                                     Pretty cool ringtones. Even makes u laugh times.   \n",
       "29367                                                                                  Make cooking easier   \n",
       "8961                       It works as if it were a game ... Very easy to use ... And brings good results.   \n",
       "\n",
       "       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "27559          3                 NaN                     NaN  \n",
       "60204          2            0.100000                0.500000  \n",
       "15160          3                 NaN                     NaN  \n",
       "19450          3                 NaN                     NaN  \n",
       "54880          2            0.200000                0.200000  \n",
       "...          ...                 ...                     ...  \n",
       "46861          0           -0.400000                0.550000  \n",
       "33416          0           -1.000000                1.000000  \n",
       "50777          2            0.300000                0.583333  \n",
       "29367          1            0.000000                0.000000  \n",
       "8961           2            0.287778                0.666667  \n",
       "\n",
       "[22105 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >> Examples for duplicate detection and removal\n",
    "# House dataset has no duplicate anyway\n",
    "# Available strategies =\n",
    "#        'ED':  exact duplicate detection/removal or\n",
    "#        'AD':  for aproximate duplicate records detection and removal\n",
    "#        based on Jaccard similarity \n",
    "\n",
    "\n",
    "# import the Duplicate_detector class\n",
    "import learn2clean.duplicate_detection.duplicate_detector as dup\n",
    "\n",
    "#Remove exact duplicates with 'ED' strategy of the Duplicate_detector class\n",
    "\n",
    "dup1 = dup.Duplicate_detector(gpsu_encoded, strategy='ED', verbose=True).transform()\n",
    "\n",
    "dup1['train'].head()\n",
    "\n",
    "#Remove approximate duplicates with thresholding Jaccard similarity \n",
    "# using 'AD'strategy of the Duplicate_detector class\n",
    "dup2 = dup.Duplicate_detector(gpsu_encoded, strategy='AD', threshold = .6, verbose=True).transform()\n",
    "\n",
    "dup2['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Detect inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size of traning set 22105\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Patterns:\n",
      "         col  num        pattern\n",
      "0        App    0  '^[A-Za-z]+$'\n",
      "1  Sentiment    0    '^[1-2]+$^'\n",
      "\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 20381\n",
      "Indexes of rows to be removed: []\n",
      "* For test dataset\n",
      "Patterns:\n",
      "         col  num        pattern\n",
      "0        App    0  '^[A-Za-z]+$'\n",
      "1  Sentiment    0    '^[1-2]+$^'\n",
      "\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 11308\n",
      "Indexes of rows to be removed: []\n",
      "Consistency checking done -- CPU time: 0.11701011657714844 seconds\n",
      "After pattern checksing 1724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27559</th>\n",
       "      <td>Clover Dating App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60204</th>\n",
       "      <td>Harry Potter: Hogwarts Mystery</td>\n",
       "      <td>I'm enjoying gameplay, story &amp; mechanics. The latest updates introduced fun ways earn in-game co...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15160</th>\n",
       "      <td>Black Wallpaper, AMOLED, Dark Background: Darkify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19450</th>\n",
       "      <td>CBS News</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54880</th>\n",
       "      <td>Google Ads</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46861</th>\n",
       "      <td>Flickr</td>\n",
       "      <td>This awful It wants auto upload photos. I find way upload image pc Mac.</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33416</th>\n",
       "      <td>Davis's Drug Guide</td>\n",
       "      <td>Terrible customer Unbound Medicine (developer) Google issues app. I'd give 0 stars I could.</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50777</th>\n",
       "      <td>Funny Alarm Clock Ringtones</td>\n",
       "      <td>Pretty cool ringtones. Even makes u laugh times.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29367</th>\n",
       "      <td>Cookpad</td>\n",
       "      <td>Make cooking easier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>Aprender inglÃ©s con Wlingua</td>\n",
       "      <td>It works as if it were a game ... Very easy to use ... And brings good results.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     App  \\\n",
       "27559                                  Clover Dating App   \n",
       "60204                     Harry Potter: Hogwarts Mystery   \n",
       "15160  Black Wallpaper, AMOLED, Dark Background: Darkify   \n",
       "19450                                           CBS News   \n",
       "54880                                         Google Ads   \n",
       "...                                                  ...   \n",
       "46861                                             Flickr   \n",
       "33416                                 Davis's Drug Guide   \n",
       "50777                        Funny Alarm Clock Ringtones   \n",
       "29367                                            Cookpad   \n",
       "8961                        Aprender inglÃ©s con Wlingua   \n",
       "\n",
       "                                                                                         Translated_Review  \\\n",
       "27559                                                                                                  NaN   \n",
       "60204  I'm enjoying gameplay, story & mechanics. The latest updates introduced fun ways earn in-game co...   \n",
       "15160                                                                                                  NaN   \n",
       "19450                                                                                                  NaN   \n",
       "54880                                                                                               Thanks   \n",
       "...                                                                                                    ...   \n",
       "46861                              This awful It wants auto upload photos. I find way upload image pc Mac.   \n",
       "33416          Terrible customer Unbound Medicine (developer) Google issues app. I'd give 0 stars I could.   \n",
       "50777                                                     Pretty cool ringtones. Even makes u laugh times.   \n",
       "29367                                                                                  Make cooking easier   \n",
       "8961                       It works as if it were a game ... Very easy to use ... And brings good results.   \n",
       "\n",
       "       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "27559          3                 NaN                     NaN  \n",
       "60204          2            0.100000                0.500000  \n",
       "15160          3                 NaN                     NaN  \n",
       "19450          3                 NaN                     NaN  \n",
       "54880          2            0.200000                0.200000  \n",
       "...          ...                 ...                     ...  \n",
       "46861          0           -0.400000                0.550000  \n",
       "33416          0           -1.000000                1.000000  \n",
       "50777          2            0.300000                0.583333  \n",
       "29367          1            0.000000                0.000000  \n",
       "8961           2            0.287778                0.666667  \n",
       "\n",
       "[22105 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >> Examples for inconsistency detection \n",
    "# Available consistency checking strategies :\n",
    "#            - 'CC': checks whether the data satisfy the constraints\n",
    "#                specified in a 'file_name'_constraint.tdda stored in 'save' directory\n",
    "#            - 'PC': checks whether the data satisfy the patterns\n",
    "#                specified in 'file_name'_patterns.txt stored in 'save' directory\n",
    "\n",
    "# import the Consistency_checker class                \n",
    "import learn2clean.consistency_checking.consistency_checker as cc\n",
    "          \n",
    "# discover the constraints from the input (train) dataset and store them in a file entitled 'gpsu'_constraint.tdda in the 'save' directory\n",
    "#cc.constraint_discovery(read_dataset('gpsu'), file_name='gpsu')\n",
    "\n",
    "# discover the patterns from the input (train) dataset and store them in a file entitled 'gpsu'_patterns.txt in the 'save' directory\n",
    "#cc.pattern_discovery(read_dataset('gpsu'), file_name='gpsu')\n",
    "\n",
    "# detect pattern violations with respect to a given file of patterns entitled 'gpsu'_constraint.tdda\" stored in the 'save' directory\n",
    "#cc.Consistency_checker(gpsu_encoded.copy(), strategy='CC', file_name='gpsu_example',verbose=False).transform()\n",
    "\n",
    "# detect pattern violations with respect to a given file of patterns entitled 'gpsu'_patterns.txt\" stored in the 'save' directory\n",
    "# with too strong patterns resulting in an empty dataframe fro the training set\n",
    "print(\"Original size of traning set\", len(gpsu_encoded['train']))\n",
    "p1= cc.Consistency_checker(gpsu_encoded.copy(), strategy='PC', file_name='gpsu_example', verbose=True).transform()\n",
    "print(\"After pattern checksing\",len(p1['train']))\n",
    "gpsu_encoded['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Apply MR feature selection with missing threshold= 0.1\n",
      "                        missing_fraction\n",
      "Translated_Review               0.042977\n",
      "Sentiment_Polarity              0.042796\n",
      "Sentiment_Subjectivity          0.042796\n",
      "App                             0.000000\n",
      "Sentiment                       0.000000\n",
      "0 features with greater than 0.10 missing values.\n",
      "\n",
      "List of variables to be removed : []\n",
      "List of variables to be keep\n",
      "['Sentiment', 'Sentiment_Polarity', 'App', 'Sentiment_Subjectivity', 'Translated_Review']\n",
      "After feature selection:\n",
      "5 features remain\n",
      "['Sentiment', 'App', 'Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "Feature selection done -- CPU time: 0.017091989517211914 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Apply LC feature selection with threshold= 0.2\n",
      "Correlation matrix\n",
      "                        Sentiment  Sentiment_Polarity  Sentiment_Subjectivity\n",
      "Sentiment                1.000000            0.756499                0.185641\n",
      "Sentiment_Polarity       0.756499            1.000000                0.274542\n",
      "Sentiment_Subjectivity   0.185641            0.274542                1.000000\n",
      "2 features with linear correlation greater than 0.20.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "List of numerical variables to be keep\n",
      "['Sentiment']\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Translated_Review', 'App']\n",
      "Feature selection done -- CPU time: 0.023969650268554688 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Warning: This strategy requires no missing values, so missing values have been removed applying DROP on the dataset.\n",
      "Apply L1 feature selection with threshold= 0.7\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.02062201499938965 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Warning: This strategy requires no missing values, so missing values have been removed applying DROP on the dataset.\n",
      "Apply IMP feature selection with threshold= 0.4\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.2693789005279541 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Warning: This strategy requires no missing values, so missing values have been removed applying DROP on the dataset.\n",
      "Apply Tree-based feature selection \n",
      "Best features to keep ['Sentiment']\n",
      "After feature selection:\n",
      "1 features remain\n",
      "['Sentiment']\n",
      "Feature selection done -- CPU time: 0.1492443084716797 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Warning: This strategy requires no missing values, so missing values have been removed applying DROP on the dataset.\n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "Best features to keep ['Sentiment', 'Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "2 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity']\n",
      "Feature selection done -- CPU time: 0.017328739166259766 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Warning: This strategy requires no missing values, so missing values have been removed applying DROP on the dataset.\n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "Best features to keep ['Sentiment', 'Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "2 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity']\n",
      "Feature selection done -- CPU time: 0.014672279357910156 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Warning: This strategy requires no missing values, so missing values have been removed applying DROP on the dataset.\n",
      "Apply SVC feature selection\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.13122797012329102 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Apply VAR feature selection with threshold= 0.3\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.00627589225769043 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Apply VAR feature selection with threshold= 0.3\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.007575035095214844 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train':        Sentiment  Sentiment_Polarity  Sentiment_Subjectivity\n",
       " 27559          3                 NaN                     NaN\n",
       " 60204          2            0.100000                0.500000\n",
       " 15160          3                 NaN                     NaN\n",
       " 19450          3                 NaN                     NaN\n",
       " 54880          2            0.200000                0.200000\n",
       " ...          ...                 ...                     ...\n",
       " 46861          0           -0.400000                0.550000\n",
       " 33416          0           -1.000000                1.000000\n",
       " 50777          2            0.300000                0.583333\n",
       " 29367          1            0.000000                0.000000\n",
       " 8961           2            0.287778                0.666667\n",
       " \n",
       " [22105 rows x 3 columns],\n",
       " 'test':        Sentiment  Sentiment_Subjectivity  Sentiment_Polarity\n",
       " 7334           3                     NaN                 NaN\n",
       " 10900          2                0.583333            0.533333\n",
       " 62550          3                     NaN                 NaN\n",
       " 42242          0                0.583333           -0.275000\n",
       " 22985          3                     NaN                 NaN\n",
       " ...          ...                     ...                 ...\n",
       " 15994          0                0.555000           -0.061771\n",
       " 16138          1                0.000000            0.000000\n",
       " 14959          1                0.500000            0.000000\n",
       " 34121          2                0.700000            0.515972\n",
       " 613            1                0.000000            0.000000\n",
       " \n",
       " [12212 rows x 3 columns],\n",
       " 'target': 27559    3\n",
       " 60204    2\n",
       " 15160    3\n",
       " 19450    3\n",
       " 54880    2\n",
       "         ..\n",
       " 29367    1\n",
       " 12033    0\n",
       " 22548    3\n",
       " 8961     2\n",
       " 9124     3\n",
       " Name: Sentiment, Length: 43077, dtype: int64,\n",
       " 'target_test': 7334     3\n",
       " 10900    2\n",
       " 62550    3\n",
       " 42242    0\n",
       " 22985    3\n",
       "         ..\n",
       " 62289    2\n",
       " 58947    3\n",
       " 14959    1\n",
       " 34121    2\n",
       " 613      1\n",
       " Name: Sentiment, Length: 21218, dtype: int64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >> Examples for Feature selection\n",
    "# Available strategies=\n",
    "#           'MR': using a default threshold on the missing ratio per variable,\n",
    "#            i.e., variables with 20% (by default) and more missing values\n",
    "#            are removed\n",
    "#            'LC': detects pairs of linearly correlated variables and remove one\n",
    "#            'VAR': uses threshold on the variance\n",
    "#            'Tree': uses decision tree classification as model for feature\n",
    "#                selection given the target set for classification task\n",
    "#                'SVC': uses linear SVC as model for feature selection given\n",
    "#                 the target set for classification task\n",
    "#            'WR': uses the selectKbest (k=10) and Chi2 for feature selection\n",
    "#                given the target set for classification task\n",
    "#            'L1': uses Lasso L1 for feature selection given the target set for\n",
    "#                regression task\n",
    "#            'IMP': uses Random Forest regression for feature selection given\n",
    "#                the target set for regression task\n",
    "\n",
    "                \n",
    "import learn2clean.feature_selection.feature_selector as fs\n",
    "\n",
    "#Available strategies for feature selection \n",
    "#        'MR': using a default threshold on the missing ratio per variable, i.e., variables\n",
    "#                with 20% (by default) and more missing values are removed\n",
    "#        'LC': detects pairs of linearly correlated variables and remove one\n",
    "#        'VAR': uses threshold on the variance\n",
    "#        'Tree': uses decision tree classification as model for feature selection given the target set for classification task\n",
    "#        'SVC': uses linear SVC as model for feature selection given the target set for classification task\n",
    "#        'WR': uses the selectKbest (k=10) and Chi2 for feature selection given the target set for classification task\n",
    "#        'L1': uses Lasso L1 for feature selection given the target set for regression task\n",
    "#        'IMP': uses Random Forest regression for feature selection given the target set for regression task\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'MR', threshold=0.1, exclude=None, verbose=True).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'LC', threshold=0.2,  exclude=None, verbose=True).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'L1',  exclude= None, threshold=.7,verbose=True).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'IMP', exclude = 'Sentiment',verbose=True, threshold=.4).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'Tree',  exclude='Sentiment',verbose=True).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'WR', exclude= 'Sentiment', verbose=True).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'WR', exclude= 'Sentiment', verbose=True).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'SVC',  exclude='Sentiment').transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'VAR',  exclude=None).transform()\n",
    "\n",
    "fs.Feature_selector(dataset = gpsu_encoded.copy(), strategy= 'VAR',  exclude='Sentiment').transform()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>Classification task\n",
      "{'mean_fit_time': array([0.0103085]), 'std_fit_time': array([0.00346133]), 'mean_score_time': array([0.0022136]), 'std_score_time': array([0.00033464]), 'params': [{}], 'split0_test_score': array([0.92287335]), 'split1_test_score': array([0.92911153]), 'split2_test_score': array([0.92230624]), 'split3_test_score': array([0.93098884]), 'mean_test_score': array([0.92631999]), 'std_test_score': array([0.00379409]), 'rank_test_score': array([1], dtype=int32)}\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.9263199900210195\n",
      "\n",
      "Classification done -- CPU time: 0.07854294776916504 seconds\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.9695166400765082\n",
      "\n",
      "Classification done -- CPU time: 0.08776712417602539 seconds\n"
     ]
    }
   ],
   "source": [
    "import learn2clean.classification.classifier as cl\n",
    "#output is accuracy of classification for k=10 cross-validation and execution time \n",
    "#plus a detailed classification report if verbose = True\n",
    "\n",
    "Cl1 = cl.Classifier(dataset = gpsu_encoded.copy(),target = 'Sentiment',strategy = 'LDA', verbose = True).transform()\n",
    "\n",
    "Cl2 = cl.Classifier(dataset = gpsu_encoded,target = 'Sentiment',strategy = 'NB',verbose = False).transform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>Regression task\n",
      "MSE values of cross validation\n",
      "[[5.33743316e-01 5.44632576e-01 5.18560311e-01 5.33404270e-01\n",
      "  5.31033047e-01 5.34874014e-01 5.23829093e-01 5.27877129e-01\n",
      "  5.18448407e-01 5.35975556e-01]\n",
      " [3.70655081e-01 3.78217066e-01 3.60111327e-01 3.70419632e-01\n",
      "  3.68772949e-01 3.71440287e-01 3.63770203e-01 3.66581340e-01\n",
      "  3.60033616e-01 3.72205247e-01]\n",
      " [2.37219252e-01 2.42058922e-01 2.30471249e-01 2.37068564e-01\n",
      "  2.36014687e-01 2.37721784e-01 2.32812930e-01 2.34612057e-01\n",
      "  2.30421514e-01 2.38211358e-01]\n",
      " [9.26637702e-02 9.45542666e-02 9.00278317e-02 9.26049079e-02\n",
      "  9.21932373e-02 9.28600718e-02 9.09425508e-02 9.16453349e-02\n",
      "  9.00084040e-02 9.30513117e-02]\n",
      " [2.31659425e-02 2.36385666e-02 2.25069579e-02 2.31512270e-02\n",
      "  2.30483093e-02 2.32150180e-02 2.27356377e-02 2.29113337e-02\n",
      "  2.25021010e-02 2.32628279e-02]\n",
      " [3.70655081e-03 3.78217066e-03 3.60111327e-03 3.70419632e-03\n",
      "  3.68772949e-03 3.71440287e-03 3.63770203e-03 3.66581340e-03\n",
      "  3.60033616e-03 3.72205247e-03]\n",
      " [9.26637702e-04 9.45542666e-04 9.00278317e-04 9.26049079e-04\n",
      "  9.21932373e-04 9.28600718e-04 9.09425508e-04 9.16453349e-04\n",
      "  9.00084040e-04 9.30513117e-04]\n",
      " [2.31659425e-04 2.36385666e-04 2.25069579e-04 2.31512270e-04\n",
      "  2.30483093e-04 2.32150180e-04 2.27356377e-04 2.29113337e-04\n",
      "  2.25021010e-04 2.32628279e-04]\n",
      " [1.48262032e-04 1.51286827e-04 1.44044531e-04 1.48167853e-04\n",
      "  1.47509180e-04 1.48576115e-04 1.45508081e-04 1.46632536e-04\n",
      "  1.44013446e-04 1.48882099e-04]\n",
      " [3.70655081e-05 3.78217066e-05 3.60111327e-05 3.70419632e-05\n",
      "  3.68772949e-05 3.71440287e-05 3.63770203e-05 3.66581340e-05\n",
      "  3.60033616e-05 3.72205247e-05]\n",
      " [3.70655081e-07 3.78217066e-07 3.60111327e-07 3.70419632e-07\n",
      "  3.68772949e-07 3.71440287e-07 3.63770203e-07 3.66581340e-07\n",
      "  3.60033616e-07 3.72205247e-07]]\n",
      "alphas vs. MSE in cross-validation\n",
      "    alpha           MSE\n",
      "0   1.200  5.302378e-01\n",
      "1   1.000  3.682207e-01\n",
      "2   0.800  2.356612e-01\n",
      "3   0.500  9.205517e-02\n",
      "4   0.250  2.301379e-02\n",
      "5   0.100  3.682207e-03\n",
      "6   0.050  9.205517e-04\n",
      "7   0.025  2.301379e-04\n",
      "8   0.020  1.472883e-04\n",
      "9   0.010  3.682207e-05\n",
      "10  0.001  3.682207e-07\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 3.6525302380173736e-07\n",
      "Regression done -- CPU time: 0.059838056564331055 seconds\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     2.085859e-14\n",
       "Sentiment                 1.000000e+00\n",
       "Sentiment_Polarity       -4.483176e-17\n",
       "Sentiment_Subjectivity    4.751516e-16\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10900</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42242</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.275000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58644</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30659</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061771</td>\n",
       "      <td>0.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16138</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14959</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34121</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.515972</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11333 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity\n",
       "10900    1.0          2            0.533333                0.583333\n",
       "42242    1.0          0           -0.275000                0.583333\n",
       "58644    1.0          0           -0.700000                0.666667\n",
       "30659    1.0          1            0.000000                0.000000\n",
       "39192    1.0          2            0.505208                0.666667\n",
       "...      ...        ...                 ...                     ...\n",
       "15994    1.0          0           -0.061771                0.555000\n",
       "16138    1.0          1            0.000000                0.000000\n",
       "14959    1.0          1            0.000000                0.500000\n",
       "34121    1.0          2            0.515972                0.700000\n",
       "613      1.0          1            0.000000                0.000000\n",
       "\n",
       "[11333 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11333, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11333, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 1.024e+31\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):               0.00\n",
      "Time:                        11:31:24   Log-Likelihood:             6.3591e+05\n",
      "No. Observations:               21159   AIC:                        -1.272e+06\n",
      "Df Residuals:                   21155   BIC:                        -1.272e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                   2.086e-14   4.41e-16     47.292      0.000       2e-14    2.17e-14\n",
      "Sentiment                  1.0000   2.76e-16   3.62e+15      0.000       1.000       1.000\n",
      "Sentiment_Polarity     -4.483e-17   6.53e-16     -0.069      0.945   -1.32e-15    1.23e-15\n",
      "Sentiment_Subjectivity  4.752e-16    5.8e-16      0.820      0.412   -6.61e-16    1.61e-15\n",
      "==============================================================================\n",
      "Omnibus:                    92619.261   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2547.838\n",
      "Skew:                           0.100   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.312   Cond. No.                         10.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE of OLS with 10  folds for cross-validation: 4.6018847098619e-28\n",
      "Regression done -- CPU time: 0.0664219856262207 seconds\n",
      "\n",
      ">>Regression task\n",
      "Earth Model\n",
      "--------------------------------------\n",
      "Basis Function  Pruned  Coefficient   \n",
      "--------------------------------------\n",
      "(Intercept)     No      -6.80935e-16  \n",
      "Sentiment       No      1             \n",
      "--------------------------------------\n",
      "MSE: 0.0000, GCV: 0.0000, RSQ: 1.0000, GRSQ: 1.0000\n",
      "MSE of MARS with 10 folds for cross-validation: 0.024741156250331926\n",
      "Regression done -- CPU time: 2.751260995864868 seconds\n"
     ]
    }
   ],
   "source": [
    "import learn2clean.regression.regressor as rg\n",
    "# output is MSE and computation time, with regression summary if verbose = True\n",
    " \n",
    "    \n",
    "rg1 = rg.Regressor(dataset = gpsu_encoded,target = 'Sentiment',strategy= 'LASSO', verbose = True).transform()\n",
    "\n",
    "rg3 = rg.Regressor(dataset = gpsu_encoded,target = 'Sentiment',strategy= 'OLS',verbose = True).transform()\n",
    "\n",
    "rg2 = rg.Regressor(dataset = gpsu_encoded,target = 'Sentiment',strategy= 'MARS',verbose = True).transform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.7106  for k= 3\n",
      "Quality of clustering 0.7106\n",
      "Labels distribution:\n",
      "0    13594\n",
      "1     4476\n",
      "2     3089\n",
      "Name: cluster_ID, dtype: int64\n",
      "Clustering done -- CPU time: 26.188260793685913 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'quality_metric': 0.7106,\n",
       " 'result': {'train':        Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
       "  60204          2            0.100000                0.500000           0\n",
       "  54880          2            0.200000                0.200000           0\n",
       "  5540           2            0.600000                0.691667           0\n",
       "  53098          0           -0.108333                0.383333           1\n",
       "  17076          2            0.044792                0.398958           0\n",
       "  ...          ...                 ...                     ...         ...\n",
       "  46861          0           -0.400000                0.550000           1\n",
       "  33416          0           -1.000000                1.000000           1\n",
       "  50777          2            0.300000                0.583333           0\n",
       "  29367          1            0.000000                0.000000           2\n",
       "  8961           2            0.287778                0.666667           0\n",
       "  \n",
       "  [21159 rows x 4 columns],\n",
       "  'test':                                                      App  \\\n",
       "  7334                                       Angry Birds 2   \n",
       "  10900                                       BIG Launcher   \n",
       "  62550                     Hola Launcher- Theme,Wallpaper   \n",
       "  42242                                                FOX   \n",
       "  22985  Camera360: Selfie Photo Editor with Funny Sticker   \n",
       "  ...                                                  ...   \n",
       "  15994                                       Block Puzzle   \n",
       "  16138                     Blogaway for Android (Blogger)   \n",
       "  14959                            BioLife Plasma Services   \n",
       "  34121                           Diary with lock password   \n",
       "  613                                            2RedBeans   \n",
       "  \n",
       "                                                                                           Translated_Review  \\\n",
       "  7334                                                                                                   NaN   \n",
       "  10900                                          Great Great I cannot delete recent calls even paid version.   \n",
       "  62550                                                                                                  NaN   \n",
       "  42242  From bad to worse, after the last update I can already stream, start for 5 seconds then turn off...   \n",
       "  22985                                                                                                  NaN   \n",
       "  ...                                                                                                    ...   \n",
       "  15994  This game okay. I thought would like Tetris isn't. There levels, can't change shapes pieces, \"ch...   \n",
       "  16138                                                                                  Thenivijayfans Move   \n",
       "  14959                                                      Been using now. All sudden I exist? Please fix.   \n",
       "  34121                                                            Super easy unlike I downloaded. Love it!!   \n",
       "  613                                                                                             can't chat   \n",
       "  \n",
       "         Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "  7334           3                 NaN                     NaN  \n",
       "  10900          2            0.533333                0.583333  \n",
       "  62550          3                 NaN                     NaN  \n",
       "  42242          0           -0.275000                0.583333  \n",
       "  22985          3                 NaN                     NaN  \n",
       "  ...          ...                 ...                     ...  \n",
       "  15994          0           -0.061771                0.555000  \n",
       "  16138          1            0.000000                0.000000  \n",
       "  14959          1            0.000000                0.500000  \n",
       "  34121          2            0.515972                0.700000  \n",
       "  613            1            0.000000                0.000000  \n",
       "  \n",
       "  [12212 rows x 5 columns],\n",
       "  'target': 27559    3\n",
       "  60204    2\n",
       "  15160    3\n",
       "  19450    3\n",
       "  54880    2\n",
       "          ..\n",
       "  29367    1\n",
       "  12033    0\n",
       "  22548    3\n",
       "  8961     2\n",
       "  9124     3\n",
       "  Name: Sentiment, Length: 43077, dtype: int64,\n",
       "  'target_test': 7334     3\n",
       "  10900    2\n",
       "  62550    3\n",
       "  42242    0\n",
       "  22985    3\n",
       "          ..\n",
       "  62289    2\n",
       "  58947    3\n",
       "  14959    1\n",
       "  34121    2\n",
       "  613      1\n",
       "  Name: Sentiment, Length: 21218, dtype: int64}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import learn2clean.clustering.clusterer as ct\n",
    "# clustering is applied to one dataset (i.e., the training set if two datasets are given in the path)\n",
    "# output is silhouette, best k, and computation time, plus the training dataset with cluster IDs\n",
    "\n",
    "ct.Clusterer(dataset = gpsu_encoded,strategy= 'KMEANS', verbose=True).transform()\n",
    "#ct.Clusterer(dataset = gpsu_encoded,strategy='HCA', verbose = True).transform()\n",
    "#ct.Clusterer(dataset = gpsu_encoded,strategy='HCA', metric= 'euclidean', verbose = True).transform()\n",
    "#ct.Clusterer(dataset = gpsu_encoded,strategy='HCA', metric= 'cosine', verbose = True).transform()\n",
    "#ct.Clusterer(dataset = gpsu_encoded,strategy='HCA', metric= 'cityblock', verbose = True).transform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Create your own pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading csv : googleplaystore_reviews.csv ...\n",
      "Reading data ...\n",
      "CPU time: 3.0525476932525635 seconds\n",
      "Profiling datasets\n",
      "                Attribute     Type  Num. Missing Values  Num. Unique Values             Sknewness  Kurtosis\n",
      "0      Sentiment_Polarity  float64              26863.0              6196.0  -0.10457655084633158  0.646756\n",
      "1  Sentiment_Subjectivity  float64              26863.0              4531.0   -0.3063336025424886 -0.282853\n",
      "2                     App   object                  0.0              1074.0                   N/A       N/A\n",
      "3       Translated_Review   object              26868.0             27995.0                   N/A       N/A\n",
      "4               Sentiment   object              26863.0                 4.0                   N/A       N/A\n",
      "\n",
      "> Number of categorical features in the training set: 3\n",
      "> Number of numerical features in the training set: 2\n",
      "> Number of data samples : 64295\n",
      "\n",
      "> Top sparse features (% missing values on dataset set):\n",
      "Translated_Review         41.9\n",
      "Sentiment_Subjectivity    41.9\n",
      "Sentiment_Polarity        41.9\n",
      "Sentiment                 41.9\n",
      "dtype: float64\n",
      "\n",
      "> Task : classification\n",
      "Positive    16082\n",
      "Negative     5458\n",
      "Neutral      3489\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Encoding target...\n",
      "Encoding target done...\n",
      ">>Imputation \n",
      "* For train dataset\n",
      "Before imputation:\n",
      "Total 54149 missing values in ['Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 36096 numerical missing values in ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 18053 non-numerical missing values in ['Translated_Review']\n",
      "After imputation:\n",
      "Total 40563 missing values\n",
      "- 0 numerical missing values\n",
      "- 40563 non-numerical missing values\n",
      "* For test dataset\n",
      "Before imputation:\n",
      "Total 26445 missing values in ['Translated_Review', 'Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 17630 numerical missing values in ['Sentiment_Polarity', 'Sentiment_Subjectivity']\n",
      "- 8815 non-numerical missing values in ['Translated_Review']\n",
      "After imputation:\n",
      "Total 31132 missing values\n",
      "- 0 numerical missing values\n",
      "- 31132 non-numerical missing values\n",
      "Imputation done -- CPU time: 0.08541178703308105 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.049268245697021484 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "LOF requires no missing values, so missing values have been removed using DROP.\n",
      "20 outlying rows have been removed\n",
      "* For test dataset\n",
      "LOF requires no missing values, so missing values have been removed using DROP.\n",
      "20 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.5719139575958252 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "{'mean_fit_time': array([0.00583142]), 'std_fit_time': array([0.00046063]), 'mean_score_time': array([0.00145078]), 'std_score_time': array([3.95433583e-05]), 'params': [{}], 'split0_test_score': array([0.64068122]), 'split1_test_score': array([0.64068122]), 'split2_test_score': array([0.64044135]), 'split3_test_score': array([0.64044135]), 'mean_test_score': array([0.64056129]), 'std_test_score': array([0.00011993]), 'rank_test_score': array([1], dtype=int32)}\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.04816699028015137 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'quality_metric': 0.6405612856800191}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create your preprocessing pipeline for classification\n",
    "\n",
    "import learn2clean.loading.reader as rd \n",
    "import learn2clean.normalization.normalizer as nl \n",
    "import learn2clean.feature_selection.feature_selector as fs\n",
    "import learn2clean.duplicate_detection.duplicate_detector as dd\n",
    "import learn2clean.outlier_detection.outlier_detector as od\n",
    "import learn2clean.imputation.imputer as imp\n",
    "import learn2clean.classification.classifier as cl\n",
    "\n",
    "d_enc = rd.Reader(sep=',',verbose=True, encoding=True) \n",
    "gpsu  = [\"../datasets/googleplaystore_reviews.csv\"]\n",
    "gpsu_encoded = d_enc.train_test_split(gpsu, 'Sentiment')\n",
    "\n",
    "# replace numerical missing values by median\n",
    "d1 = imp.Imputer(dataset=gpsu_encoded, strategy = 'MEDIAN',verbose=False).transform()\n",
    "# decima scaling for numerical variables\n",
    "d2 = nl.Normalizer(dataset=d1, strategy='DS', exclude = 'Sentiment', verbose=False).transform()\n",
    "# eliminate 20 LOF outliers\n",
    "d3 = od.Outlier_detector(dataset=d2, strategy='LOF', threshold= 0.2,verbose=False).transform()\n",
    "\n",
    "# classify with LDA\n",
    "cl.Classifier(dataset=d3,strategy = 'LDA', target = 'Sentiment', verbose =True).transform()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn2clean data preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Learn2Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.13692498207092285 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> AD -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03148818016052246 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 5\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 2\n",
      "Deduplication done -- CPU time: 0.8885259628295898 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.640093276308767\n",
      "\n",
      "Classification done -- CPU time: 50.96629095077515 seconds\n",
      "End Pipeline CPU time: 51.886422872543335 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> LOF -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.027534008026123047 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.5257349014282227 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6399731462231462\n",
      "\n",
      "Classification done -- CPU time: 50.02764892578125 seconds\n",
      "End Pipeline CPU time: 50.581071853637695 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> IQR -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.018052101135253906 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.020533323287963867 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6397803892458918\n",
      "\n",
      "Classification done -- CPU time: 46.89527702331543 seconds\n",
      "End Pipeline CPU time: 46.933987855911255 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> IQR -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment', 'Sentiment_Subjectivity', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.01884174346923828 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02375507354736328 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6397803892458918\n",
      "\n",
      "Classification done -- CPU time: 47.436577796936035 seconds\n",
      "End Pipeline CPU time: 47.48066997528076 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> LOF -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "5 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "4 features remain\n",
      "['Sentiment', 'Translated_Review', 'App', 'Sentiment_Polarity']\n",
      "Feature selection done -- CPU time: 0.010115861892700195 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.44301795959472656 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6397928577616079\n",
      "\n",
      "Classification done -- CPU time: 39.160138845443726 seconds\n",
      "End Pipeline CPU time: 39.613975048065186 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> IQR -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.024981021881103516 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6397803892458918\n",
      "\n",
      "Classification done -- CPU time: 47.48653173446655 seconds\n",
      "End Pipeline CPU time: 47.5115749835968 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> Tree -> IQR -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.026963233947753906 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02789783477783203 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.636600965045725\n",
      "\n",
      "Classification done -- CPU time: 37.02832531929016 seconds\n",
      "End Pipeline CPU time: 37.08339524269104 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.5392050743103027 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6399731462231462\n",
      "\n",
      "Classification done -- CPU time: 46.102135181427 seconds\n",
      "End Pipeline CPU time: 46.641395807266235 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02478790283203125 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6397803892458918\n",
      "\n",
      "Classification done -- CPU time: 47.47861886024475 seconds\n",
      "End Pipeline CPU time: 47.50350213050842 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.15782904624938965 seconds\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6397803892458918\n",
      "\n",
      "Classification done -- CPU time: 47.017603158950806 seconds\n",
      "End Pipeline CPU time: 47.17568612098694 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.06539535522460938 seconds\n",
      "\n",
      ">>Classification task\n",
      "Error: Need at least one continous variable and 10 observations for classification\n",
      "Classification done -- CPU time: 0.0013630390167236328 seconds\n",
      "End Pipeline CPU time: 0.06680822372436523 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> LOF -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16158\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4224\n",
      "Deduplication done -- CPU time: 0.013789176940917969 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.45992016792297363 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6388883590061519\n",
      "\n",
      "Classification done -- CPU time: 46.38021492958069 seconds\n",
      "End Pipeline CPU time: 46.85413098335266 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> CART\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 5\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 2\n",
      "Deduplication done -- CPU time: 2.0838983058929443 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.640093276308767\n",
      "\n",
      "Classification done -- CPU time: 46.642614126205444 seconds\n",
      "End Pipeline CPU time: 48.726613998413086 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6416392980396726\n",
      "\n",
      "Classification done -- CPU time: 87.13948082923889 seconds\n",
      "End Pipeline CPU time: 87.13950800895691 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> AD -> CART', 'MM -> LOF -> CART', 'ZS -> IQR -> CART', 'WR -> IQR -> CART', 'LC -> LOF -> CART', 'Tree -> IQR -> CART', 'ZSB -> Tree -> IQR -> CART', 'LOF -> CART', 'IQR -> CART', 'CC -> CART', 'PC -> CART', 'ED -> LOF -> CART', 'AD -> CART']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.640093276308767}, {'quality_metric': 0.6399731462231462}, {'quality_metric': 0.6397803892458918}, {'quality_metric': 0.6397803892458918}, {'quality_metric': 0.6397928577616079}, {'quality_metric': 0.6397803892458918}, {'quality_metric': 0.636600965045725}, {'quality_metric': 0.6399731462231462}, {'quality_metric': 0.6397803892458918}, {'quality_metric': 0.6397803892458918}, {'quality_metric': None}, {'quality_metric': 0.6388883590061519}, {'quality_metric': 0.640093276308767}, {'quality_metric': 0.6416392980396726}]\n",
      "\n",
      "Strategy CART for maximal accuracy : 0.6416392980396726 for CART\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 645.2055609226227 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'CART', 'Sentiment', None, 'CART', 'accuracy', 0.6416392980396726, 645.2055609226227)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtyklEQVR4nO3deXxcd33v/9dbkndbcrxLtmPHiR1bdhaICQkh7AkOS8KPJSRsSaFQoJRyewsl5V4I9N7eUpYSIJSypEApWYCSmjYLIQQCgSSWszheJNtx4ki25C22JK/aPr8/zpEzKLKlsTWaRe/n46GHZ86cOfMZRZn3fM/3e75fRQRmZmaDVZbvAszMrLg4OMzMLCsODjMzy4qDw8zMsuLgMDOzrDg4zMwsKw4OG3Ek/VrSnx7jsfmSQlLFcNeVL8f7fZj1x8FhBUnS05IOSWqXtE/S7yV9UFLB/M1KulbS7wqgji9K2pT+ruolvafP46MlXZ/ucyD93d4kaX6eSrYiVzD/E5r1440RMQmYB/wD8DfAd/Nb0vAaZMvnAPBGoAq4BrhB0ksyHv8JcDnwjnSfc4DVwKuHtlobKRwcVvAiojUiVgJvB66RtExSlaQfSNolaauk/9XbGkm/Xf+w9/nHOP10uqSHJbVJ+k9JU/p77fR1viupWdI2Sf9HUvlANUtaLOkeSc9KapB0ZcZjr5f0aPrajZKu76fW90l6BvhVb8smbVnslfSUpMsyfj+fiYj6iOiJiIeA3wIXpsd7DXAJcEVErIqIrvT3eWNE9BvCkt4raUP6WndLmpfx2A1pzW2SVku6OOOx6yXdlv53aZe0TtLygX5XVnwcHFY0IuJhoAm4GPgaybfnBcDLgfcAf5LF4d4DvBeoBrqArx5jv++lj58BvAC4FDhuf4CkCcA9wI+AGcBVwDck1aa7HEhffzLweuBDkt7U5zAvB5YAr03vvxhoAKYB/wh8V5L6ee1xwIuAdemm1wAPR0Tj8WrOeP4VwN8Cbwamk4TQzRm7rALOBaak7+/HksZmPH45cEv63lYCXx/M61pxcXBYsdlO8qF1FXBdRLRHxNPAl4B3Z3Gcf4uItRFxAPjfwJV9WxKSZgKvAz4WEQciYifwT+lrH88bgKcj4l/Tb/iPAj8F3gYQEb+OiCfSFsIakg/ml/c5xvXpax5K72+NiG9HRDfwfZLAm9nPa38TeBy4O70/FWge6JeR4YPA/4uIDRHRBfw9cG5vqyMifhgRe9L39SVgDHBmxvN/FxF3pHX+G8lpMSsxI2bkiJWM2SR/t6OArRnbt6aPDVbmN/Ct6fGm9dlnXrq9OePLfVmf5/ZnHvBiSfsytlWQfJAi6cUkfTbLgNEkH74/Pk59AC29NyLiYFrPxMwdJH0hPeYr47nZS/cAiwaot2/tN0j6UuahSX63WyX9NfA+oAYIoJI//r21ZNw+CIyVVJGGkJUItzisaEh6EckH2O1AJ8mHXK9TgW3p7QPA+IzHZvVzuLl9ntsJ7O6zTyNwBJgWEZPTn8qIWDpAqY3AbzKeMzkiJkbEh9LHf0RyGmduRFSRtBL6nnbKatpqSZ8FLgMujYi2jId+CZwvac4gD9UI/Fmf2sdFxO/T/oxPAFcCp0TEZKC1n9qtxDk4rOBJqpT0BpJz5z+MiMeB24D/K2lSehrlr4DeDvHHgJdJOlVSFXBdP4d9l6RaSeOBzwE/SU+vHBURzcAvgC+lNZRJOl1S5mklSRqb+QP8F7BI0rsljUp/XiRpSfqcScCzEXFY0vkko51O5vdzXXqM10TEnj7v4Zck/S0/k3SepIr0d/ZBSe/t53DfBK6TtDQ9dpWkt2XU3QXsAiokfZqkxWEjjIPDCtnPJbWTfAv+FPBlnusA/wuSlsUW4Hck3+JvAoiIe4BbgTUkw07/q59j/xtJx3cLMBb46DFqeA/J6aT1wF6Soa3VGY+/BDjUz8+lJH0h29PX+DzJKSmADwOfS9/bp0lC8GT8PUmrabOk/enP32Y8/lbgDpLfSSuwFlhO0hr5IxHxs7TWWyS1pfv2juC6G7gL2Ehyeu8wA5+2sxIkL+RkZmbZcIvDzMyy4uAwM7OsODjMzCwrDg4zM8vKiLgAcNq0aTF//vx8l2FmVlRWr169OyKm990+IoJj/vz51NXV5bsMM7OiImlrf9t9qsrMzLLi4DAzs6w4OMzMLCsODjMzy4qDw8zMsuLgMDOzrDg4zMwsKw4OM7MS9HjjPr7+q020H+4c8mM7OMzMStAP/rCVb/5mC+VlQ79Ao4PDzKzEtB/u5I4nmnnjOTWMHz30E4Q4OMzMSszPH2/mUGc3b3/R3Jwc38FhZlZibqtrZNHMiZwzpyonx3dwmJmVkI072nmscR9XLp+LNPT9G+DgMDMrKbeuamRUuXjzC+fk7DUcHGZmJaKjq4efPbqNS2pnMmXC6Jy9joPDzKxE/HLDDp490MGVy3PTKd7LwWFmViJuXdVIddVYLl74vEX7hpSDw8ysBGzfd4j7N+3irefNyclFf5kcHGZmJeCnq5uIgLedl9vTVODgMDMrej09wW2rG3nJ6VM5der4nL+eg8PMrMg9uGUPjc8eytmV4n05OMzMitytdY1MGlvBa5fOGpbXc3CYmRWx1oOd3Lm2hTedO5uxo8qH5TUdHGZmRWzl49vo6OoZttNU4OAwMytqt9Y1UltdybLZuZnQsD8ODjOzIrVueytrt7UNa2sDHBxmZkXrtlWNjK4o44pza4b1dR0cZmZF6HBnN7c/tp3XLp3F5PG5m9CwPw4OM7Mi9Iv1O2g91MnbczyhYX8cHGZmRei2VY3MOWUcLzl96rC/dk6DQ9IKSQ2SNkv65DH2uVLSeknrJP2oz2OVkpokfT1j2/+V1Chpfy5rNzMrVI3PHuR3m3fztvPmUpbjCQ37k7PgkFQO3AhcBtQCV0uq7bPPQuA64KKIWAp8rM9h/g64v8+2nwPn56JmM7Ni8OPVTUjw1uW5W+XveHLZ4jgf2BwRWyKiA7gFuKLPPu8HboyIvQARsbP3AUnnATOBX2Q+ISIejIjmHNZtZlawunuCn9Q18tIzpjF78ri81JDL4JgNNGbcb0q3ZVoELJL0gKQHJa0AkFQGfAn46xN9cUkfkFQnqW7Xrl0nehgzs4LywObdbG89POzXbmTKd+d4BbAQeAVwNfBtSZOBDwN3RETTiR44Ir4VEcsjYvn06bldDcvMbLjcWtfI5PGjuKR2Zt5qqMjhsbcBmZE4J92WqQl4KCI6gackbSQJkguBiyV9GJgIjJa0PyL67WA3MxsJ9h7o4J51O3jHi09lTMXwTGjYn1y2OFYBCyWdJmk0cBWwss8+t5O0NpA0jeTU1ZaIeGdEnBoR80lOV/3AoWFmI93PHt1GR/fwTmjYn5wFR0R0AR8B7gY2ALdFxDpJn5N0ebrb3cAeSeuB+4CPR8Se4x1X0j9KagLGp0N1r8/VezAzKxQRwW11jZw9p4ol1ZV5rUURkdcChsPy5cujrq4u32WYmZ2wNU37uPzrD/B/3rSMd10wb1heU9LqiFjed3u+O8fNzGwQbl3VyJiKMi4f5gkN++PgMDMrcIc6uln52HZed1Y1lWNH5bscB4eZWaG7c20z7Ue6uDIPExr2x8FhZlbgbqtrZN7U8VywYEq+SwEcHGZmBW3rngM8uOVZrlw+F2n4JzTsj4PDzKyA3VbXSJngLS/Mz4SG/XFwmJkVqK7uHn6yuomXL5rOrKqx+S7nKAeHmVmBun/TLna0Hcn7leJ9OTjMzArUbauamDphNK9anL8JDfvj4DAzK0C79x/hlxt28OYXzmZ0RWF9VBdWNWZmBsDPHtlGV08UzLUbmRwcZmYFJiK4ta6RF5w6mYUzJ+W7nOdxcJiZFZhHntnH5p37eXsBtjbAwWFmVnB+XNfI+NHlvOGc/E9o2B8Hh5lZATlwpIufP76d159VzcQxuVyk9cQ5OMzMCsh/P9HMgY7ugrt2I5ODw8ysgNy2qpEF0ydw3rxT8l3KMTk4zMwKxOad+6nburegJjTsj4PDzKxA/Hh1I+Vl4s0vnJ3vUo7LwWFmVgA6u3v46eptvGrxDGZMKpwJDfvj4DAzKwD31e9k9/4jBXvtRiYHh5lZAbitrpHpk8bwijOn57uUATk4zMzybGfbYe5r2MVbXjiHivLC/1gu/ArNzErcTx/ZRndPcOXywlnl73gcHGZmeRQR/LiukfPnT2HB9In5LmdQHBxmZnm06um9bNl9gCsL+ErxvhwcZmZ5dOuqRiaOqeB1Z83KdymD5uAwM8uT9sOd3PFEM288p5rxowtzQsP+ODjMzPLkv9Y0c6izuyBX+Tue4om4PLjmpoc53NnNWbOrOGtOFWfNrmL+1AmUlRXuHDJmVhwiglsefoZFMydy7tzJ+S4nKzkNDkkrgBuAcuA7EfEP/exzJXA9EMDjEfGOjMcqgfXA7RHxkXTbecD3gHHAHcBfRkTkov4zZ03i4aee5QcPbqWjqweASWMqWDq7krPnTGbZ7CrOnl3FvKnjC3pCMjMrPA9s3sPjTa383ZuWFd3nR86CQ1I5cCNwCdAErJK0MiLWZ+yzELgOuCgi9kqa0ecwfwfc32fbPwPvBx4iCY4VwJ25eA9/+7olQDKHzKYd+3li2z6e2NbKE02tfO+Bp+noTsKkcmwFyzJaJWfPnszcKeOK7o/BzIZHRHDDvRuZVTm2aK7dyJTLFsf5wOaI2AIg6RbgCpIWRK/3AzdGxF6AiNjZ+0DaspgJ3AUsT7dVA5UR8WB6/wfAm8hRcPQaVV5GbU0ltTWVvP1FybaOrh427mhPgiQNk5t+9xSd3Unjp2rcqD86xXXW7CrmnOIwMTP4w5N7WPX0Xj57+VLGVJTnu5ys5TI4ZgONGfebgBf32WcRgKQHSE5nXR8Rd0kqA74EvAt4TZ9jNvU5Zl7mHx5dUcay2VUsm13F1em2I13dbGzZn4ZJ0jr5zm+3HA2TyeNHHQ2Rs+dUcc7cyVRXjctH+VaEDnV0U1EuRhXBlBR2fF+5dxMzK8cU9Cp/x5PvzvEKYCHwCmAOcL+ks0gC446IaDrRb+iSPgB8AODUU08dkmIHMqaiPGlhzKkCktc80tVNQ0s7a5paWbutlTVNrXzr/i109SRhsmx2JZctq+a1S2dxxoziuGrUhl9E8Jov/4b2w528ZslMViybxcsWTWfsqOL7tjrSPbhlDw8/9SyfeWNt0f73y2VwbAMy43ROui1TE/BQRHQCT0naSBIkFwIXS/owMBEYLWk/SUf7nAGOCUBEfAv4FsDy5ctz0nk+GGMqyjl7zmTOnjP56LbDnd3Ut7Tz0JY93LWuhS/c3cAX7m5g4YyJXLZsFq9dNova6kqf1rKjtrceZtu+Q5w1u4p763fyH49uY/zocl65eAYrls7ilYtnMHFMvr8H2mDc8MtNTJ80hqvPH54vtLmQy7+0VcBCSaeRfLhfBbyjzz63A1cD/yppGsmpqy0R8c7eHSRdCyyPiE+m99skXUDSOf4e4Gs5fA85MXZUOefOncy5cyfzZy8/nebWQ9y9toU717bw9fs289VfbebUKeO5bNksViybxTlzJnsI8AjX0NIGwKffWMu5cyfz4JY93Lm2hV+sa+G/1zQzuqKMly2czopls7hkyUyqxo/Kc8XWn4efepY/bNnD/35D8bY2IIfBERFdkj4C3E3Sf3FTRKyT9DmgLiJWpo9dKmk90A18PCL2DHDoD/PccNw7yXHH+HCorhrHtRedxrUXncbu/Ue4Z/0O7lzbwnd/9xT/cv8WZlWOZUUaIi+aP4Vyh8iIs6G5HUiGiI8qL+PihdO5eOF0/u6KZazeupc71zZz99oWfrlhBxVl4sLTp7Ji2SwurZ3F9Elj8ly99brh3o1MmziGdxRxawNAOboEoqAsX7486urq8l1G1loPdnJvfRIi92/cxZGuHqZOGM2lS2eyYlk1Fy6YyugKd5SOBB+9+VFWb93LA5981TH3iQgeb2rlrrUt3LW2maf3HESCF82fkpwCXTqLmskejJEvdU8/y1u/+Qc+9bolvP9lC/JdzqBIWh0Ry5+33cFRHA4c6eLXDbu4c20z99Xv5EBHN5VjK9xROkK89p/uZ/Yp47jp2hcNav+IoL6lnTvXtnD32hYadiQtlnPmTk5OgS6dxfxpE3JZsvXx7u8+xPrtbfz2b15ZNPNSOTiKPDgyHe7s5nebdnNnemqi9VBn0lF65gxWLCvOjtKIoLM76OrpoasnKJeSoadlZSO+f6ejq4faT9/FB162gE+sWHxCx9iya38SIutaWNPUCsDiWZO4bFk1K5bNYtHMiR6MkUOPPLOXN3/j91x32WL+7OWn57ucQXNwlFBwZOrs7uEPTyajs36xroXd+zsYXVHGxWdMY84puTst0R1BV3fyYd/Z3UNXT89zt9N/k+0Z+3Rn7NOTsU93HB2e3J/yMlFRJkaXl1FRLirKy567XZZc15D8JI+NSq91qCjLuJ2G0KgKcWlt0kIrFhua27jsht9yw1XncsW5J3/ZUtPeg9yVhkjd1r1EwIJpE7jg9KmMymFIX37ubM6bd0rOjl/IrrnpYZ7Y1spvP/FKJhTRl7pjBUfxvAPr16jyMl62aDovW5R0lNY9/Sx3rWvh3g07Wf3M3py9bpkyP7R7P7DT2+n28aMrjl6wlmzP/IB/7gO/73EqykR3TxImHV1JKHV1Bx1HQ6aHjq7os73n6P6HO3vYf7iLju5Iw6rnaGtm78FOHn1mX1EFR0NLcppp8azKITnenFPG86cXL+BPL17AzrbD3L1+B3etbeaOJ5qH5PjH8oJTTxmRwfFY4z5+s3EXn1hxZlGFxvGUxrswIPlm/uIFU3nxgql85o1L811OQfp/d27gX3/3NB1dPUUzsKC+pZ1R5WLB9KHvk5hROZZ3XzCPd18wb8iPbYkbfrmRyeNH8Z4L5+e7lCFTHP/nmA2R2upKOrp7eHLX/nyXMmj1LW2cPn2ipxopQmua9nFfwy7ef/GCout3PB7/JdqIsrQmOd2zfntbnisZvIaWdhbPmpTvMuwEfPXeTVSNG8V7LiytFp2Dw0aU06ZNZOyoMtY3F0dwtB7spLn1MGcOUf+GDZ+121r55YadvO+lpzFpbGldye/gsBGlvEycOauyaFoc9elUI4ur3eIoNjfcu4nKsRVce9H8fJcy5BwcNuLUVleyvrmNYhiK3nvhnk9VFZd121u5Z/0O3vvS06gssdYGODhsBKqtqaT1UCfbWw/nu5QB1be0Uzm2glmVY/NdimXha/duZtLYCv7kotPyXUpOODhsxKmtLp4O8vrmNhZ7iv2isqG5jbvWtfAnF51G1bjSa22Ag8NGoMWzJiEVfnBEBBt37PdpqiLztV9tYuKYCt5bgn0bvRwcNuJMGFPBaVMnsL65Nd+lHFfT3kPsP9LFmQ6OotHQ0s4dT7Rw7UvmM3n86HyXkzMODhuRltRUFvyQ3OemGnFwFIuv/WoTE0aX876XlmbfRi8Hh41ItdWVND57iNZDnfku5Zh6h+IumungKAabdrTz3080c81L5nPKhNJtbcAgg0PS/yepKuP+ZElvyllVZjlWm15BXl/ArY76lnbmnDKu5C4eK1Vf+9Vmxo0q508vLo5Fmk7GYFscn4mIoyeEI2If8JmcVGQ2DJb2jqwq4ODwVCPFY/PO/fx8zXbefeE8ppR4awMGHxz97Vc6M3bZiDN90himTRxdsCOrjnR1s2X3gSGbSt1y6+u/2sTYinI+MAJaGzD44KiT9GVJp6c/XwZW57Iws1ySxJLqwu0g37xzP9094RFVRWDLrv2sfDxpbUydOCbf5QyLwQbHXwAdwK3pzxHgz3NVlNlwqK2pZNOO/XR09eS7lOfxiKri8fX7NjO6ooz3j5DWBgzydFNEHAA+meNazIZV79ocm3fuP9pZXijqW9oZXV7GadOGfvEmGzpP7z7Afz62nWtfMp/pk0ZGawMGCA5JX4mIj0n6OfC8GeEi4vKcVWaWY0trkoGC65vbCjI4zpgxkQov3lTQvn7fZirKxJ+9fOS0NmDgFse/pf9+MdeFmA2306ZNSNbm2N4G5+W7mj/W0NLGRadPy3cZdhxb9xzgZ49u4z0XzmPGpJE1CeVxgyMiVksqBz4QEe8cpprMhkV5mVg8q7Lgph7Ze6CDHW1H3DFe4L5x35OUl4kPvvz0fJcy7AZsB0dENzBPUukPTrYRp7YmWdSpkNbmqO/tGK8urNNn9pzGZw/y00eaeMf5pzJzBE55P9hrMbYAD0haCRzo3RgRX85JVWbDpLa6kh899Azb9h1izinj810OkJymAo+oKmTf+PVmyjTy+jZ6DTY4nkx/yoDev+bC+YpmdoJ6O8XXb28rnODY0c7k8aOYMYJG6RSTpr0H+XFdE1effyrVVePyXU5eDDY41kfEjzM3SHpbDuoxG1ZH1+ZobuPSpbPyXQ4AG5rb07q8eFMh+savn0SCD71i5PVt9BrsWL/rBrnNrKiMH13BadMmFMzUIz09wcYd7Z5qpEBt33eIH9c1cuXyudRMHpmtDRj4Oo7LgNcBsyV9NeOhSqArl4WZDZfa6koea9yX7zKAZPGmgx3dHlFVoP75108C8OFXnpHnSvJroBbHdqAOOEwyN1Xvz0rgtQMdXNIKSQ2SNkvq98pzSVdKWi9pnaQfpdvmSXpE0mPp9g9m7P92SWvS7Z8f3Ns0O7bamkqa9hbG2hwb3DFesJpbD3Hrqkbeet4cZo/g1gYMfB3H48Dj6Qd6BXBqRDQM5sDp9R83ApcATcAqSSsjYn3GPgtJTnldFBF7Jc1IH2oGLoyII5ImAmvTEV1HgC8A50XELknfl/TqiLg3q3dtlqE2Hfa6obmNCxZMzWstvXNUefGmwvPNXz9JTwQffsXIbm3A4Ps4VgCPAXcBSDo3/SA/nvOBzRGxJSI6gFuAK/rs837gxojYCxARO9N/OyLiSLrPmIw6FwCbImJXev+XwFsG+R7M+pU5sirfGlraOXXKeCaM8aoFhWRH22FuXtXIW144h7lTCmP0XT4NNjiuJwmCfQAR8Rgw0KK6s4HGjPtN6bZMi4BFkh6Q9KCkFb0PSJoraU16jM9HxHZgM3CmpPmSKoA3AXP7e3FJH5BUJ6lu165d/e1iBsCMSWOZNnFMQUyxXt/S5v6NAvTN3zxJd0/w5yO8b6PXYIOjM3MFwNRQXMdRASwEXgFcDXxb0mSAiGiMiLOBM4BrJM1MWyYfIpna/bfA00B3fweOiG9FxPKIWD59+vQhKNVKWe8V5Pl0uLObp3YfYImDo6DsbDvMjx56hje/YDanTnVrAwYfHOskvQMol7RQ0teA3w/wnG38cWtgTrotUxOwMiI6I+IpYCNJkByVtjTWAhen938eES+OiAuBhvQ5ZieltrqSTTvb87o2x+ad++kJONNDcQvKv9y/hS63Nv5INgs5LSXpnL4ZaAM+NsBzVgELJZ2WznN1FclorEy3k7Q2kDSN5NTVFklzJI1Lt58CvJQkJOjtQE+3fxj4ziDfg9kx1dZU0tkdbN65P2819M5R5VNVhWNX+xH+/aGtXHFuDfO9NspRg13I6SDwqfRnUCKiS9JHgLuBcuCmiFgn6XNAXUSsTB+7VNJ6klNOH4+IPZIuAb4kKQABX4yIJ9JD3yDpnPT25yLCLQ47ab0jq/K5Nkd9cxtjKsqY79MhBeOJbfsYVVbGX7xq4cA7jyADXQB43JFTAy3kFBF3AHf02fbpjNsB/FX6k7nPPcDZxzjm1cd7TbMTUQhrczTsaGfhTC/eVEhetXgmD33q1Ywf7VFumQb6bVxIMqrpZuAhkm//ZiWnENbmqG9p52ULPZCj0Dg0nm+grzazgL8FlgE3kFzMtzsifhMRv8l1cWbDKZ9rc+zZf4Rd7UdYUu3+DSt8xw2OiOiOiLsi4hrgApLrKH6d9l2YlZSlNZW0He5i275Dw/7aDe4YtyIyYBtM0hjg9STXWcwHvgr8LLdlmQ2/3g7ydXlYm8MjqqyYDNQ5/gOS01R3AJ+NiLXDUpVZHiyeVUmZkqlHXjvMa3M0tLQzZcJopk/04k1W+AZqcbyLZKnYvwQ+mrGwjEgGRflKJSsZ40aXJ2tz5GHqkfqWNi/eZEVjoNlxPS7QRpTamioe2bp3WF8zWbxpP1ed3++0a2YFx8FglqG2upJt+w7RenD41uZ45tmDHOrs9hocVjQcHGYZjk6xPoynq+qPLt7kM79WHBwcZhkypx4ZLvUt7UhevMmKh4PDLMP0SWOYPmnMsE6x3tDSzrwp4xk3unzYXtPsZDg4zPqora4c9haHT1NZMXFwmPVRW1PJ5mFam+NQRzdP7zngC/+sqDg4zPqorU7W5ti0sz3nr7VpZzsReESVFRUHh1kfR0dWDUM/h6casWLk4DDrY/7UCYwbVT4s/Rz1ze2MHVXGvKleXc6Kh4PDrI/yMrG4etKwtDgadrSxaOYkyss81YgVDweHWT96R1blem2OhpZ2zvT1G1ZkHBxm/aitqaT9cBdNe3O3Nseu9iPs3t/B4moPxbXi4uAw68dwXEHeu3iTR1RZsXFwmPUjc22OXOmdo8ojqqzYODjM+jEca3PUt7QzbeIYpnnxJisyDg6zY1haU5XTFkdDS7tPU1lRcnCYHUNtTe7W5ujuCTbuaPdpKitKDg6zY+jtIF/X3Drkx9665wBHunocHFaUHBxmx7CkOndTj/RONbLEs+JaEXJwmB3D9EljmDFpTE46yOtb2ikTLJw5cciPbZZrDg6z46itqcxJi6OhpY35UycwdpQXb7Li4+AwO47a6ko279zPka7uIT1ufUs7i6vdv2HFycFhdhy1NZV09QSbduwfsmMe7OjimWcPcuZM929YccppcEhaIalB0mZJnzzGPldKWi9pnaQfpdvmSXpE0mPp9g9m7H+1pCckrZF0l6RpuXwPNrLlYuqRjTv2E+Erxq14VeTqwJLKgRuBS4AmYJWklRGxPmOfhcB1wEURsVfSjPShZuDCiDgiaSKwVtJKYCdwA1AbEbsl/SPwEeD6XL0PG9nmTZ3A+NHlQ9rPUZ+G0BKfqrIilcsWx/nA5ojYEhEdwC3AFX32eT9wY0TsBYiInem/HRFxJN1nTEadSn8mSBJQCWzP4XuwEa68TCyeNWlIWxz1Le2MH13O3FPGD9kxzYZTLoNjNtCYcb8p3ZZpEbBI0gOSHpS0ovcBSXMlrUmP8fmI2B4RncCHgCdIAqMW+G5/Ly7pA5LqJNXt2rVr6N6VjTi1NZVs2D50a3M0tLSzcOYkyrx4kxWpfHeOVwALgVcAVwPfljQZICIaI+Js4AzgGkkzJY0iCY4XADXAGpJTXc8TEd+KiOURsXz69Ok5fyNWumqrq2g/MjRrc0QE9S1tLPbiTVbEchkc24C5GffnpNsyNQErI6IzIp4CNpIEyVERsR1YC1wMnJtuezKSr3+3AS/JSfVmqdqadOqRIejn2NV+hL0HOz0U14paLoNjFbBQ0mmSRgNXASv77HM7SWuDdHTUImCLpDmSxqXbTwFeCjSQBE+tpN4mxCXAhhy+BzPOnDkpWZtjCPo5eqca8YgqK2Y5G1UVEV2SPgLcDZQDN0XEOkmfA+oiYmX62KWS1gPdwMcjYo+kS4AvSQqSzvAvRsQTAJI+C9wvqRPYClybq/dgBsnaHAumTxySkVXPrfrnaziseOUsOAAi4g7gjj7bPp1xO4C/Sn8y97kHOPsYx/wm8M0hL9bsOGqrK1m9de9JH2dDSxszJo1hyoTRQ1CVWX7ku3PcrCj0rs2x72DHSR2nocVrcFjxc3CYDcJQXEHe1d3Dpp37veqfFT0Hh9kg9I6sOpl+jqf3HKCjq8f9G1b0HBxmgzBt4hhmVp7c2hweUWWlwsFhNki11Se3NkdDSzvlZeKMGV68yYqbg8NskGprTm5tjg3N7cyfOt6LN1nRc3CYDVJtddVJrc3RsKONxdXu37Di5+AwG6ST6SDff6SLxmcPeY4qKwkODrNBmjdlfLI2xwl0kG/c4Y5xKx0ODrNBKisTS06wg7y+OQmOJT5VZSXAwWGWhdrqStY3t9HTk93aHA0tbUwYXc7syeNyVJnZ8HFwmGWhtqaS/SewNkd9SzuLZnnxJisNDg6zLDw39UjroJ+TLN7U7ivGrWQ4OMyycOasdG2OLPo5drQdofVQp+eospLh4DDLwthR5Zw+fWJWI6vqW5J9PaLKSoWDwyxLtTXZjayqP7p4k4PDSoODwyxLtdWVbG89zN4Dg1ubo6GlnVmVY5k83os3WWlwcJhlqfcK8g2DPF1V78WbrMQ4OMyytCSLRZ06u3t40os3WYlxcJhl6ejaHIPo53hq9wE6untYXO3gsNLh4DA7Ab1XkA/k6OJNM30Nh5UOB4fZCehdm+Nw5/HX5mhoaaO8TJw+Y8IwVWaWew4OsxOwtCZZm2PzzuOvzVHf3M7p0ycwpsKLN1npcHCYnYCjU48M0M+RjKjyaSorLQ4OsxNw6pTxTBhgbY62w51s23fII6qs5Dg4zE7AYNbm2Hi0Y9zBYaXFwWF2gmprjr82x9GpRjwU10qMg8PsBNVWH39tjoaWdiaNqfDiTVZyHBxmJ6h36pF12/tfm6MhXbxJ8uJNVlocHGYnaNHMSZSXqd8O8ohgQ0ubO8atJOU0OCStkNQgabOkTx5jnyslrZe0TtKP0m3zJD0i6bF0+wfT7ZPSbb0/uyV9JZfvwexYkrU5JvTbQd7cepj2w10ODitJFbk6sKRy4EbgEqAJWCVpZUSsz9hnIXAdcFFE7JU0I32oGbgwIo5ImgisTZ+7HTg34/mrgf/I1XswG0htdSUPPfXs87Y39I6o8jUcVoJy2eI4H9gcEVsiogO4Bbiizz7vB26MiL0AEbEz/bcjIo6k+4zpr05Ji4AZwG9zVL/ZgGprKmluPcyzfdbm2OBV/6yE5TI4ZgONGfeb0m2ZFgGLJD0g6UFJK3ofkDRX0pr0GJ9PWxuZrgJujYh+x0JK+oCkOkl1u3btOuk3Y9af2uoq4PlrczS0tFNTNZaqcaPyUZZZTuW7c7wCWAi8Arga+LakyQAR0RgRZwNnANdImtnnuVcBNx/rwBHxrYhYHhHLp0+fnovazViSXqPRt5+jwYs3WQnLZXBsA+Zm3J+TbsvUBKyMiM6IeArYSBIkR6UtjbXAxb3bJJ0DVETE6lwUbjZYUyeOYVbl2D8aWdXR1cPmnfvdv2ElK5fBsQpYKOk0SaNJWggr++xzO0lrA0nTSE5dbZE0R9K4dPspwEuBhoznXc1xWhtmw6m25o+nHtmyez9dPXG0NWJWanIWHBHRBXwEuBvYANwWEeskfU7S5eludwN7JK0H7gM+HhF7gCXAQ5IeB34DfDEinsg4/JU4OKxA1FZXsnnXc2tzPDeiysFhpSlnw3EBIuIO4I4+2z6dcTuAv0p/Mve5Bzj7OMddMLSVmp242ppKunuCTTv2c9acKupb2qkoEwumTcx3aWY5ke/OcbOid3RtjuZk6pH65jbOmDGR0RX+38tKk/+yzU7S0bU50n4Oj6iyUufgMDtJR9fmaG6j9VAn21sPOzispDk4zIbA0ppKNjS3U58Oy13iobhWwhwcZkOgtiZZm+Oe9TsAj6iy0ubgMBsCvVOP/Ofj25k0toLqqrF5rsgsdxwcZkNg4cyJlJeJXe1HWOzFm6zEOTjMhsDYUeWcMT25bmOx+zesxDk4zIZI71Ky7t+wUufgMBsivRcCetU/K3U5nXLEbCS54twadu8/wjlzJ+e7FLOccnCYDZEZlWO57nVL8l2GWc75VJWZmWXFwWFmZllxcJiZWVYcHGZmlhUHh5mZZcXBYWZmWXFwmJlZVhwcZmaWFUVEvmvIOUm7gK0n+PRpwO4hLGc4ufbhV6x1g2vPl0KufV5ETO+7cUQEx8mQVBcRy/Ndx4lw7cOvWOsG154vxVi7T1WZmVlWHBxmZpYVB8fAvpXvAk6Cax9+xVo3uPZ8Kbra3cdhZmZZcYvDzMyy4uAwM7OsODiOQdIKSQ2SNkv6ZL7rGSxJcyXdJ2m9pHWS/jLfNWVLUrmkRyX9V75ryYakyZJ+Iqle0gZJF+a7psGS9D/Sv5e1km6WNDbfNR2LpJsk7ZS0NmPbFEn3SNqU/ntKPms8lmPU/oX0b2aNpJ9JmpzHEgfFwdEPSeXAjcBlQC1wtaTa/FY1aF3A/4yIWuAC4M+LqPZefwlsyHcRJ+AG4K6IWAycQ5G8B0mzgY8CyyNiGVAOXJXfqo7re8CKPts+CdwbEQuBe9P7heh7PL/2e4BlEXE2sBG4briLypaDo3/nA5sjYktEdAC3AFfkuaZBiYjmiHgkvd1O8uE1O79VDZ6kOcDrge/ku5ZsSKoCXgZ8FyAiOiJiX16Lyk4FME5SBTAe2J7neo4pIu4Hnu2z+Qrg++nt7wNvGs6aBqu/2iPiFxHRld59EJgz7IVlycHRv9lAY8b9Jorow7eXpPnAC4CH8lxKNr4CfALoyXMd2ToN2AX8a3qa7TuSJuS7qMGIiG3AF4FngGagNSJ+kd+qsjYzIprT2y3AzHwWcxLeC9yZ7yIG4uAoUZImAj8FPhYRbfmuZzAkvQHYGRGr813LCagAXgj8c0S8ADhA4Z4u+SNpf8AVJOFXA0yQ9K78VnXiIrnGoOiuM5D0KZJTzf+e71oG4uDo3zZgbsb9Oem2oiBpFElo/HtE/Ee+68nCRcDlkp4mOT34Kkk/zG9Jg9YENEVEb+vuJyRBUgxeAzwVEbsiohP4D+Alea4pWzskVQOk/+7Mcz1ZkXQt8AbgnVEEF9c5OPq3Clgo6TRJo0k6ClfmuaZBkSSS8+wbIuLL+a4nGxFxXUTMiYj5JL/zX0VEUXzzjYgWoFHSmemmVwPr81hSNp4BLpA0Pv37eTVF0rGfYSVwTXr7GuA/81hLViStIDk9e3lEHMx3PYPh4OhH2lH1EeBukv+BbouIdfmtatAuAt5N8m39sfTndfkuaoT4C+DfJa0BzgX+Pr/lDE7aSvoJ8AjwBMnnQsFOgyHpZuAPwJmSmiS9D/gH4BJJm0haUP+QzxqP5Ri1fx2YBNyT/v/6zbwWOQiecsTMzLLiFoeZmWXFwWFmZllxcJiZWVYcHGZmlhUHh5mZZcXBYXYCJHVnDHd+bKAZlCV9UNJ7huB1n5Y07WSPY3YyPBzX7ARI2h8RE/Pwuk+TzGK7e7hf26yXWxxmQyhtEfyjpCckPSzpjHT79ZL+Or390XS9lDWSbkm3TZF0e7rtQUlnp9unSvpFulbGdwBlvNa70td4TNK/pMsBmOWcg8PsxIzrc6rq7RmPtUbEWSRXBH+ln+d+EnhBuv7CB9NtnwUeTbf9LfCDdPtngN9FxFLgZ8CpAJKWAG8HLoqIc4Fu4J1D+QbNjqUi3wWYFalD6Qd2f27O+Pef+nl8DcnUJLcDt6fbXgq8BSAifpW2NCpJ1vh4c7r9vyXtTfd/NXAesCqZXopxFNnEfla8HBxmQy+OcbvX60kC4Y3ApySddQKvIeD7EVHwq8VZ6fGpKrOh9/aMf/+Q+YCkMmBuRNwH/A1QBUwEfkt6qknSK4Dd6Toq9wPvSLdfBvSupX0v8FZJM9LHpkial7u3ZPYctzjMTsw4SY9l3L8rInqH5J6SzpB7BLi6z/PKgR+mS80K+GpE7JN0PXBT+ryDPDdF+GeBmyWtA35PMgU6EbFe0v8CfpGGUSfw58DWIX6fZs/j4bhmQ8jDZW0k8KkqMzPLilscZmaWFbc4zMwsKw4OMzPLioPDzMyy4uAwM7OsODjMzCwr/z9MoaB09bUZMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='CART',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.14276409149169922 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> LOF -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03119206428527832 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.27724695205688477 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6406343958874892\n",
      "\n",
      "Classification done -- CPU time: 0.06008601188659668 seconds\n",
      "End Pipeline CPU time: 0.3687629699707031 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> LOF -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03076314926147461 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.2933776378631592 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.640574314176362\n",
      "\n",
      "Classification done -- CPU time: 0.05155611038208008 seconds\n",
      "End Pipeline CPU time: 0.37592506408691406 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> AD -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.017484188079833984 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 0.9788987636566162 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.05611705780029297 seconds\n",
      "End Pipeline CPU time: 1.0526080131530762 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> LOF -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.01568293571472168 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.31906890869140625 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6402739344922839\n",
      "\n",
      "Classification done -- CPU time: 0.06646013259887695 seconds\n",
      "End Pipeline CPU time: 0.4023270606994629 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> LOF -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.01415109634399414 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.322437047958374 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405142324652349\n",
      "\n",
      "Classification done -- CPU time: 0.046784162521362305 seconds\n",
      "End Pipeline CPU time: 0.38537073135375977 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> ZSB -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.02685689926147461 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6380997474747475\n",
      "\n",
      "Classification done -- CPU time: 0.04988265037536621 seconds\n",
      "End Pipeline CPU time: 0.0768880844116211 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.02643299102783203 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6380997474747475\n",
      "\n",
      "Classification done -- CPU time: 0.04718637466430664 seconds\n",
      "End Pipeline CPU time: 0.07367300987243652 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.3147149085998535 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6402739344922839\n",
      "\n",
      "Classification done -- CPU time: 0.05820727348327637 seconds\n",
      "End Pipeline CPU time: 0.37297725677490234 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.025951862335205078 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.0539860725402832 seconds\n",
      "End Pipeline CPU time: 0.07999396324157715 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.10588479042053223 seconds\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.05392193794250488 seconds\n",
      "End Pipeline CPU time: 0.1598660945892334 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> IQR -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.06990718841552734 seconds\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "No outlier detection for train dataset\n",
      "No outlier detection for test dataset\n",
      "Outlier detection and removal done -- CPU time: 9.393692016601562e-05 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Error: Need at least one continous variable and 10 observations for classification\n",
      "Classification done -- CPU time: 0.001600027084350586 seconds\n",
      "End Pipeline CPU time: 0.07167410850524902 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> IQR -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.024038076400756836 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.031298160552978516 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.06356406211853027 seconds\n",
      "End Pipeline CPU time: 0.11916637420654297 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> LDA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 0.9468681812286377 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.05409407615661621 seconds\n",
      "End Pipeline CPU time: 1.0010349750518799 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.05755496025085449 seconds\n",
      "End Pipeline CPU time: 0.05758094787597656 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> LOF -> LDA', 'MM -> LOF -> LDA', 'ZS -> AD -> LDA', 'WR -> LOF -> LDA', 'LC -> LOF -> LDA', 'Tree -> ZSB -> LDA', 'ZSB -> LDA', 'LOF -> LDA', 'IQR -> LDA', 'CC -> LDA', 'PC -> IQR -> LDA', 'ED -> IQR -> LDA', 'AD -> LDA']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.6406343958874892}, {'quality_metric': 0.640574314176362}, {'quality_metric': 0.6405612856800191}, {'quality_metric': 0.6402739344922839}, {'quality_metric': 0.6405142324652349}, {'quality_metric': 0.6380997474747475}, {'quality_metric': 0.6380997474747475}, {'quality_metric': 0.6402739344922839}, {'quality_metric': 0.6405612856800191}, {'quality_metric': 0.6405612856800191}, {'quality_metric': None}, {'quality_metric': 0.6405612856800191}, {'quality_metric': 0.6405612856800191}, {'quality_metric': 0.6405612856800191}]\n",
      "\n",
      "Strategy DS -> LOF -> LDA for maximal accuracy : 0.6406343958874892 for LDA\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 4.606396198272705 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'LDA', 'Sentiment', None, 'DS -> LOF -> LDA', 'accuracy', 0.6406343958874892, 4.606396198272705)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='LDA',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.13640785217285156 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> LOF -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.027326107025146484 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.2788207530975342 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6406343843843845\n",
      "\n",
      "Classification done -- CPU time: 0.06772828102111816 seconds\n",
      "End Pipeline CPU time: 0.37407803535461426 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> AD -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02672719955444336 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.1256740093231201 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.07197880744934082 seconds\n",
      "End Pipeline CPU time: 1.2244911193847656 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> IQR -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.018669843673706055 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.023543834686279297 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.06667304039001465 seconds\n",
      "End Pipeline CPU time: 0.10901713371276855 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> ZS -> IQR -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.01261591911315918 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.01587700843811035 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02460312843322754 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.0760798454284668 seconds\n",
      "End Pipeline CPU time: 0.13035821914672852 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> LOF -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.013834953308105469 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.31290125846862793 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405142642642643\n",
      "\n",
      "Classification done -- CPU time: 0.0639810562133789 seconds\n",
      "End Pipeline CPU time: 0.3925669193267822 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> IQR -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.026173114776611328 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.07290911674499512 seconds\n",
      "End Pipeline CPU time: 0.09913897514343262 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.029366016387939453 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6380997612283668\n",
      "\n",
      "Classification done -- CPU time: 0.06341195106506348 seconds\n",
      "End Pipeline CPU time: 0.09283614158630371 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.321012020111084 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6402739518364517\n",
      "\n",
      "Classification done -- CPU time: 0.06821203231811523 seconds\n",
      "End Pipeline CPU time: 0.3892793655395508 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.027238845825195312 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.0660700798034668 seconds\n",
      "End Pipeline CPU time: 0.09336185455322266 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.10632491111755371 seconds\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.06699013710021973 seconds\n",
      "End Pipeline CPU time: 0.17336821556091309 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> IQR -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.06870293617248535 seconds\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "No outlier detection for train dataset\n",
      "No outlier detection for test dataset\n",
      "Outlier detection and removal done -- CPU time: 0.00021219253540039062 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Error: Need at least one continous variable and 10 observations for classification\n",
      "Classification done -- CPU time: 0.0028569698333740234 seconds\n",
      "End Pipeline CPU time: 0.07189512252807617 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> ZS -> IQR -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.0346529483795166 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.022435903549194336 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.026634931564331055 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.0671091079711914 seconds\n",
      "End Pipeline CPU time: 0.15109515190124512 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> NB\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.21923828125 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.06939411163330078 seconds\n",
      "End Pipeline CPU time: 1.288696050643921 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.06604409217834473 seconds\n",
      "End Pipeline CPU time: 0.0660858154296875 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> LOF -> NB', 'MM -> AD -> NB', 'ZS -> IQR -> NB', 'WR -> ZS -> IQR -> NB', 'LC -> LOF -> NB', 'Tree -> IQR -> NB', 'ZSB -> NB', 'LOF -> NB', 'IQR -> NB', 'CC -> NB', 'PC -> IQR -> NB', 'ED -> ZS -> IQR -> NB', 'AD -> NB']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.6406343843843845}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6405142642642643}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6380997612283668}, {'quality_metric': 0.6402739518364517}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6405613121979921}, {'quality_metric': None}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6405613121979921}, {'quality_metric': 0.6405613121979921}]\n",
      "\n",
      "Strategy DS -> LOF -> NB for maximal accuracy : 0.6406343843843845 for NB\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 4.663424968719482 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'NB', 'Sentiment', None, 'DS -> LOF -> NB', 'accuracy', 0.6406343843843845, 4.663424968719482)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='NB',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.12810778617858887 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> LOF -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.027039051055908203 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.27722811698913574 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.2592189311981201 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.1165706227344132\n",
      "Regression done -- CPU time: 0.03882002830505371 seconds\n",
      "End Pipeline CPU time: 1.602755069732666 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03688502311706543 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.4274590015411377 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.0987335781900334\n",
      "Regression done -- CPU time: 0.04051995277404785 seconds\n",
      "End Pipeline CPU time: 1.5052008628845215 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> IQR -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.027621030807495117 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.036512136459350586 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  1.2\n",
      "MSE of LASSO with 10  folds for cross-validation: 2.6469078179696615\n",
      "Regression done -- CPU time: 0.04743599891662598 seconds\n",
      "End Pipeline CPU time: 0.1118478775024414 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> ZSB -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.02003002166748047 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.03635716438293457 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 0.5322060585021973 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.0133387361779598\n",
      "Regression done -- CPU time: 0.03772401809692383 seconds\n",
      "End Pipeline CPU time: 0.6279098987579346 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.01750016212463379 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.4453938007354736 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Error: Need at least one continous variable and  10  observations for regression\n",
      "Regression done -- CPU time: 0.0066487789154052734 seconds\n",
      "End Pipeline CPU time: 1.4719948768615723 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.400681972503662 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.0987335781900334\n",
      "Regression done -- CPU time: 0.039504289627075195 seconds\n",
      "End Pipeline CPU time: 1.4402668476104736 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.04189300537109375 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.3113858699798584 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.0133387361779598\n",
      "Regression done -- CPU time: 0.03565216064453125 seconds\n",
      "End Pipeline CPU time: 1.3892250061035156 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.3545091152191162 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.7106537818908691 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.099084696253305\n",
      "Regression done -- CPU time: 0.038140058517456055 seconds\n",
      "End Pipeline CPU time: 2.1035990715026855 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.041854143142700195 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.1486877052906703\n",
      "Regression done -- CPU time: 0.053143978118896484 seconds\n",
      "End Pipeline CPU time: 0.09508705139160156 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.13871502876281738 seconds\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.1486877052906703\n",
      "Regression done -- CPU time: 0.04163098335266113 seconds\n",
      "End Pipeline CPU time: 0.18041276931762695 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.11472773551940918 seconds\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "No train dataset, no duplicate detection\n",
      "No test dataset, no duplicate detection\n",
      "Deduplication done -- CPU time: 9.393692016601562e-05 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Error: Need at least one continous variable and  10  observations for regression\n",
      "Regression done -- CPU time: 0.002682924270629883 seconds\n",
      "End Pipeline CPU time: 0.1175990104675293 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> CC -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.039475202560424805 seconds\n",
      "\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.10667705535888672 seconds\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.1486877052906703\n",
      "Regression done -- CPU time: 0.038717031478881836 seconds\n",
      "End Pipeline CPU time: 0.1849668025970459 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> LASSO\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.6315510272979736 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.0987335781900334\n",
      "Regression done -- CPU time: 0.03930497169494629 seconds\n",
      "End Pipeline CPU time: 1.6711530685424805 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.001\n",
      "MSE of LASSO with 10  folds for cross-validation: 1.1486877052906703\n",
      "Regression done -- CPU time: 0.05217289924621582 seconds\n",
      "End Pipeline CPU time: 0.05220675468444824 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> LOF -> AD -> LASSO', 'MM -> AD -> LASSO', 'ZS -> IQR -> LASSO', 'WR -> ZSB -> AD -> LASSO', 'LC -> AD -> LASSO', 'Tree -> AD -> LASSO', 'ZSB -> AD -> LASSO', 'LOF -> AD -> LASSO', 'IQR -> LASSO', 'CC -> LASSO', 'PC -> AD -> LASSO', 'ED -> CC -> LASSO', 'AD -> LASSO']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 1.1165706227344132}, {'quality_metric': 1.0987335781900334}, {'quality_metric': 2.6469078179696615}, {'quality_metric': 1.0133387361779598}, {'quality_metric': None}, {'quality_metric': 1.0987335781900334}, {'quality_metric': 1.0133387361779598}, {'quality_metric': 1.099084696253305}, {'quality_metric': 1.1486877052906703}, {'quality_metric': 1.1486877052906703}, {'quality_metric': None}, {'quality_metric': 1.1486877052906703}, {'quality_metric': 1.0987335781900334}, {'quality_metric': 1.1486877052906703}]\n",
      "\n",
      "Strategy WR -> ZSB -> AD -> LASSO for minimal MSE  1.0133387361779598 for LASSO\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 12.561751127243042 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'LASSO', 'Sentiment', None, 'WR -> ZSB -> AD -> LASSO', 'MSE', 1.0133387361779598, 12.561751127243042)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='LASSO',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "Reward matrix\n",
      "[[ -1.  -1.  -1.   0.   0.   0.   0.   0.   0.  -1.  -1.   0.   0.  -1.]\n",
      " [ -1.  -1.  -1.   0.   0.   0.   0.   0.   0.  -1.  -1.   0.   0.  -1.]\n",
      " [ -1.  -1.  -1.   0.   0.   0.   0.   0.   0.  -1.  -1.   0.   0.  -1.]\n",
      " [  0.   0.   0.  -1.  -1.  -1.   0.   0.   0.  -1.  -1.   0.   0.  -1.]\n",
      " [  0.   0.   0.  -1.  -1.  -1.   0.   0.   0.  -1.  -1.   0.   0.  -1.]\n",
      " [  0.   0.   0.  -1.  -1.  -1.   0.   0.   0.  -1.  -1.   0.   0.  -1.]\n",
      " [ -1.  -1.  -1.   0.   0.   0.  -1.  -1.  -1.  -1.  -1.   0.   0. 100.]\n",
      " [ -1.  -1.  -1.   0.   0.   0.  -1.  -1.  -1.  -1.  -1.   0.   0. 100.]\n",
      " [ -1.  -1.  -1.   0.   0.   0.  -1.  -1.  -1.  -1.  -1.   0.   0. 100.]\n",
      " [ -1.  -1.  -1.  -1.  -1.  -1.   0.   0.   0.  -1.  -1.   0.   0. 100.]\n",
      " [ -1.  -1.  -1.  -1.  -1.  -1.   0.   0.   0.  -1.  -1.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  -1.  -1. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  -1.  -1. 100.]]\n",
      "Qa-value matrix\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.0040621e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.9959375e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0368214e-01\n",
      "  0.0000000e+00 0.0000000e+00 7.9631793e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.5158619e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 5.4598313e-02 7.9381543e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [9.1569191e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.4566101e-03 0.0000000e+00 7.8830719e-01 0.0000000e+00\n",
      "  0.0000000e+00 1.6820772e-01 3.1871624e-02 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 3.6134776e-01 0.0000000e+00\n",
      "  6.3865221e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.8850688e-19 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 4.1504510e-38 7.5043477e-34 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 4.4246894e-11 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 7.5680910e-05 0.0000000e+00 3.8917605e-02 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.0229757e-01 0.0000000e+00 2.3751880e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1190228e-02]\n",
      " [0.0000000e+00 2.6878955e-19 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.8862224e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9611378e-01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "Qb-value matrix\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.3766399e-02\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6944709e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 6.3678652e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 7.0776814e-01 0.0000000e+00\n",
      "  0.0000000e+00 2.1800315e-01 7.4228622e-02 0.0000000e+00]\n",
      " [2.3271034e-02 1.7738615e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 7.9077274e-01 0.0000000e+00\n",
      "  0.0000000e+00 8.5700713e-03 0.0000000e+00 0.0000000e+00]\n",
      " [2.0437045e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 7.9562956e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.2361444e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.7689643e-02 0.0000000e+00 7.9985487e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.6009402e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.8975564e-01\n",
      "  6.1024433e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 3.2682445e-07 9.9999970e-01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 6.1017358e-01 0.0000000e+00 3.8982648e-01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.4927379e-01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 7.5072622e-01 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.4382593e-43 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 3.3172550e-33 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.1548140048980713 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> AD -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "DS normalizing...\n",
      "... train dataset\n",
      "* For test dataset\n",
      "DS normalizing...\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.030282974243164062 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.8524680137634277 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.406726\n",
       "Sentiment_Polarity        0.039954\n",
       "Sentiment_Subjectivity   -0.014062\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719660</td>\n",
       "      <td>0.724321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819807</td>\n",
       "      <td>0.852755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.548125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity\n",
       "10       1.0            0.719660                0.724321\n",
       "16       1.0            0.388889                0.000000\n",
       "20       1.0            0.388889                0.000000\n",
       "23       1.0            0.819807                0.852755\n",
       "27       1.0            0.955556                0.907407\n",
       "...      ...                 ...                     ...\n",
       "20850    1.0            0.388889                0.000000\n",
       "20919    1.0            0.962963                0.780488\n",
       "20972    1.0            0.111111                0.548125\n",
       "20998    1.0            0.388889                0.000000\n",
       "21198    1.0            0.388889                0.000000\n",
       "\n",
       "[4285 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.147\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):              0.318\n",
      "Time:                        11:43:07   Log-Likelihood:                -20541.\n",
      "No. Observations:               16676   AIC:                         4.109e+04\n",
      "Df Residuals:                   16673   BIC:                         4.111e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.4067      0.011    128.328      0.000       1.385       1.428\n",
      "Sentiment_Polarity         0.0400      0.027      1.462      0.144      -0.014       0.094\n",
      "Sentiment_Subjectivity    -0.0141      0.022     -0.643      0.520      -0.057       0.029\n",
      "==============================================================================\n",
      "Omnibus:                     4424.412   Durbin-Watson:                   1.753\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2898.747\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.065   Cond. No.                         5.90\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7090616625839601\n",
      "Regression done -- CPU time: 0.03780102729797363 seconds\n",
      "End Pipeline CPU time: 1.9210669994354248 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> LOF -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "MM normalizing...\n",
      "... train dataset\n",
      "* For test dataset\n",
      "MM normalizing...\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02966785430908203 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "with indexes: [1416, 3808, 4067, 4940, 5016, 6668, 7877, 8115, 10537, 15003, 16017, 17972, 18008, 20355, 22281, 23554, 23596, 25082, 25214, 26861, 28357, 29531, 32598, 33600, 34401, 36034, 38993, 39091, 40661, 40729]\n",
      "\n",
      "Outliers:\n",
      "         New_ID  Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "1416   0.036162            0.388889                0.000000         3   \n",
      "3808   0.099490            0.933333                0.789116         2   \n",
      "4067   0.103868            0.388889                0.000000         1   \n",
      "4940   0.124318            0.388889                0.000000         3   \n",
      "5016   0.125697            0.388889                0.000000         3   \n",
      "6668   0.169355            0.388889                0.000000         3   \n",
      "7877   0.198921            0.388889                0.000000         3   \n",
      "8115   0.206177            0.388889                0.000000         3   \n",
      "10537  0.269925            0.911111                1.000000         2   \n",
      "15003  0.393223            0.388889                0.000000         3   \n",
      "16017  0.402339            0.388889                0.000000         3   \n",
      "17972  0.461649            0.388889                0.000000         3   \n",
      "18008  0.462789            0.388889                0.000000         3   \n",
      "20355  0.518561            0.388889                0.000000         3   \n",
      "22281  0.561799            0.388889                0.000000         3   \n",
      "23554  0.581049            0.388889                0.000000         3   \n",
      "23596  0.582789            0.388889                0.000000         3   \n",
      "25082  0.607676            0.388889                0.000000         3   \n",
      "25214  0.612534            0.388889                0.000000         3   \n",
      "26861  0.645277            0.911111                1.000000         2   \n",
      "28357  0.670405            0.388889                0.000000         3   \n",
      "29531  0.706927            0.388889                0.000000         3   \n",
      "32598  0.776432            0.933333                0.789116         2   \n",
      "33600  0.784828            0.388889                0.000000         3   \n",
      "34401  0.806777            0.388889                0.000000         3   \n",
      "36034  0.850555            0.388889                0.000000         3   \n",
      "38993  0.901709            0.388889                0.000000         3   \n",
      "39091  0.905787            0.739520                0.510282         2   \n",
      "40661  0.934333            0.388889                0.000000         3   \n",
      "40729  0.936972            0.388889                0.000000         1   \n",
      "\n",
      "                                                     App  \\\n",
      "1416                                         8 Ball Pool   \n",
      "3808    Acorn TV: World-class TV from Britain and Beyond   \n",
      "4067                             Ada - Your Health Guide   \n",
      "4940                         AirBrush: Easy Photo Editor   \n",
      "5016                                              Airbnb   \n",
      "6668                                     Amazon Shopping   \n",
      "7877                               Animated Photo Editor   \n",
      "8115   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "10537                        BBW Dating & Plus Size Chat   \n",
      "15003                      Birdays â Birthday reminder   \n",
      "16017                                       Block Puzzle   \n",
      "17972                                  Bualuang mBanking   \n",
      "18008                                     Bubble Shooter   \n",
      "20355                       CNN Breaking US & World News   \n",
      "22281                       Calorie Counter - MyNetDiary   \n",
      "23554                                   Candy Crush Saga   \n",
      "23596                                   Candy Crush Saga   \n",
      "25082                                       Chase Mobile   \n",
      "25214                          ChatVideo Meet new people   \n",
      "26861                                       Clash Royale   \n",
      "28357     Colorful Glitter Neon Butterfly Keyboard Theme   \n",
      "29531                           Couch to 5K by RunDouble   \n",
      "32598                                           DStv Now   \n",
      "33600                                       Delta Dental   \n",
      "34401                     Digit Save Money Automatically   \n",
      "36034                       Dr. Panda & Toto's Treehouse   \n",
      "38993                                Easy Voice Recorder   \n",
      "39091                     Eat Fit - Diet and Health Free   \n",
      "40661                                    Equestria Girls   \n",
      "40729                                Essential Anatomy 3   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "1416   I know deal is. Phone shuts turns back I'm playing game. Keeps happening. While I'm playing big ...   \n",
      "3808   Freezes stutters. Other video I doesn't. Will retain password. I resubmit password every video I...   \n",
      "4067   Ada helped put mind ease assisting clarify symptoms. After I read suggestions, made perfect sens...   \n",
      "4940                                          I like take pictures scenery.when add oil filter boom hahaha   \n",
      "5016   I sign app. I asked I robot taken verification questions, like choosing images street signs goes...   \n",
      "6668                                                       I know latest update did. Now I can't open all.   \n",
      "7877                                                                   This amazing making funny images...   \n",
      "8115   Most recent update really screwed interface. Makes difficult get actual lists, wants add them. A...   \n",
      "10537                                                       Wonderful loves thick women â¤â¤â¤â¤â¤â¤   \n",
      "15003  Looks good. But texting via WhatsApp, Facebook, twitter option must added. Without options incom...   \n",
      "16017  Love game. Hate refresh button easily accessed. Takes long get passed high score I accidently to...   \n",
      "17972                                        Have you ever had a favorite? The good thing is through wifi.   \n",
      "18008                                  Not good. Designed force pay money trivial poorly thought gameplay.   \n",
      "20355  Works great I 66 years old need want anything complicated turn on. But viewing screen could bigg...   \n",
      "22281         Easiest way calorie count honest. Down 2lbs week since I started. Also, reliable motivating.   \n",
      "23554  My boyfriend level 376 finished level sugar crush 33 minutes still going on. still 10 moves left...   \n",
      "23596  I've playing game less week n enjoyed challenge. Only problem game like many match 3 games--get ...   \n",
      "25082  07/23/18 -Updated Update unable login. Uninstalled reinstalled, i'm able login get \"turn notific...   \n",
      "25214  Well wanna tell guys make rules dont follow. No nudity etc...then dont banned people whos showin...   \n",
      "26861  I playing game 2 years. But stop playing game twice getting good cards, specially legendary card...   \n",
      "28357  I guess cool actually I something I downloaded totally went went phone . I really really wanted ...   \n",
      "29531  I've never runner way. This helping slowly increase run time without making feel like impossible...   \n",
      "32598  Watching DSTV via Internet works fine, buffers every seconds attempting watch App. Definitely Ne...   \n",
      "33600             Takes forever load crashes almost every time. It's worked like twice whole time I've it.   \n",
      "34401  Really great, sometimes takes bit money though updated amount actually bank, otherwise fun way s...   \n",
      "36034  It reminds niece really cool I love game make free dr. Panda bus make feel really happy. From Ra...   \n",
      "38993  I compared voice recorder control bit rate sampling rate. This inferior terms size. This occupie...   \n",
      "39091                                                                              Eat Fit Awesome wanted.   \n",
      "40661  new update message Dear hasbro love game much I play lot, easy play I love it, please make new u...   \n",
      "40729  Why u treat users less While apple already version 5, stuck outdated 3rd.. even mention iyoga av...   \n",
      "\n",
      "                                                                                                       row  \n",
      "1416   3*0.3888888888888889*0.0*8BallPool*Iknowdealis.PhoneshutsturnsbackI'mplayinggame.Keepshappening....  \n",
      "3808   2*0.9333333333333333*0.7891156462585034*AcornTV:World-classTVfromBritainandBeyond*Freezesstutter...  \n",
      "4067   1*0.3888888888888889*0.0*Ada-YourHealthGuide*Adahelpedputmindeaseassistingclarifysymptoms.AfterI...  \n",
      "4940   3*0.3888888888888889*0.0*AirBrush:EasyPhotoEditor*Iliketakepicturesscenery.whenaddoilfilterboomh...  \n",
      "5016   3*0.3888888888888889*0.0*Airbnb*Isignapp.IaskedIrobottakenverificationquestions,likechoosingimag...  \n",
      "6668   3*0.3888888888888889*0.0*AmazonShopping*Iknowlatestupdatedid.NowIcan'topenall.*2825*3*0.38888888...  \n",
      "7877   3*0.3888888888888889*0.0*AnimatedPhotoEditor*Thisamazingmakingfunnyimages...*3318*3*0.3888888888...  \n",
      "8115   3*0.3888888888888889*0.0*Any.do:To-dolist,Calendar,Reminders&Planner*Mostrecentupdatereallyscrew...  \n",
      "10537  2*0.9111111111111111*1.0*BBWDating&PlusSizeChat*Wonderfullovesthickwomenâ¤â¤â¤â¤â¤â¤*4502*...  \n",
      "15003  3*0.3888888888888889*0.0*BirdaysâBirthdayreminder*Looksgood.ButtextingviaWhatsApp,Facebook,twi...  \n",
      "16017  3*0.3888888888888889*0.0*BlockPuzzle*Lovegame.Haterefreshbuttoneasilyaccessed.Takeslonggetpassed...  \n",
      "17972  3*0.3888888888888889*0.0*BualuangmBanking*Haveyoueverhadafavorite?Thegoodthingisthroughwifi.*769...  \n",
      "18008  3*0.3888888888888889*0.0*BubbleShooter*Notgood.Designedforcepaymoneytrivialpoorlythoughtgameplay...  \n",
      "20355  3*0.3888888888888889*0.0*CNNBreakingUS&WorldNews*WorksgreatI66yearsoldneedwantanythingcomplicate...  \n",
      "22281  3*0.3888888888888889*0.0*CalorieCounter-MyNetDiary*Easiestwaycaloriecounthonest.Down2lbsweeksinc...  \n",
      "23554  3*0.3888888888888889*0.0*CandyCrushSaga*Myboyfriendlevel376finishedlevelsugarcrush33minutesstill...  \n",
      "23596  3*0.3888888888888889*0.0*CandyCrushSaga*I'veplayinggamelessweeknenjoyedchallenge.Onlyproblemgame...  \n",
      "25082  3*0.3888888888888889*0.0*ChaseMobile*07/23/18-UpdatedUpdateunablelogin.Uninstalledreinstalled,i'...  \n",
      "25214  3*0.3888888888888889*0.0*ChatVideoMeetnewpeople*Wellwannatellguysmakerulesdontfollow.Nonudityetc...  \n",
      "26861  2*0.9111111111111111*1.0*ClashRoyale*Iplayinggame2years.Butstopplayinggametwicegettinggoodcards,...  \n",
      "28357  3*0.3888888888888889*0.0*ColorfulGlitterNeonButterflyKeyboardTheme*IguesscoolactuallyIsomethingI...  \n",
      "29531  3*0.3888888888888889*0.0*Couchto5KbyRunDouble*I'veneverrunnerway.Thishelpingslowlyincreaseruntim...  \n",
      "32598  2*0.9333333333333333*0.7891156462585034*DStvNow*WatchingDSTVviaInternetworksfine,bufferseverysec...  \n",
      "33600  3*0.3888888888888889*0.0*DeltaDental*Takesforeverloadcrashesalmosteverytime.It'sworkedliketwicew...  \n",
      "34401  3*0.3888888888888889*0.0*DigitSaveMoneyAutomatically*Reallygreat,sometimestakesbitmoneythoughupd...  \n",
      "36034  3*0.3888888888888889*0.0*Dr.Panda&Toto'sTreehouse*ItremindsniecereallycoolIlovegamemakefreedr.Pa...  \n",
      "38993  3*0.3888888888888889*0.0*EasyVoiceRecorder*Icomparedvoicerecordercontrolbitratesamplingrate.This...  \n",
      "39091  2*0.7395204725577672*0.5102820450296675*EatFit-DietandHealthFree*EatFitAwesomewanted.*15105*2*0....  \n",
      "40661  3*0.3888888888888889*0.0*EquestriaGirls*newupdatemessageDearhasbrolovegamemuchIplaylot,easyplayI...  \n",
      "40729  1*0.3888888888888889*0.0*EssentialAnatomy3*WhyutreatuserslessWhileapplealreadyversion5,stuckoutd...  \n",
      "\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "with indexes: [1537, 1771, 1845, 2223, 3218, 4018, 4598, 4829, 7570, 7640, 9098, 9435, 9533, 9736, 9820, 10478, 11360, 11937, 12340, 13045, 14335, 14341, 14752, 16129, 16947, 17046, 17167, 17994, 18481, 18645, 19767, 20604]\n",
      "\n",
      "Outliers:\n",
      "         New_ID  Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "1537   0.075397            0.388889                0.000000         3   \n",
      "1771   0.095238            0.388889                0.000000         1   \n",
      "1845   0.099907            0.388889                0.000000         3   \n",
      "2223   0.105742            0.388889                0.000000         3   \n",
      "3218   0.154062            0.388889                0.000000         3   \n",
      "4018   0.185341            0.388889                0.000000         3   \n",
      "4598   0.214052            0.388889                0.000000         1   \n",
      "4829   0.229225            0.388889                0.000000         3   \n",
      "7570   0.354575            0.388889                0.000000         3   \n",
      "7640   0.360878            0.388889                0.000000         3   \n",
      "9098   0.427871            0.388889                0.000000         3   \n",
      "9435   0.447712            1.000000                1.000000         2   \n",
      "9533   0.454949            0.388889                0.000000         3   \n",
      "9736   0.464286            0.388889                0.000000         3   \n",
      "9820   0.468721            0.388889                0.000000         3   \n",
      "10478  0.502801            0.388889                0.000000         1   \n",
      "11360  0.554388            0.388889                0.000000         1   \n",
      "11937  0.582400            0.388889                0.000000         3   \n",
      "12340  0.610644            0.388889                0.000000         3   \n",
      "13045  0.658964            0.388889                0.000000         1   \n",
      "14335  0.697012            0.388889                0.000000         3   \n",
      "14341  0.697479            0.388889                0.000000         1   \n",
      "14752  0.729925            0.388889                0.000000         3   \n",
      "16129  0.768908            0.388889                0.000000         3   \n",
      "16947  0.815359            0.933333                0.790123         2   \n",
      "17046  0.824930            0.388889                0.000000         1   \n",
      "17167  0.831933            0.388889                0.000000         3   \n",
      "17994  0.874183            0.388889                0.000000         3   \n",
      "18481  0.891457            0.388889                0.000000         3   \n",
      "18645  0.902194            0.388889                0.000000         3   \n",
      "19767  0.951914            0.388889                0.000000         3   \n",
      "20604  0.996732            0.388889                0.000000         3   \n",
      "\n",
      "                                                      App  \\\n",
      "1537                                          8 Ball Pool   \n",
      "1771                         8fit Workouts & Meal Planner   \n",
      "1845                      95Live -SG#1 Live Streaming App   \n",
      "2223                         A+ Gallery - Photos & Videos   \n",
      "3218                             ASUS Cover for ZenFone 2   \n",
      "4018                              Ada - Your Health Guide   \n",
      "4598                                              Agar.io   \n",
      "4829                                          Air Traffic   \n",
      "7570                                  Angry Birds Classic   \n",
      "7640                                  Angry Birds Classic   \n",
      "9098                                             Arrow.io   \n",
      "9435                          Asteroids 3D live wallpaper   \n",
      "9533        AutoScout24 Switzerland â Find your new car   \n",
      "9736                              Aviary Effects: Classic   \n",
      "9820                                                 Azar   \n",
      "10478                         BBW Dating & Plus Size Chat   \n",
      "11360                                  Baby Name Together   \n",
      "11937                                         Bad Piggies   \n",
      "12340                    Bangla Newspaper â Prothom Alo   \n",
      "13045                           Bathroom Decorating Ideas   \n",
      "14335                                 Best Wallpapers QHD   \n",
      "14341                                 Best Wallpapers QHD   \n",
      "14752  BigOven Recipes, Meal Planner, Grocery List & More   \n",
      "16129                      Blogaway for Android (Blogger)   \n",
      "16947                                          Bowmasters   \n",
      "17046                                          Bowmasters   \n",
      "17167                                          Bowmasters   \n",
      "17994                                   Bualuang mBanking   \n",
      "18481                                   Buienradar - weer   \n",
      "18645                        Bukalapak - Jual Beli Online   \n",
      "19767   CBS Sports App - Scores, News, Stats & Watch Live   \n",
      "20604                                           CWT To Go   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "1537   Takes money different rates 11700 coins. I went 2500 game lost round come moneys gone. Also offe...   \n",
      "1771                      love app! easy straight forward, tailor fit schedule! Meal plans amazing tasty!!   \n",
      "1845                                                                                                    ok   \n",
      "2223                                                       It was very good that it was better than simple   \n",
      "3218   Can't view emails. , Need option customise appearance colour. , Need show what's pop Asus cover ...   \n",
      "4018   This built depth research great branching questions answer get possible answers. It asks symptom...   \n",
      "4598                                    Fix lag add private servers others players fun without interrupted   \n",
      "4829                                             Love planes, seeing routes take get airport, fascinating.   \n",
      "7570   This game cool, challenging challenging games make want throw phone window, birds Rovio gave som...   \n",
      "7640   Is really good game wasting time. I like able buy using real money aspect games using. Too easy ...   \n",
      "9098                            I uninstalled game month, I installed back old account gone...help fix. TQ   \n",
      "9435                                                           They charge like 2 bucks it.its really cool   \n",
      "9533                                                                                        Thank you good   \n",
      "9736   Best use. Wouldn't waste time others. I Photo Editor also. You disappointed. I knew nothing Avia...   \n",
      "9820   I nothing,I good person gentle, play report u bad of me, hope u help restart account , thank YOU...   \n",
      "10478                          For now, proving great app, weeks I'd know I'll let stars remain five less.   \n",
      "11360                                                                               Too many interruptions   \n",
      "11937  The game's good road el porkador switches glitch. I can't even get past level 18. I spent coins ...   \n",
      "12340                                                                         Too much ads . Too much ads.   \n",
      "13045                                                                                           Waste time   \n",
      "14335                                            This best aap I ever found .........everyone must install   \n",
      "14341                                                                                        good pictures   \n",
      "14752  Unable household share option. Please fix 8-2-18 Update: In order add and/or except ppl househol...   \n",
      "16129                                               Won't publish post pictures. Makes useless please sort   \n",
      "16947  I like game alot. It's fun competitive. I local online multiplayer different game modes. Huge se...   \n",
      "17046                                     I know I said lot sure lot times someone tell legendary upgrades   \n",
      "17167  Really like game far. Great gameplay lots fun. Edit: I took away star constant asking rate even ...   \n",
      "17994                                                                                        All day long!   \n",
      "18481       I need radar map. Lost days, found answer little upper right arrows. And works again. Perfect.   \n",
      "18645  from the cellphone shake event if you go to the main menu of purchase, how come back to the even...   \n",
      "19767  This great recently. Now locks closes every single time open it. I've sent feedback couple weeks...   \n",
      "20604                                                                     Does even load yr trips tickets.   \n",
      "\n",
      "                                                                                                       row  \n",
      "1537   3*0.3888888888888889*0.0*8BallPool*Takesmoneydifferentrates11700coins.Iwent2500gamelostroundcome...  \n",
      "1771   1*0.3888888888888889*0.0*8fitWorkouts&MealPlanner*loveapp!easystraightforward,tailorfitschedule!...  \n",
      "1845   3*0.3888888888888889*0.0*95Live-SG#1LiveStreamingApp*ok*429*3*0.3888888888888889*0.0*95Live-SG#1...  \n",
      "2223   3*0.3888888888888889*0.0*A+Gallery-Photos&Videos*Itwasverygoodthatitwasbetterthansimple*454*3*0....  \n",
      "3218   3*0.3888888888888889*0.0*ASUSCoverforZenFone2*Can'tviewemails.,Needoptioncustomiseappearancecolo...  \n",
      "4018   3*0.3888888888888889*0.0*Ada-YourHealthGuide*Thisbuiltdepthresearchgreatbranchingquestionsanswer...  \n",
      "4598   1*0.3888888888888889*0.0*Agar.io*Fixlagaddprivateserversothersplayersfunwithoutinterrupted*918*1...  \n",
      "4829   3*0.3888888888888889*0.0*AirTraffic*Loveplanes,seeingroutestakegetairport,fascinating.*983*3*0.3...  \n",
      "7570   3*0.3888888888888889*0.0*AngryBirdsClassic*Thisgamecool,challengingchallenginggamesmakewantthrow...  \n",
      "7640   3*0.3888888888888889*0.0*AngryBirdsClassic*Isreallygoodgamewastingtime.Ilikeablebuyusingrealmone...  \n",
      "9098   3*0.3888888888888889*0.0*Arrow.io*Iuninstalledgamemonth,Iinstalledbackoldaccountgone...helpfix.T...  \n",
      "9435   2*1.0*1.0*Asteroids3Dlivewallpaper*Theychargelike2bucksit.itsreallycool*1919*2*1.0*1.0*Asteroids...  \n",
      "9533   3*0.3888888888888889*0.0*AutoScout24SwitzerlandâFindyournewcar*Thankyougood*1950*3*0.388888888...  \n",
      "9736   3*0.3888888888888889*0.0*AviaryEffects:Classic*Bestuse.Wouldn'twastetimeothers.IPhotoEditoralso....  \n",
      "9820   3*0.3888888888888889*0.0*Azar*Inothing,Igoodpersongentle,playreportubadofme,hopeuhelprestartacco...  \n",
      "10478  1*0.3888888888888889*0.0*BBWDating&PlusSizeChat*Fornow,provinggreatapp,weeksI'dknowI'llletstarsr...  \n",
      "11360  1*0.3888888888888889*0.0*BabyNameTogether*Toomanyinterruptions*2376*1*0.3888888888888889*0.0*Bab...  \n",
      "11937  3*0.3888888888888889*0.0*BadPiggies*Thegame'sgoodroadelporkadorswitchesglitch.Ican'tevengetpastl...  \n",
      "12340  3*0.3888888888888889*0.0*BanglaNewspaperâProthomAlo*Toomuchads.Toomuchads.*2617*3*0.3888888888...  \n",
      "13045  1*0.3888888888888889*0.0*BathroomDecoratingIdeas*Wastetime*2824*1*0.3888888888888889*0.0*Bathroo...  \n",
      "14335  3*0.3888888888888889*0.0*BestWallpapersQHD*ThisbestaapIeverfound.........everyonemustinstall*298...  \n",
      "14341  1*0.3888888888888889*0.0*BestWallpapersQHD*goodpictures*2989*1*0.3888888888888889*0.0*BestWallpa...  \n",
      "14752  3*0.3888888888888889*0.0*BigOvenRecipes,MealPlanner,GroceryList&More*Unablehouseholdshareoption....  \n",
      "16129  3*0.3888888888888889*0.0*BlogawayforAndroid(Blogger)*Won'tpublishpostpictures.Makesuselessplease...  \n",
      "16947  2*0.9333333333333333*0.7901234567901234*Bowmasters*Ilikegamealot.It'sfuncompetitive.Ilocalonline...  \n",
      "17046  1*0.3888888888888889*0.0*Bowmasters*IknowIsaidlotsurelottimessomeonetelllegendaryupgrades*3535*1...  \n",
      "17167  3*0.3888888888888889*0.0*Bowmasters*Reallylikegamefar.Greatgameplaylotsfun.Edit:Itookawaystarcon...  \n",
      "17994  3*0.3888888888888889*0.0*BualuangmBanking*Alldaylong!*3746*3*0.3888888888888889*0.0*BualuangmBan...  \n",
      "18481  3*0.3888888888888889*0.0*Buienradar-weer*Ineedradarmap.Lostdays,foundanswerlittleupperrightarrow...  \n",
      "18645  3*0.3888888888888889*0.0*Bukalapak-JualBeliOnline*fromthecellphoneshakeeventifyougotothemainmenu...  \n",
      "19767  3*0.3888888888888889*0.0*CBSSportsApp-Scores,News,Stats&WatchLive*Thisgreatrecently.Nowlocksclos...  \n",
      "20604  3*0.3888888888888889*0.0*CWTToGo*Doesevenloadyrtripstickets.*4271*3*0.3888888888888889*0.0*CWTTo...  \n",
      "\n",
      "Outlier detection and removal done -- CPU time: 0.29216718673706055 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.373357\n",
       "New_ID                    0.053910\n",
       "Sentiment_Polarity        0.040714\n",
       "Sentiment_Subjectivity   -0.006756\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>New_ID</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.818172</td>\n",
       "      <td>0.855967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.790123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.516755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4253 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const    New_ID  Sentiment_Polarity  Sentiment_Subjectivity\n",
       "10       1.0  0.000000            0.715793                0.735972\n",
       "16       1.0  0.000233            0.388889                0.000000\n",
       "20       1.0  0.000467            0.388889                0.000000\n",
       "23       1.0  0.000700            0.818172                0.855967\n",
       "27       1.0  0.000934            0.955556                0.907407\n",
       "...      ...       ...                 ...                     ...\n",
       "20850    1.0  0.999066            0.388889                0.000000\n",
       "20919    1.0  0.999300            0.962963                0.790123\n",
       "20972    1.0  0.999533            0.148148                0.516755\n",
       "20998    1.0  0.999767            0.388889                0.000000\n",
       "21198    1.0  1.000000            0.388889                0.000000\n",
       "\n",
       "[4253 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4253, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4253, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.673\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0457\n",
      "Time:                        11:43:07   Log-Likelihood:                -20496.\n",
      "No. Observations:               16646   AIC:                         4.100e+04\n",
      "Df Residuals:                   16642   BIC:                         4.103e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3734      0.018     75.619      0.000       1.338       1.409\n",
      "New_ID                     0.0539      0.022      2.422      0.015       0.010       0.098\n",
      "Sentiment_Polarity         0.0407      0.029      1.426      0.154      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0068      0.019     -0.353      0.724      -0.044       0.031\n",
      "==============================================================================\n",
      "Omnibus:                     4370.755   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2892.894\n",
      "Skew:                          -0.909   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.069   Cond. No.                         6.65\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7098646330792925\n",
      "Regression done -- CPU time: 0.04136300086975098 seconds\n",
      "End Pipeline CPU time: 0.3635399341583252 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> IQR -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "ZS normalizing... \n",
      "... train dataset\n",
      "* For test dataset\n",
      "ZS normalizing... \n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.022320985794067383 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02631688117980957 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.418326\n",
       "Sentiment_Polarity        0.010473\n",
       "Sentiment_Subjectivity   -0.002271\n",
       "New_ID                    0.015781\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807272</td>\n",
       "      <td>0.918389</td>\n",
       "      <td>-1.731445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.697853</td>\n",
       "      <td>1.250214</td>\n",
       "      <td>0.995864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191978</td>\n",
       "      <td>0.798182</td>\n",
       "      <td>0.996672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.986172</td>\n",
       "      <td>-1.730636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.986172</td>\n",
       "      <td>-1.729828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.986172</td>\n",
       "      <td>0.991822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777633</td>\n",
       "      <td>0.774141</td>\n",
       "      <td>0.992630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.568022</td>\n",
       "      <td>1.362034</td>\n",
       "      <td>0.993439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.465994</td>\n",
       "      <td>-0.986172</td>\n",
       "      <td>0.994247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.616249</td>\n",
       "      <td>1.101122</td>\n",
       "      <td>0.995055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity    New_ID\n",
       "10       1.0            0.807272                0.918389 -1.731445\n",
       "16396    1.0            1.697853                1.250214  0.995864\n",
       "16398    1.0            0.191978                0.798182  0.996672\n",
       "16       1.0           -0.465994               -0.986172 -1.730636\n",
       "20       1.0           -0.465994               -0.986172 -1.729828\n",
       "...      ...                 ...                     ...       ...\n",
       "16364    1.0           -0.465994               -0.986172  0.991822\n",
       "16366    1.0            0.777633                0.774141  0.992630\n",
       "16372    1.0            1.568022                1.362034  0.993439\n",
       "16377    1.0           -0.465994               -0.986172  0.994247\n",
       "16378    1.0           -1.616249                1.101122  0.995055\n",
       "\n",
       "[4285 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.746\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0414\n",
      "Time:                        11:43:07   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16672   BIC:                         4.111e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.4183      0.006    220.875      0.000       1.406       1.431\n",
      "Sentiment_Polarity         0.0105      0.007      1.429      0.153      -0.004       0.025\n",
      "Sentiment_Subjectivity    -0.0023      0.007     -0.310      0.757      -0.017       0.012\n",
      "New_ID                     0.0158      0.006      2.457      0.014       0.003       0.028\n",
      "==============================================================================\n",
      "Omnibus:                     4396.236   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.242\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                         1.69\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7097725841264618\n",
      "Regression done -- CPU time: 0.037102699279785156 seconds\n",
      "End Pipeline CPU time: 0.0860738754272461 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> IQR -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "Best features to keep ['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.018774032592773438 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.0291898250579834 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.372401\n",
       "Sentiment_Polarity        0.040811\n",
       "Sentiment_Subjectivity   -0.005926\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>3376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708183</td>\n",
       "      <td>0.680230</td>\n",
       "      <td>3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>3372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16396    1.0            0.944444                0.864198    3375\n",
       "16398    1.0            0.557819                0.689521    3376\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "...      ...                 ...                     ...     ...\n",
       "16364    1.0            0.388889                0.000000    3370\n",
       "16366    1.0            0.708183                0.680230    3371\n",
       "16372    1.0            0.911111                0.907407    3372\n",
       "16377    1.0            0.388889                0.000000    3373\n",
       "16378    1.0            0.093567                0.806584    3374\n",
       "\n",
       "[4285 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.746\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0414\n",
      "Time:                        11:43:08   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16672   BIC:                         4.111e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3724      0.018     75.599      0.000       1.337       1.408\n",
      "Sentiment_Polarity         0.0408      0.029      1.429      0.153      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0059      0.019     -0.310      0.757      -0.043       0.032\n",
      "New_ID                  3.278e-06   1.33e-06      2.457      0.014    6.63e-07    5.89e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4396.236   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.242\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                     4.87e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.87e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7085140234413241\n",
      "Regression done -- CPU time: 0.037689924240112305 seconds\n",
      "End Pipeline CPU time: 0.08731889724731445 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> IQR -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "Correlation matrix\n",
      "                        Sentiment_Polarity  Sentiment_Subjectivity    New_ID\n",
      "Sentiment_Polarity                1.000000                0.481869 -0.004953\n",
      "Sentiment_Subjectivity            0.481869                1.000000 -0.006178\n",
      "New_ID                           -0.004953               -0.006178  1.000000\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "List of numerical variables to be keep\n",
      "['Sentiment_Polarity', 'New_ID']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.025055885314941406 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.03333306312561035 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                 1.372323\n",
       "Sentiment_Polarity    0.036547\n",
       "New_ID                0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>New_ID</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3376</td>\n",
       "      <td>0.557819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3370</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3371</td>\n",
       "      <td>0.708183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3372</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3373</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3374</td>\n",
       "      <td>0.093567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  New_ID  Sentiment_Polarity\n",
       "10       1.0       1            0.715793\n",
       "16396    1.0    3375            0.944444\n",
       "16398    1.0    3376            0.557819\n",
       "16       1.0       2            0.388889\n",
       "20       1.0       3            0.388889\n",
       "...      ...     ...                 ...\n",
       "16364    1.0    3370            0.388889\n",
       "16366    1.0    3371            0.708183\n",
       "16372    1.0    3372            0.911111\n",
       "16377    1.0    3373            0.388889\n",
       "16378    1.0    3374            0.093567\n",
       "\n",
       "[4285 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     4.072\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0171\n",
      "Time:                        11:43:08   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16673   BIC:                         4.110e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  1.3723      0.018     75.604      0.000       1.337       1.408\n",
      "Sentiment_Polarity     0.0365      0.025      1.461      0.144      -0.012       0.086\n",
      "New_ID               3.28e-06   1.33e-06      2.459      0.014    6.65e-07    5.89e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4397.425   Durbin-Watson:                   1.753\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.184\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                     4.32e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.32e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 8176.870637302701\n",
      "Regression done -- CPU time: 0.03790736198425293 seconds\n",
      "End Pipeline CPU time: 0.09842705726623535 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> IQR -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.033667802810668945 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.372401\n",
       "Sentiment_Polarity        0.040811\n",
       "Sentiment_Subjectivity   -0.005926\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>3376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708183</td>\n",
       "      <td>0.680230</td>\n",
       "      <td>3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>3372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16396    1.0            0.944444                0.864198    3375\n",
       "16398    1.0            0.557819                0.689521    3376\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "...      ...                 ...                     ...     ...\n",
       "16364    1.0            0.388889                0.000000    3370\n",
       "16366    1.0            0.708183                0.680230    3371\n",
       "16372    1.0            0.911111                0.907407    3372\n",
       "16377    1.0            0.388889                0.000000    3373\n",
       "16378    1.0            0.093567                0.806584    3374\n",
       "\n",
       "[4285 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.746\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0414\n",
      "Time:                        11:43:08   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16672   BIC:                         4.111e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3724      0.018     75.599      0.000       1.337       1.408\n",
      "Sentiment_Polarity         0.0408      0.029      1.429      0.153      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0059      0.019     -0.310      0.757      -0.043       0.032\n",
      "New_ID                  3.278e-06   1.33e-06      2.457      0.014    6.63e-07    5.89e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4396.236   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.242\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                     4.87e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.87e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7085140234413241\n",
      "Regression done -- CPU time: 0.04060792922973633 seconds\n",
      "End Pipeline CPU time: 0.07451319694519043 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> Tree -> IQR -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "with indexes: [0, 1, 37, 49, 56, 66, 72, 73, 79, 94, 98, 105, 106, 111, 114, 116, 120, 124, 126, 134, 135, 146, 147, 152, 158, 169, 174, 180, 198, 203, 219, 230, 235, 263, 276, 280, 281, 286, 291, 292, 310, 311, 323, 325, 328, 341, 356, 358, 360, 361, 372, 373, 375, 381, 382, 385, 391, 394, 395, 398, 410, 424, 431, 434, 440, 460, 462, 463, 467, 482, 494, 498, 500, 505, 506, 510, 514, 520, 524, 525, 527, 542, 544, 547, 560, 570, 571, 574, 579, 583, 584, 585, 586, 595, 613, 618, 631, 633, 652, 654, 666, 668, 680, 684, 693, 699, 701, 708, 710, 717, 888, 894, 948, 979, 982, 1008, 1023, 1034, 1041, 1077, 1091, 1187, 1193, 1209, 1221, 1226, 1252, 1264, 1273, 1297, 1347, 1350, 1352, 1371, 1390, 1398, 1408, 1417, 1430, 1435, 1437, 1441, 1450, 1454, 1469, 1471, 1474, 1477, 1485, 1489, 1494, 1495, 1502, 1509, 1540, 1556, 1562, 1564, 1578, 1588, 1589, 1597, 1600, 1602, 1610, 1618, 1619, 1622, 1630, 1632, 1634, 1638, 1646, 1649, 1651, 1662, 1663, 1664, 1704, 1705, 1723, 1726, 1738, 1740, 1748, 1752, 1760, 1769, 1784, 1800, 1805, 1808, 1810, 1815, 1819, 1820, 1824, 1830, 1832, 1836, 1846, 1860, 1867, 1868, 1871, 1884, 2048, 2055, 2057, 2063, 2075, 2085, 2098, 2137, 2139, 2151, 2158, 2168, 2180, 2196, 2207, 2210, 2249, 2256, 2259, 2276, 2293, 2308, 2309, 2315, 2324, 2325, 2329, 2336, 2340, 2343, 2345, 2347, 2356, 2360, 2362, 2380, 2387, 2388, 2390, 2398, 2405, 2410, 2415, 2418, 2419, 2426, 2427, 2428, 2431, 2437, 2460, 2469, 2472, 2476, 2502, 2503, 2510, 2512, 2528, 2529, 2534, 2535, 2537, 2539, 2548, 2554, 2558, 2565, 2570, 2571, 2577, 2581, 2583, 2585, 2594, 2596, 2599, 2603, 2605, 2621, 2623, 2628, 2636, 2652, 2661, 2816, 2817, 2853, 2855, 2858, 2867, 2870, 2884, 2885, 2889, 2900, 2902, 2905, 2921, 2926, 2931, 2936, 2952, 2957, 2960, 2961, 2963, 2997, 3002, 3011, 3017, 3020, 3024, 3032, 3034, 3035, 3052, 3060, 3062, 3084, 3110, 3119, 3123, 3130, 3132, 3136, 3137, 3139, 3141, 3142, 3149, 3154, 3162, 3163, 3170, 3182, 3191, 3193, 3195, 3199, 3208, 3210, 3344, 3354, 3398, 3406, 3417, 3434, 3443, 3445, 3447, 3461, 3487, 3499, 3513, 3528, 3530, 3533, 3544, 3547, 3549, 3553, 3557, 3562, 3573, 3583, 3590, 3595, 3597, 3605, 3609, 3612, 3618, 3619, 3621, 3622, 3638, 3667, 3677, 3679, 3680, 3681, 3683, 3684, 3688, 3693, 3695, 3713, 3732, 3751, 3756, 3758, 3762, 3768, 3770, 3773, 3774, 3782, 3783, 3795, 3802, 3808, 3816, 3821, 3842, 3955, 3966, 3968, 3973, 3996, 3999, 4003, 4009, 4036, 4049, 4051, 4052, 4053, 4054, 4061, 4072, 4086, 4099, 4107, 4112, 4115, 4128, 4130, 4134, 4142, 4154, 4161, 4167, 4172, 4178, 4186, 4198, 4204, 4213, 4215, 4220, 4245, 4248, 4256, 4257, 4258, 4264, 4270, 4271, 4276, 4278, 4292, 4319, 4322, 4351, 4371, 4483, 4485, 4499, 4526, 4535, 4537, 4543, 4547, 4562, 4570, 4572, 4583, 4589, 4591, 4592, 4593, 4600, 4625, 4626, 4635, 4663, 4670, 4678, 4697, 4715, 4734, 4746, 4747, 4752, 4755, 4757, 4765, 4770, 4774, 4777, 4812, 4836, 4873, 4895, 4968, 4969, 4973, 4991, 5022, 5036, 5038, 5070, 5103, 5106, 5113, 5119, 5124, 5126, 5158, 5162, 5165, 5168, 5183, 5185, 5187, 5189, 5208, 5210, 5218, 5219, 5220, 5229, 5236, 5250, 5253, 5254, 5259, 5266, 5267, 5275, 5297, 5304, 5306, 5308, 5346, 5347, 5349, 5350, 5356, 5364, 5373, 5378, 5385, 5386, 5396, 5401, 5410, 5414, 5417, 5429, 5531, 5538, 5544, 5547, 5568, 5574, 5581, 5588, 5590, 5591, 5600, 5604, 5610, 5617, 5631, 5640, 5650, 5653, 5657, 5675, 5678, 5685, 5692, 5701, 5704, 5714, 5716, 5718, 5732, 5746, 5749, 5754, 5758, 5763, 5769, 5770, 5780, 5789, 5796, 5805, 5811, 5823, 5828, 5837, 5844, 5847, 5848, 5852, 5863, 5865, 5866, 5874, 5877, 5884, 5885, 5888, 5898, 5932, 6062, 6070, 6080, 6081, 6106, 6114, 6117, 6130, 6134, 6139, 6141, 6145, 6146, 6150, 6176, 6190, 6195, 6205, 6208, 6216, 6230, 6235, 6244, 6247, 6248, 6261, 6263, 6265, 6270, 6278, 6290, 6291, 6292, 6297, 6305, 6306, 6312, 6319, 6338, 6341, 6349, 6357, 6374, 6375, 6389, 6398, 6414, 6423, 6427, 6438, 6444, 6449, 6471, 6493, 6503, 6507, 6655, 6679, 6691, 6701, 6705, 6730, 6733, 6735, 6751, 6773, 6786, 6788, 6796, 6806, 6811, 6828, 6829, 6831, 6833, 6847, 6849, 6852, 6855, 6856, 6861, 6867, 6874, 6875, 6878, 6887, 6888, 6914, 6931, 6932, 6933, 6946, 6954, 6956, 6957, 6962, 6968, 6969, 6973, 6976, 6985, 6993, 6998, 7007, 7021, 7022, 7026, 7031, 7047, 7049, 7063, 7064, 7089, 7095, 7101, 7106, 7107, 7110, 7125, 7131, 7134, 7153, 7171, 7175, 7314, 7327, 7344, 7347, 7357, 7361, 7364, 7370, 7383, 7385, 7388, 7392, 7397, 7398, 7405, 7412, 7424, 7430, 7439, 7445, 7460, 7463, 7469, 7471, 7494, 7512, 7513, 7517, 7523, 7524, 7542, 7544, 7546, 7549, 7554, 7560, 7584, 7591, 7604, 7605, 7610, 7615, 7621, 7626, 7627, 7633, 7635, 7641, 7644, 7649, 7653, 7661, 7674, 7679, 7684, 7687, 7702, 7711, 7719, 7735, 7835, 7841, 7853, 7868, 7871, 7883, 7886, 7890, 7903, 7918, 7936, 7939, 7947, 7958, 7981, 7986, 7993, 7998, 8002, 8005, 8010, 8012, 8017, 8030, 8031, 8035, 8036, 8039, 8051, 8058, 8064, 8068, 8077, 8079, 8097, 8107, 8108, 8114, 8117, 8122, 8128, 8131, 8132, 8133, 8139, 8144, 8145, 8172, 8174, 8176, 8182, 8184, 8186, 8228, 8230, 8264, 8345, 8350, 8352, 8353, 8383, 8385, 8415, 8420, 8421, 8445, 8451, 8453, 8455, 8473, 8475, 8484, 8505, 8514, 8516, 8527, 8538, 8540, 8542, 8555, 8560, 8573, 8577, 8581, 8585, 8587, 8602, 8605, 8607, 8609, 8616, 8630, 8631, 8632, 8636, 8648, 8653, 8665, 8668, 8677, 8693, 8705, 8722, 8731, 8743, 8771, 8779, 8800, 8841, 8847, 8850, 8867, 8879, 8893, 8903, 8904, 8924, 8927, 8928, 8939, 8954, 8958, 8964, 8981, 8986, 8995, 9005, 9044, 9049, 9066, 9071, 9073, 9074, 9075, 9076, 9080, 9081, 9086, 9094, 9099, 9103, 9114, 9116, 9125, 9131, 9136, 9137, 9146, 9147, 9149, 9161, 9167, 9184, 9198, 9201, 9212, 9229, 9231, 9237, 9252, 9254, 9281, 9288, 9291, 9301, 9334, 9341, 9350, 9363, 9385, 9395, 9410, 9417, 9427, 9450, 9460, 9471, 9477, 9481, 9495, 9498, 9501, 9518, 9519, 9523, 9542, 9600, 9625, 9640, 9643, 9662, 9670, 9679, 9689, 9690, 9705, 9724, 9728, 9735, 9745, 9747, 9752, 9753, 9755, 9763, 9766, 9787, 9795, 9797, 9799, 9801, 9802, 9808, 9815, 9823, 9825, 9830, 9831, 9839, 9844, 9845, 9850, 9856, 9859, 9866, 9871, 9873, 9878, 9882, 9891, 9901, 9902, 9920, 9927, 9928, 10017, 10019, 10031, 10049, 10051, 10095, 10096, 10098, 10119, 10128, 10130, 10132, 10163, 10189, 10194, 10195, 10197, 10202, 10228, 10229, 10243, 10254, 10260, 10261, 10272, 10277, 10289, 10291, 10294, 10301, 10327, 10328, 10339, 10348, 10355, 10367, 10368, 10370, 10376, 10378, 10388, 10396, 10401, 10404, 10406, 10408, 10415, 10417, 10421, 10429, 10434, 10437, 10443, 10450, 10459, 10467, 10469, 10484, 10490, 10492, 10495, 10497, 10498, 10508, 10510, 10526, 10529, 10531, 10537, 10542, 10557, 10572, 10577, 10582, 10585, 10589, 10594, 10596, 10598, 10606, 10614, 10627, 10635, 10646, 10658, 10660, 10666, 10669, 10671, 10673, 10674, 10683, 10686, 10702, 10721, 10728, 10729, 10731, 10749, 10753, 10755, 10762, 10785, 10786, 10788, 10795, 10798, 10805, 10817, 10818, 10835, 10836, 10841, 10843, 10857, 10860, 10862, 10863, 10866, 10868, 10869, 10872, 10877, 10878, 10893, 10902, 10905, 10933, 10934, 10940, 10942, 10944, 10949, 10959, 10988, 10994, 10996, 11007, 11032, 11041, 11097, 11105, 11129, 11150, 11168, 11186, 11191, 11216, 11219, 11220, 11226, 11232, 11238, 11247, 11254, 11255, 11256, 11262, 11273, 11274, 11276, 11284, 11286, 11287, 11290, 11299, 11305, 11316, 11322, 11324, 11325, 11335, 11357, 11364, 11378, 11383, 11384, 11396, 11409, 11410, 11421, 11423, 11434, 11437, 11442, 11466, 11486, 11494, 11495, 11505, 11516, 11526, 11529, 11532, 11534, 11539, 11540, 11547, 11659, 11670, 11687, 11693, 11718, 11719, 11726, 11736, 11756, 11773, 11779, 11787, 11793, 11796, 11798, 11808, 11809, 11814, 11830, 11833, 11837, 11844, 11850, 11851, 11852, 11857, 11863, 11865, 11890, 11895, 11897, 11899, 11904, 11907, 11910, 11911, 11917, 11932, 11955, 11957, 11967, 11970, 11972, 11978, 11980, 11985, 11986, 11990, 12002, 12005, 12027, 12032, 12045, 12047, 12053, 12056, 12057, 12068, 12082, 12085, 12100, 12101, 12108, 12116, 12121, 12127, 12129, 12134, 12135, 12136, 12138, 12141, 12142, 12153, 12171, 12172, 12174, 12185, 12187, 12189, 12195, 12196, 12204, 12216, 12227, 12235, 12254, 12264, 12272, 12273, 12275, 12277, 12278, 12281, 12286, 12307, 12309, 12311, 12314, 12325, 12337, 12341, 12347, 12356, 12363, 12364, 12365, 12366, 12368, 12374, 12378, 12388, 12394, 12395, 12400, 12416, 12418, 12424, 12429, 12447, 12448, 12463, 12465, 12523, 12527, 12629, 12651, 12655, 12682, 12683, 12691, 12708, 12709, 12711, 12712, 12717, 12719, 12720, 12724, 12728, 12735, 12749, 12760, 12763, 12768, 12775, 12777, 12781, 12789, 12790, 12793, 12801, 12804, 12815, 12818, 12824, 12827, 12836, 12838, 12845, 12878, 12879, 12890, 12891, 12897, 12899, 12901, 12917, 12926, 12928, 12930, 12932, 12937, 12958, 12962, 12966, 12977, 12980, 12984, 12987, 13013, 13018, 13026, 13027, 13029, 13041, 13042, 13050, 13053, 13055, 13060, 13075, 13082, 13083, 13100, 13109, 13120, 13122, 13127, 13133, 13157, 13173, 13174, 13182, 13186, 13191, 13192, 13195, 13210, 13225, 13227, 13229, 13248, 13254, 13258, 13263, 13265, 13295, 13296, 13303, 13306, 13329, 13332, 13338, 13339, 13348, 13364, 13382, 13393, 13394, 13400, 13406, 13410, 13431, 13432, 13450, 13475, 13477, 13478, 13482, 13484, 13486, 13490, 13505, 14080, 14299, 14308, 14311, 14327, 14329, 14331, 14338, 14347, 14352, 14356, 14367, 14368, 14370, 14371, 14375, 14383, 14387, 14392, 14396, 14405, 14433, 14439, 14451, 14456, 14457, 14460, 14469, 14483, 14486, 14493, 14494, 14502, 14520, 14529, 14540, 14554, 14557, 14560, 14563, 14578, 14581, 14582, 14585, 14588, 14589, 14590, 14593, 14611, 14619, 14626, 14629, 14654, 14659, 14664, 14665, 14669, 14670, 14673, 14674, 14676, 14677, 14682, 14684, 14691, 14703, 14704, 14705, 14716, 14720, 14747, 14748, 14766, 14772, 14774, 14781, 14793, 14794, 14804, 14805, 14807, 14812, 14824, 14836, 14849, 14856, 14858, 14860, 14866, 14867, 14877, 14887, 14896, 14900, 14902, 14904, 14908, 14909, 14914, 14916, 14917, 14918, 14929, 14932, 14934, 14940, 14942, 14945, 14948, 14955, 14958, 14960, 14966, 14976, 14978, 14994, 15013, 15017, 15018, 15019, 15025, 15058, 15063, 15065, 15083, 15086, 15088, 15110, 15884, 15888, 15889, 15894, 15895, 15897, 15932, 15965, 15970, 15974, 15995, 15997, 15998, 16005, 16007, 16008, 16020, 16031, 16034, 16035, 16041, 16050, 16051, 16059, 16060, 16068, 16078, 16092, 16097, 16102, 16114, 16123, 16125, 16138, 16142, 16167, 16175, 16177, 16187, 16195, 16210, 16212, 16224, 16226, 16227, 16229, 16233, 16234, 16240, 16244, 16253, 16260, 16264, 16274, 16276, 16279, 16281, 16282, 16290, 16301, 16302, 16304, 16307, 16324, 16338, 16346, 16347, 16352, 16369, 16373, 16380, 16382, 16384, 16387, 16397, 16401, 16403, 16414, 16416, 16420, 16421, 16423, 16424, 16437, 16438, 16440, 16444, 16446, 16449, 16467, 16471, 16478, 16486, 16512, 16518, 16526, 16537, 16553, 16715, 16720, 16721, 16722, 16728, 16729, 16730, 16733, 16757, 16758, 16761, 16763, 16764, 16774, 16775, 16783, 16790, 16796, 16808, 16813, 16829, 16830, 16835, 16838, 16851, 16853, 16854, 16862, 16863, 16872, 16874, 16880, 16882, 16891, 16892, 16900, 16908, 16911, 16920, 16922, 16923, 16924, 16925, 16928, 16951, 16953, 16963, 16986, 16996, 16997, 17001, 17002, 17004, 17005, 17010, 17032, 17044, 17047, 17050, 17051, 17052, 17060, 17079, 17082, 17105, 17106, 17108, 17110, 17134, 17143, 17146, 17148, 17156, 17157, 17158, 17161, 17164, 17166, 17169, 17171, 17177, 17182, 17183, 17187, 17196, 17202, 17204, 17207, 17208, 17209, 17212, 17213, 17214, 17219, 17221, 17223, 17230, 17238, 17252, 17253, 17259, 17260, 17261, 17262, 17271, 17285, 17296, 17298, 17300, 17303, 17316, 17317, 17321, 17325, 17333, 17338, 17346, 17351, 17352, 17361, 17365, 17367, 17369, 17377, 17389, 17410, 17411, 17417, 17420, 17428, 17429, 17430, 17435, 17445, 17448, 17451, 17462, 17472, 17480, 17493, 17497, 17500, 17506, 17507, 17524, 17545, 17720, 17733, 17741, 17796, 17820, 17822, 17848, 17875, 17876, 17877, 17887, 17892, 17923, 17941, 17942, 17960, 17982, 17997, 18010, 18013, 18019, 18022, 18024, 18026, 18030, 18032, 18033, 18035, 18042, 18052, 18060, 18077, 18079, 18112, 18114, 18119, 18121, 18125, 18134, 18138, 18162, 18178, 18184, 18189, 18198, 18200, 18209, 18218, 18271, 18343, 18371, 18388, 18419, 18428, 18429, 18433, 18445, 18453, 18459, 18493, 18497, 18498, 18502, 18503, 18512, 18529, 18531, 18539, 18541, 18553, 18564, 18578, 18585, 18590, 18596, 18602, 18604, 18605, 18628, 18630, 18665, 18699, 18812, 18823, 18830, 18842, 18854, 18867, 18883, 18890, 18905, 18918, 18923, 18929, 18940, 18946, 18952, 18965, 18976, 18982, 18987, 19000, 19016, 19017, 19020, 19022, 19029, 19033, 19038, 19049, 19056, 19062, 19065, 19080, 19084, 19091, 19093, 19100, 19106, 19109, 19111, 19115, 19141, 19143, 19145, 19155, 19169, 19174, 19192, 19201, 19219, 19223, 19240, 19249, 19255, 19262, 19265, 19274, 19277, 19280, 19283, 19290, 19297, 19301, 19302, 19305, 19329, 19468, 19478, 19490, 19502, 19508, 19524, 19528, 19532, 19534, 19573, 19586, 19592, 19642, 19661, 19672, 19685, 19693, 19695, 19697, 19707, 19718, 19720, 19735, 19754, 19775, 19780, 19781, 19793, 19798, 19821, 19825, 19827, 19860, 19862, 19868, 19870, 19887, 19892, 19894, 19899, 19924, 20074, 20089, 20098, 20112, 20113, 20115, 20119, 20123, 20126, 20128, 20130, 20137, 20139, 20150, 20165, 20170, 20189, 20190, 20208, 20211, 20219, 20222, 20223, 20224, 20239, 20251, 20257, 20260, 20273, 20274, 20276, 20283, 20286, 20287, 20317, 20320, 20330, 20334, 20335, 20338, 20339, 20341, 20345, 20347, 20349, 20353, 20360, 20366, 20367, 20371, 20375, 20377, 20382, 20390, 20403, 20407, 20409, 20412, 20420, 20426, 20428, 20431, 20440, 20447, 20449, 20459, 20476, 20481, 20488, 20499, 20507, 20511, 20515, 20520, 20521, 20525, 20534, 20537, 20556, 20558, 20564, 20571, 20581, 20582, 20597, 20599, 20601, 20607, 20609, 20621, 20627, 20630, 20635, 20805, 20888, 20893, 21039, 21157, 21227, 21238, 21463, 21466, 21472, 21477, 21488, 21494, 21502, 21515, 21516, 21520, 21543, 21545, 21546, 21547, 21571, 21585, 21597, 21598, 21599, 21601, 21602, 21618, 21621, 21624, 21640, 21644, 21654, 21659, 21664, 21694, 21698, 21702, 21706, 21707, 21709, 21710, 21718, 21727, 21735, 21742, 21743, 21760, 21767, 21776, 21787, 21790, 21794, 21802, 21814, 21825, 21835, 21838, 21846, 21861, 21866, 21869, 21872, 21873, 21874, 21877, 21879, 21900, 21904, 21919, 21926, 21929, 21939, 21950, 21962, 22009, 22021, 22035, 22039, 22042, 22045, 22048, 22060, 22062, 22067, 22068, 22071, 22074, 22078, 22081, 22089, 22094, 22097, 22099, 22104, 22108, 22120, 22129, 22138, 22142, 22149, 22155, 22164, 22168, 22180, 22195, 22197, 22199, 22200, 22205, 22208, 22212, 22217, 22223, 22228, 22239, 22244, 22246, 22254, 22255, 22256, 22260, 22261, 22266, 22271, 22275, 22291, 23123, 23124, 23135, 23143, 23148, 23150, 23155, 23158, 23167, 23174, 23180, 23182, 23189, 23196, 23203, 23210, 23211, 23216, 23217, 23219, 23234, 23237, 23238, 23241, 23244, 23250, 23256, 23261, 23272, 23273, 23278, 23283, 23285, 23290, 23299, 23307, 23308, 23309, 23310, 23315, 23316, 23319, 23322, 23326, 23330, 23333, 23345, 23346, 23351, 23361, 23363, 23374, 23377, 23378, 23388, 23389, 23390, 23391, 23398, 23409, 23414, 23416, 23418, 23421, 23431, 23436, 23439, 23449, 23453, 23455, 23460, 23462, 23468, 23480, 23493, 23495, 23503, 23507, 23514, 23529, 23530, 23540, 23560, 23563, 23569, 23570, 23579, 23580, 23624, 23629, 23639, 23640, 23649, 23665, 23671, 23681, 23688, 23696, 23703, 23709, 23723, 23728, 23742, 23745, 23753, 23778, 23780, 23790, 23791, 23792, 23804, 23805, 23814, 23816, 23821, 23823, 23825, 23838, 23839, 23842, 23845, 23846, 23848, 23862, 23870, 23873, 23885, 23895, 23903, 23904, 23911, 23923, 23939, 23943, 23957, 23962, 23970, 23972, 23976, 23983, 23992, 24001, 24010, 24013, 24014, 24017, 24823, 24847, 24855, 24867, 24879, 24880, 24882, 24892, 24894, 24900, 24901, 24912, 24921, 24922, 24928, 24932, 24934, 24945, 24950, 24956, 24960, 24962, 24972, 24978, 24983, 24994, 24996, 25007, 25011, 25015, 25022, 25037, 25039, 25040, 25042, 25052, 25091, 25096, 25098, 25100, 25109, 25123, 25135, 25154, 25165, 25169, 25179, 25182, 25188, 25189, 25200, 25202, 25224, 25234, 25246, 25264, 25266, 25276, 25281, 25285, 25302, 25309, 25314, 25316, 25317, 25327, 25331, 25333, 25338, 25351, 25355, 25366, 25371, 25378, 25381, 25382, 25385, 25386, 25390, 25403, 25413, 25418, 25424, 25427, 25430, 25437, 25438, 25447, 25448, 25464, 25466, 25496, 25498, 26288, 26290, 26293, 26295, 26299, 26301, 26304, 26306, 26309, 26315, 26328, 26335, 26337, 26341, 26343, 26344, 26349, 26350, 26351, 26354, 26357, 26358, 26359, 26367, 26368, 26371, 26383, 26389, 26396, 26406, 26410, 26414, 26420, 26433, 26438, 26444, 26449, 26452, 26458, 26465, 26467, 26473, 26488, 26490, 26501, 26502, 26505, 26514, 26529, 26539, 26541, 26542, 26545, 26550, 26553, 26555, 26556, 26557, 26572, 26574, 26576, 26588, 26591, 26607, 26612, 26616, 26625, 26626, 26627, 26635, 26646, 26652, 26653, 26667, 26677, 26689, 26698, 26706, 26710, 26717, 26724, 26734, 26740, 26741, 26743, 26749, 26752, 26758, 26769, 26781, 26783, 26798, 26801, 26815, 26841, 26846, 26847, 26850, 26856, 26859, 26861, 26865, 26871, 26879, 26882, 26883, 26886, 26890, 26893, 26894, 26920, 26932, 26937, 26940, 26942, 26952, 26953, 26966, 26974, 26979, 26983, 26990, 26997, 26998, 27011, 27012, 27013, 27018, 27019, 27023, 27024, 27025, 27028, 27827, 27828, 27837, 27841, 27853, 27868, 27879, 27885, 27889, 27900, 27905, 27924, 27926, 27935, 27946, 27951, 27954, 27959, 27962, 27975, 27979, 28004, 28012, 28013, 28019, 28024, 28030, 28032, 28034, 28040, 28043, 28044, 28046, 28049, 28054, 28082, 28086, 28095, 28100, 28101, 28114, 28115, 28121, 28122, 28123, 28124, 28129, 28134, 28149, 28151, 28158, 28169, 28185, 28192, 28204, 28215, 28216, 28222, 28223, 28233, 28234, 28238, 28247, 28268, 28276, 28280, 28281, 28308, 28329, 28334, 28354, 28380, 28381, 28388, 28394, 28398, 28403, 28406, 28408, 28420, 28427, 28429, 28458, 28460, 28462, 28472, 28473, 28476, 28492, 28498, 28500, 28505, 28510, 28513, 28515, 28519, 28520, 28528, 28530, 28531, 28536, 28539, 28545, 28584, 28592, 28593, 28602, 28606, 28609, 28619, 28620, 28626, 28627, 28646, 28656, 28662, 28677, 28693, 28890, 28892, 28896, 28903, 28904, 28912, 28915, 28932, 28933, 28935, 28947, 28960, 28978, 28987, 28988, 28990, 28992, 29017, 29019, 29022, 29032, 29038, 29039, 29047, 29048, 29049, 29063, 29065, 29069, 29075, 29076, 29088, 29095, 29104, 29109, 29118, 29119, 29136, 29153, 29157, 29160, 29167, 29172, 29174, 29175, 29176, 29179, 29192, 29199, 29201, 29206, 29218, 29219, 29220, 29233, 29241, 29252, 29253, 29258, 29261, 29263, 29271, 29274, 29293, 29302, 29305, 29310, 29312, 29320, 29323, 29339, 29347, 29358, 29361, 29363, 29369, 29377, 29392, 29400, 29408, 29413, 29416, 29438, 29444, 29457, 29461, 29475, 29478, 29500, 29501, 29509, 29514, 29516, 29518, 29552, 29557, 29558, 29560, 29564, 29565, 29573, 29587, 29598, 29601, 29633, 29641, 29650, 29651, 29654, 29656, 29663, 29671, 29681, 29697, 29701, 30518, 30523, 30527, 30530, 30532, 30549, 30550, 30604, 30611, 30629, 30633, 30645, 30650, 30653, 30655, 30657, 30660, 30665, 30672, 30673, 30683, 30692, 30695, 30700, 30717, 30722, 30726, 30739, 30740, 30745, 30751, 30752, 30768, 30769, 30771, 30775, 30776, 30778, 30785, 30789, 30793, 30800, 30805, 30818, 30819, 30820, 30822, 30836, 30837, 30841, 30847, 30857, 30858, 30860, 30866, 30868, 30883, 30886, 30891, 30893, 30894, 30895, 30899, 30918, 30920, 30922, 30935, 30940, 30968, 30980, 30986, 30987, 30989, 30990, 30992, 30993, 30996, 30997, 30999, 31005, 31015, 31017, 31019, 31020, 31022, 31024, 31026, 31030, 31040, 31041, 31043, 31049, 31057, 31061, 31062, 31063, 31066, 31068, 31093, 31100, 31103, 31104, 31106, 31108, 31109, 31113, 31117, 31120, 31127, 31145, 31163, 31165, 31168, 31179, 31187, 31196, 31208, 31211, 31218, 31219, 31221, 31224, 31228, 31233, 31245, 31388, 31394, 31396, 31426, 31427, 31428, 31436, 31438, 31439, 31452, 31455, 31470, 31485, 31516, 31522, 31536, 31539, 31558, 31582, 31585, 31589, 31592, 31603, 31609, 31615, 31618, 31622, 31629, 31635, 31638, 31647, 31671, 31681, 31688, 31689, 31699, 31701, 31715, 31727, 31731, 31732, 31733, 31736, 31740, 31744, 31751, 31753, 31759, 31765, 31772, 31778, 31794, 31816, 31825, 31834, 31860, 31867, 31897, 31902, 31915, 31925, 31930, 31932, 31939, 32081, 32089, 32096, 32100, 32103, 32125, 32136, 32155, 32159, 32172, 32174, 32184, 32192, 32197, 32206, 32211, 32219, 32222, 32228, 32237, 32248, 32257, 32277, 32300, 32306, 32307, 32329, 32335, 32336, 32345, 32357, 32364, 32369, 32370, 32373, 32391, 32401, 32405, 32408, 32412, 32413, 32423, 32424, 32429, 32441, 32450, 32452, 32454, 32470, 32473, 32493, 32501, 32506, 32507, 32510, 32522, 32525, 32527, 32532, 32537, 32540, 32544, 32549, 32556, 32557, 32559, 32560, 32572, 32574, 32579, 32580, 32586, 32598, 32600, 32602, 32603, 32606, 32616, 32623, 32629, 32642, 32651, 32662, 32676, 32681, 32695, 32697, 32707, 32712, 32910, 32914, 32957, 32968, 33015, 33018, 33057, 33258, 33288, 33382, 33386, 33403, 33416, 33565, 33588, 33592, 33597, 33607, 33608, 33609, 33610, 33620, 33625, 33627, 33628, 33649, 33660, 33673, 33674, 33680, 33683, 33684, 33686, 33693, 33696, 33704, 33712, 33718, 33721, 33736, 33754, 33756, 33765, 33768, 33769, 33773, 33776, 33779, 33788, 33790, 33794, 33796, 33799, 33809, 33813, 33814, 33817, 33832, 33835, 33837, 33850, 33851, 33864, 33878, 33880, 33881, 33884, 33887, 33892, 33895, 33915, 33916, 33940, 33941, 33955, 33956, 33965, 33968, 33971, 33978, 33989, 34000, 34004, 34008, 34009, 34020, 34029, 34033, 34043, 34046, 34060, 34069, 34072, 34073, 34080, 34104, 34119, 34120, 34268, 34279, 34280, 34289, 34292, 34297, 34312, 34318, 34319, 34324, 34329, 34339, 34347, 34348, 34370, 34385, 34390, 34398, 34400, 34403, 34414, 34417, 34421, 34443, 34446, 34458, 34463, 34467, 34480, 34490, 34491, 34516, 34520, 34521, 34529, 34534, 34561, 34579, 34599, 34601, 34602, 34610, 34615, 34622, 34635, 34667, 34835, 34837, 34847, 34861, 34891, 34901, 34907, 34914, 34915, 34919, 34930, 34939, 34940, 34963, 34984, 34988, 35001, 35006, 35016, 35026, 35039, 35046, 35053, 35055, 35058, 35064, 35067, 35068, 35074, 35077, 35084, 35088, 35094, 35098, 35102, 35106, 35107, 35118, 35129, 35138, 35145, 35152, 35175, 35182, 35192, 35197, 35198, 35205, 35208, 35210, 35211, 35239, 35244, 35250, 35252, 35313, 35317, 35327, 35341, 35566, 35568, 35576, 35580, 35584, 35585, 35594, 35603, 35608, 35626, 35630, 35636, 35649, 35660, 35662, 35665, 35667, 35669, 35670, 35673, 35674, 35676, 35686, 35694, 35712, 35716, 35726, 35727, 35732, 35733, 35754, 35761, 35779, 35800, 35806, 35807, 35812, 35823, 35831, 35849, 35856, 35872, 35877, 35888, 35901, 35905, 35907, 35916, 35918, 35919, 35924, 35928, 35931, 35936, 35937, 35948, 35957, 35962, 35969, 35973, 35975, 35992, 35996, 36001, 36031, 36040, 36043, 36046, 36052, 36054, 36057, 36062, 36063, 36068, 36071, 36105, 36118, 36119, 36122, 36125, 36126, 36133, 36167, 36176, 36183, 36197, 36201, 37032, 37036, 37043, 37050, 37056, 37071, 37073, 37074, 37087, 37097, 37101, 37105, 37126, 37131, 37136, 37147, 37160, 37171, 37182, 37194, 37197, 37209, 37212, 37223, 37226, 37236, 37237, 37241, 37247, 37248, 37249, 37257, 37272, 37275, 37281, 37302, 37304, 37305, 37316, 37319, 37321, 37323, 37328, 37334, 37351, 37352, 37373, 37378, 37379, 37380, 37389, 37409, 37410, 37414, 37417, 37419, 37431, 37436, 37440, 37443, 37455, 37463, 37469, 37471, 37472, 37474, 37485, 37496, 37502, 37510, 37512, 37517, 37539, 37540, 37548, 37553, 37564, 37570, 37576, 37594, 37600, 37614, 37628, 37641, 37642, 37644, 37646, 37647, 37649, 37652, 37661, 37663, 37680, 37681, 37689, 37695, 37697, 37699, 37706, 37713, 37718, 37729, 37734, 37736, 37740, 37742, 37743, 37749, 37754, 37761, 37764, 37775, 37776, 37778, 37785, 37798, 37803, 37805, 37810, 37815, 37824, 37825, 37828, 37830, 37831, 37839, 37842, 37847, 37849, 37859, 37860, 37862, 37869, 37871, 37874, 37878, 38688, 38694, 38718, 38725, 38734, 38750, 38751, 38768, 38776, 38786, 38797, 38801, 38804, 38816, 38817, 38828, 38834, 38839, 38859, 38865, 38866, 38868, 38871, 38874, 38876, 38886, 38890, 38891, 38894, 38905, 38908, 38940, 38941, 38944, 38949, 38955, 38964, 38966, 38970, 38976, 38978, 38986, 38987, 39006, 39011, 39012, 39018, 39019, 39030, 39032, 39033, 39035, 39040, 39051, 39055, 39068, 39070, 39087, 39088, 39090, 39101, 39111, 39113, 39117, 39119, 39127, 39130, 39140, 39142, 39147, 39152, 39162, 39167, 39169, 39184, 39194, 39196, 39200, 39213, 39215, 39221, 39225, 39226, 39228, 39235, 39240, 39241, 39243, 39250, 39252, 39254, 39261, 39262, 39269, 39272, 39273, 39275, 39295, 39296, 39298, 39299, 39307, 39310, 39312, 39330, 39333, 39350, 39352, 39353, 39357, 39367, 39398, 39409, 39411, 39412, 39418, 39421, 39428, 39451, 39467, 40237, 40240, 40251, 40253, 40273, 40284, 40294, 40295, 40297, 40305, 40306, 40308, 40315, 40317, 40323, 40330, 40357, 40371, 40383, 40387, 40396, 40401, 40404, 40418, 40425, 40431, 40434, 40438, 40446, 40452, 40463, 40467, 40472, 40482, 40483, 40486, 40496, 40497, 40499, 40501, 40503, 40507, 40509, 40515, 40517, 40521, 40524, 40549, 40559, 40561, 40570, 40577, 40578, 40580, 40581, 40587, 40590, 40604, 40606, 40618, 40621, 40628, 40632, 40669, 40671, 40675, 40682, 40687, 40708, 40709, 40714, 40719, 40732, 40735, 40740, 40741, 40750, 40751, 40755, 40759, 40770, 40799, 40800, 40806, 40813, 40815, 40820, 40826, 40829, 40833, 40837, 40840, 40843, 40859, 40861, 40885, 40899, 40907, 40920, 40922, 40923, 40931, 40932, 40940, 40946, 40955, 40970, 41175, 41186, 41193, 41195, 41198, 41200, 41206, 41207, 41229, 41230, 41235, 41241, 41245, 41258, 41260, 41262, 41278, 41279, 41288, 41337, 41354, 41358, 41362, 41370, 41375, 41387, 41392, 41400, 41406, 41422, 41431, 41434, 41450, 41467, 41470, 41474, 41480, 41487, 41491, 41497, 41516, 41528, 41546, 41560, 41565, 41568, 41732, 41733, 41752, 41762, 41772, 41773, 41783, 41795, 41796, 41806, 41808, 41809, 41812, 41817, 41822, 41829, 41830, 41840, 41841, 41855, 41857, 41875, 41880, 41885, 41888, 41891, 41898, 41903, 41914, 41923, 41927, 41937, 41939, 41948, 41954, 41970, 41979, 41985, 41987, 41990, 41993, 41994, 41995, 41997, 42002, 42004, 42007, 42008, 42009, 42011, 42017, 42024, 42033, 42040, 42048, 42054, 42056, 42057, 42059, 42061, 42077, 42082, 42107, 42112, 42118, 42123, 42124, 42126, 42131, 42132, 42139, 42140, 42149, 42153, 42157, 42163, 42166, 42167, 42168, 42206, 42211, 42219, 42221, 42238, 42244, 42246, 42256, 42268, 42274, 42276, 42282, 42288, 42295, 42320, 42324, 42326, 42333, 42337, 42339, 42341, 42346, 42347, 42365, 42366, 42376, 42398, 42408, 42418, 42420, 42422, 42429, 42449, 42455, 42456, 42466, 42650, 42652, 42704, 42735, 42743, 42745, 42747, 42752, 42766, 42768, 42770, 42774, 42789, 42791, 42795, 42816, 42830, 42833, 42837, 42843, 42850, 42852, 42859, 42863, 42870, 42893, 42907, 42910, 42912, 42917, 42938, 42947, 42951, 42953, 42963, 42966, 42977, 42980, 42987, 43002, 43009, 43021, 43028, 43043, 43050, 43054, 43059, 43070, 43072, 43076]\n",
      "\n",
      "Outliers:\n",
      "      Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "0             2            0.858225                0.900089   \n",
      "1             2            1.000000                0.543201   \n",
      "37            2            0.949074                0.922840   \n",
      "49            2            0.811728                0.651231   \n",
      "56            2            0.951111                1.000000   \n",
      "...         ...                 ...                     ...   \n",
      "43054         2            0.873457                0.895062   \n",
      "43059         2            0.819444                0.564794   \n",
      "43070         2            0.911111                1.000000   \n",
      "43072         2            0.805298                0.789116   \n",
      "43076         2            0.933333                0.916667   \n",
      "\n",
      "                         App  \\\n",
      "0      10 Best Foods for You   \n",
      "1      10 Best Foods for You   \n",
      "37     10 Best Foods for You   \n",
      "49     10 Best Foods for You   \n",
      "56     10 Best Foods for You   \n",
      "...                      ...   \n",
      "43054          Facebook Lite   \n",
      "43059         Facebook Local   \n",
      "43070         Facebook Local   \n",
      "43072         Facebook Local   \n",
      "43076         Facebook Local   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "0      I like eat delicious food. That's I'm cooking food myself, case \"10 Best Foods\" helps lot, also ...   \n",
      "1                                                          This help eating healthy exercise regular basis   \n",
      "37     WEALTH OF INFORMATION Very informative ... easy understand. (The ads middle page interupted read...   \n",
      "49                                                                              Lovely Best everyone needs   \n",
      "56                                                                                            This helpful   \n",
      "...                                                                                                    ...   \n",
      "43054  This is what has been said about Vicky Singh, who has been accused of being involved in a fake e...   \n",
      "43059  Way many notifications way turn ones want. Example: notifications every event even Interested/Go...   \n",
      "43070  I actually liked app, ever since I upgraded OnePlus 6, work. It opens, I can't interact all. Cli...   \n",
      "43072                                 This would lot better, quit recommending businesses closed year ago.   \n",
      "43076  I Love Application & Until day another day The World Will Become Pretty & technology Development...   \n",
      "\n",
      "       New_ID  \\\n",
      "0           1   \n",
      "1           2   \n",
      "37         24   \n",
      "49         30   \n",
      "56         35   \n",
      "...       ...   \n",
      "43054   16664   \n",
      "43059   16667   \n",
      "43070   16673   \n",
      "43072   16674   \n",
      "43076   16676   \n",
      "\n",
      "                                                                                                       row  \n",
      "0      2*0.8582251082251081*0.9000893286607572*10BestFoodsforYou*Ilikeeatdeliciousfood.That'sI'mcooking...  \n",
      "1      2*1.0*0.543200845322279*10BestFoodsforYou*Thishelpeatinghealthyexerciseregularbasis*2*2*1.0*0.54...  \n",
      "37     2*0.9490740740740741*0.9228395061728395*10BestFoodsforYou*WEALTHOFINFORMATIONVeryinformative...e...  \n",
      "49     2*0.8117283950617283*0.651231391918776*10BestFoodsforYou*LovelyBesteveryoneneeds*30*2*0.81172839...  \n",
      "56     2*0.9511111111111111*1.0*10BestFoodsforYou*Thishelpful*35*2*0.9511111111111111*1.0*10BestFoodsfo...  \n",
      "...                                                                                                    ...  \n",
      "43054  2*0.8734567901234567*0.8950617283950617*FacebookLite*ThisiswhathasbeensaidaboutVickySingh,whohas...  \n",
      "43059  2*0.8194444444444443*0.5647938533305888*FacebookLocal*Waymanynotificationswayturnoneswant.Exampl...  \n",
      "43070  2*0.9111111111111111*1.0*FacebookLocal*Iactuallylikedapp,eversinceIupgradedOnePlus6,work.Itopens...  \n",
      "43072  2*0.8052983539094649*0.7891156462585034*FacebookLocal*Thiswouldlotbetter,quitrecommendingbusines...  \n",
      "43076  2*0.9333333333333333*0.9166666666666666*FacebookLocal*ILoveApplication&UntildayanotherdayTheWorl...  \n",
      "\n",
      "[4004 rows x 7 columns]\n",
      "\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "with indexes: [23, 27, 46, 58, 70, 76, 95, 96, 112, 117, 125, 161, 167, 179, 183, 188, 205, 238, 239, 257, 297, 303, 314, 333, 346, 347, 349, 351, 357, 365, 369, 377, 412, 421, 429, 437, 453, 501, 503, 516, 541, 548, 552, 554, 555, 567, 568, 594, 603, 615, 623, 651, 665, 686, 696, 734, 1020, 1030, 1065, 1123, 1132, 1326, 1332, 1373, 1387, 1413, 1419, 1427, 1452, 1468, 1472, 1487, 1490, 1493, 1504, 1549, 1561, 1571, 1575, 1577, 1601, 1604, 1609, 1613, 1614, 1626, 1641, 1650, 1655, 1685, 1686, 1695, 1703, 1713, 1732, 1736, 1742, 1753, 1755, 1765, 1766, 1801, 1802, 1831, 1848, 1874, 1879, 1881, 2078, 2080, 2144, 2170, 2250, 2268, 2295, 2351, 2353, 2377, 2422, 2430, 2498, 2504, 2513, 2515, 2542, 2556, 2559, 2561, 2575, 2578, 2580, 2587, 2610, 2613, 2630, 2663, 2683, 2837, 2854, 2862, 2873, 2907, 2924, 2938, 3029, 3048, 3061, 3082, 3092, 3102, 3128, 3134, 3155, 3156, 3165, 3188, 3383, 3448, 3460, 3494, 3495, 3537, 3542, 3546, 3604, 3617, 3624, 3628, 3629, 3670, 3672, 3674, 3698, 3727, 3745, 3775, 3781, 3952, 3988, 3993, 4010, 4032, 4043, 4058, 4064, 4068, 4073, 4136, 4225, 4244, 4268, 4290, 4293, 4312, 4315, 4323, 4324, 4344, 4354, 4367, 4490, 4525, 4575, 4587, 4602, 4610, 4611, 4616, 4758, 4784, 4793, 4806, 4844, 4933, 5058, 5125, 5139, 5157, 5163, 5166, 5182, 5186, 5237, 5241, 5249, 5255, 5271, 5290, 5293, 5303, 5326, 5328, 5366, 5397, 5402, 5423, 5551, 5553, 5559, 5580, 5602, 5605, 5621, 5626, 5636, 5655, 5715, 5720, 5729, 5730, 5741, 5748, 5784, 5786, 5810, 5815, 5843, 5851, 5872, 5875, 5880, 5890, 6097, 6112, 6118, 6127, 6143, 6144, 6152, 6164, 6196, 6203, 6207, 6211, 6222, 6245, 6308, 6313, 6322, 6342, 6379, 6393, 6416, 6452, 6456, 6480, 6714, 6760, 6780, 6805, 6808, 6848, 6853, 6863, 6872, 6892, 6912, 6920, 6934, 6936, 6948, 6958, 6964, 6980, 7008, 7013, 7019, 7038, 7060, 7073, 7074, 7093, 7099, 7119, 7144, 7156, 7159, 7186, 7312, 7320, 7333, 7351, 7362, 7372, 7393, 7406, 7425, 7429, 7431, 7433, 7441, 7444, 7446, 7458, 7473, 7485, 7489, 7571, 7576, 7590, 7592, 7625, 7652, 7675, 7689, 7700, 7732, 7860, 7861, 7869, 7882, 7895, 7897, 7911, 7928, 7940, 7954, 8022, 8081, 8123, 8127, 8155, 8167, 8180, 8185, 8201, 8205, 8235, 8348, 8360, 8392, 8431, 8450, 8454, 8466, 8469, 8472, 8483, 8518, 8565, 8610, 8667, 8672, 8701, 8718, 8734, 8737, 8749, 8851, 8854, 8872, 8876, 8884, 8895, 8909, 8919, 8946, 8947, 8957, 8961, 8974, 8975, 9061, 9064, 9093, 9139, 9141, 9188, 9215, 9224, 9227, 9232, 9234, 9265, 9282, 9285, 9346, 9349, 9372, 9374, 9375, 9394, 9403, 9405, 9421, 9435, 9439, 9440, 9464, 9485, 9505, 9520, 9622, 9631, 9660, 9667, 9676, 9680, 9683, 9691, 9698, 9757, 9764, 9774, 9785, 9792, 9796, 9810, 9848, 9860, 9861, 9889, 9909, 9910, 9915, 10035, 10038, 10043, 10082, 10094, 10103, 10116, 10122, 10123, 10126, 10158, 10205, 10258, 10275, 10286, 10293, 10300, 10310, 10335, 10357, 10361, 10405, 10410, 10411, 10430, 10431, 10465, 10501, 10521, 10523, 10549, 10568, 10578, 10588, 10602, 10607, 10612, 10615, 10642, 10665, 10670, 10690, 10723, 10759, 10761, 10768, 10770, 10791, 10803, 10844, 10871, 10897, 10899, 10907, 10917, 10951, 10955, 10957, 10962, 10985, 11025, 11039, 11085, 11107, 11117, 11166, 11180, 11223, 11243, 11245, 11250, 11296, 11326, 11338, 11341, 11346, 11347, 11449, 11490, 11535, 11545, 11672, 11684, 11691, 11697, 11729, 11730, 11739, 11769, 11776, 11811, 11828, 11859, 11878, 11884, 11886, 11893, 11905, 11925, 11964, 11983, 11994, 12001, 12006, 12008, 12015, 12017, 12024, 12028, 12046, 12055, 12062, 12063, 12075, 12094, 12095, 12126, 12147, 12159, 12163, 12175, 12188, 12198, 12206, 12208, 12217, 12234, 12257, 12284, 12290, 12292, 12301, 12322, 12324, 12331, 12354, 12379, 12381, 12391, 12407, 12411, 12415, 12479, 12485, 12506, 12507, 12591, 12594, 12595, 12598, 12642, 12643, 12664, 12665, 12679, 12684, 12693, 12713, 12725, 12736, 12746, 12766, 12772, 12791, 12808, 12817, 12821, 12830, 12833, 12839, 12846, 12863, 12865, 12869, 12884, 12903, 12927, 12929, 12939, 12968, 12973, 12982, 12988, 12992, 13011, 13012, 13049, 13069, 13104, 13124, 13134, 13147, 13162, 13175, 13181, 13185, 13193, 13218, 13238, 13255, 13311, 13315, 13320, 13322, 13328, 13335, 13395, 13401, 13426, 13435, 13441, 13447, 13476, 13483, 13510, 13818, 14314, 14317, 14318, 14354, 14363, 14420, 14421, 14423, 14436, 14441, 14443, 14446, 14448, 14464, 14490, 14507, 14534, 14539, 14558, 14576, 14614, 14672, 14680, 14700, 14706, 14710, 14719, 14722, 14736, 14742, 14755, 14757, 14773, 14780, 14810, 14823, 14845, 14865, 14869, 14878, 14881, 14882, 14933, 14936, 14952, 14979, 14992, 15032, 15034, 15041, 15052, 15084, 15890, 15892, 15901, 15926, 15942, 15947, 15951, 15952, 15990, 15991, 16042, 16091, 16183, 16191, 16193, 16194, 16204, 16216, 16222, 16236, 16252, 16255, 16259, 16268, 16284, 16288, 16289, 16310, 16311, 16316, 16322, 16323, 16326, 16332, 16372, 16396, 16405, 16413, 16419, 16428, 16433, 16451, 16454, 16531, 16540, 16725, 16736, 16741, 16760, 16765, 16782, 16787, 16789, 16800, 16815, 16837, 16847, 16860, 16865, 16866, 16878, 16916, 16933, 16936, 16945, 16947, 16952, 16966, 16981, 16985, 16991, 16992, 17017, 17025, 17055, 17070, 17086, 17092, 17093, 17112, 17113, 17115, 17130, 17149, 17190, 17194, 17200, 17211, 17257, 17268, 17278, 17279, 17293, 17336, 17350, 17354, 17379, 17391, 17407, 17509, 17528, 17540, 17544, 17547, 17724, 17751, 17787, 17801, 17821, 17840, 17894, 17919, 17922, 17946, 17962, 18005, 18007, 18029, 18050, 18084, 18115, 18126, 18214, 18255, 18341, 18366, 18375, 18405, 18412, 18431, 18435, 18446, 18452, 18460, 18491, 18492, 18511, 18530, 18545, 18550, 18558, 18597, 18601, 18616, 18621, 18636, 18659, 18807, 18831, 18837, 18840, 18846, 18856, 18875, 18880, 18882, 18917, 18939, 18944, 18954, 18962, 18968, 18975, 18988, 18989, 19023, 19044, 19046, 19051, 19054, 19063, 19098, 19146, 19152, 19161, 19164, 19193, 19203, 19209, 19213, 19236, 19254, 19256, 19259, 19292, 19312, 19483, 19512, 19545, 19587, 19597, 19606, 19616, 19678, 19689, 19698, 19716, 19719, 19726, 19748, 19777, 19790, 19794, 19797, 19851, 19867, 19898, 19903, 20127, 20158, 20188, 20193, 20196, 20203, 20213, 20215, 20218, 20241, 20267, 20279, 20281, 20303, 20328, 20331, 20361, 20372, 20383, 20443, 20450, 20461, 20471, 20493, 20502, 20506, 20518, 20570, 20586, 20589, 20638, 20639, 20919]\n",
      "\n",
      "Outliers:\n",
      "      Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "46            2            0.782813                0.539683   \n",
      "58            2            0.803590                0.652084   \n",
      "70            2            0.911111                1.000000   \n",
      "...         ...                 ...                     ...   \n",
      "20586         2            0.841744                0.962963   \n",
      "20589         2            0.888889                0.790123   \n",
      "20638         2            0.792242                0.660352   \n",
      "20639         2            0.911111                1.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "\n",
      "                                                      App  \\\n",
      "23                                  10 Best Foods for You   \n",
      "27                                  10 Best Foods for You   \n",
      "46                                  10 Best Foods for You   \n",
      "58                                  10 Best Foods for You   \n",
      "70                                  10 Best Foods for You   \n",
      "...                                                   ...   \n",
      "20586                                           CWT To Go   \n",
      "20589                                           CWT To Go   \n",
      "20638  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20639  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20919                      Calculator with Percent (Free)   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.   \n",
      "27                                                                                          Healthy Eating   \n",
      "46                                                        Healthy Food Really good information eat healthy   \n",
      "58                                                                                             Very useful   \n",
      "70                                                                                             I Love Good   \n",
      "...                                                                                                    ...   \n",
      "20586  Best thing ever. Kept track recent business trip full changes. Its like virtual personal assista...   \n",
      "20589                    I usually rate apps, works great need update trip, do, contacts information wrong   \n",
      "20638                                                          Please add something scan protect browsers.   \n",
      "20639                          Good actually works. It enhances net speed great extent. Really useful app.   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "\n",
      "       New_ID  \\\n",
      "23          4   \n",
      "27          5   \n",
      "46         16   \n",
      "58         20   \n",
      "70         26   \n",
      "...       ...   \n",
      "20586    4262   \n",
      "20589    4265   \n",
      "20638    4279   \n",
      "20639    4280   \n",
      "20919    4282   \n",
      "\n",
      "                                                                                                       row  \n",
      "23     2*0.8181718971672669*0.8559670781893003*10BestFoodsforYou*HEALTHSHOULDALWAYSBETOPPRIORITY.!!.ONM...  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "46     2*0.782813401306456*0.5396825396825397*10BestFoodsforYou*HealthyFoodReallygoodinformationeatheal...  \n",
      "58     2*0.8035902952417616*0.6520840438615537*10BestFoodsforYou*Veryuseful*20*2*0.8035902952417616*0.6...  \n",
      "70     2*0.9111111111111111*1.0*10BestFoodsforYou*ILoveGood*26*2*0.9111111111111111*1.0*10BestFoodsforY...  \n",
      "...                                                                                                    ...  \n",
      "20586  2*0.8417442277411409*0.962962962962963*CWTToGo*Bestthingever.Kepttrackrecentbusinesstripfullchan...  \n",
      "20589  2*0.8888888888888888*0.7901234567901233*CWTToGo*Iusuallyrateapps,worksgreatneedupdatetrip,do,con...  \n",
      "20638  2*0.7922423335360056*0.6603520085986843*CacheCleaner-DUSpeedBooster(booster&cleaner)*Pleaseaddso...  \n",
      "20639  2*0.9111111111111111*1.0*CacheCleaner-DUSpeedBooster(booster&cleaner)*Goodactuallyworks.Itenhanc...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[964 rows x 7 columns]\n",
      "\n",
      "Outlier detection and removal done -- CPU time: 0.04720902442932129 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.03020000457763672 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.371194\n",
       "Sentiment_Polarity        0.023909\n",
       "Sentiment_Subjectivity   -0.003276\n",
       "New_ID                    0.000004\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>3376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3321 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "8192     1.0            0.388889                0.000000    1661\n",
       "8196     1.0            0.388889                0.000000    1662\n",
       "10       1.0            0.715793                0.735972       1\n",
       "8202     1.0            0.388889                0.000000    1664\n",
       "16398    1.0            0.557819                0.689521    3376\n",
       "...      ...                 ...                     ...     ...\n",
       "8175     1.0            0.388889                0.000000    1656\n",
       "8177     1.0            0.738622                0.507937    1657\n",
       "16377    1.0            0.388889                0.000000    3373\n",
       "16378    1.0            0.093567                0.806584    3374\n",
       "8190     1.0            0.388889                0.000000    1660\n",
       "\n",
       "[3321 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3321, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3321, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.355\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0699\n",
      "Time:                        11:43:08   Log-Likelihood:                -15647.\n",
      "No. Observations:               12672   AIC:                         3.130e+04\n",
      "Df Residuals:                   12668   BIC:                         3.133e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3712      0.023     59.766      0.000       1.326       1.416\n",
      "Sentiment_Polarity         0.0239      0.042      0.566      0.571      -0.059       0.107\n",
      "Sentiment_Subjectivity    -0.0033      0.022     -0.152      0.879      -0.046       0.039\n",
      "New_ID                  3.984e-06   1.54e-06      2.595      0.009    9.74e-07    6.99e-06\n",
      "==============================================================================\n",
      "Omnibus:                     3602.071   Durbin-Watson:                   1.772\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2178.120\n",
      "Skew:                          -0.895   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.041   Cond. No.                     5.97e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.97e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7061822160225694\n",
      "Regression done -- CPU time: 0.035875797271728516 seconds\n",
      "End Pipeline CPU time: 0.11380195617675781 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "with indexes: [5, 642, 1109, 2609, 8139, 9175, 11904, 12011, 13229, 14545, 18070, 20212, 22086, 22281, 23201, 24871, 24876, 25214, 25460, 26620, 26929, 28049, 30543, 30992, 31495, 33580, 41218, 42843, 43065, 43066]\n",
      "\n",
      "Outliers:\n",
      "      Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "5             3            0.388889                0.000000   \n",
      "642           3            0.388889                0.000000   \n",
      "1109          3            0.388889                0.000000   \n",
      "2609          3            0.388889                0.000000   \n",
      "8139          2            0.851852                0.925926   \n",
      "9175          3            0.388889                0.000000   \n",
      "11904         2            0.888889                0.680400   \n",
      "12011         3            0.388889                0.000000   \n",
      "13229         2            0.911111                1.000000   \n",
      "14545         3            0.388889                0.000000   \n",
      "18070         3            0.388889                0.000000   \n",
      "20212         2            0.655447                0.574055   \n",
      "22086         1            0.388889                0.000000   \n",
      "22281         3            0.388889                0.000000   \n",
      "23201         3            0.388889                0.000000   \n",
      "24871         3            0.388889                0.000000   \n",
      "24876         1            0.388889                0.000000   \n",
      "25214         3            0.388889                0.000000   \n",
      "25460         3            0.388889                0.000000   \n",
      "26620         3            0.388889                0.000000   \n",
      "26929         3            0.388889                0.000000   \n",
      "28049         2            0.859708                0.876039   \n",
      "30543         1            0.388889                0.000000   \n",
      "30992         2            1.000000                1.000000   \n",
      "31495         3            0.388889                0.000000   \n",
      "33580         3            0.388889                0.000000   \n",
      "41218         2            0.577154                0.735331   \n",
      "42843         2            1.000000                0.543201   \n",
      "43065         3            0.388889                0.000000   \n",
      "43066         3            0.388889                0.000000   \n",
      "\n",
      "                                                                                       App  \\\n",
      "5                                                                    10 Best Foods for You   \n",
      "642                                                          2ndLine - Second Phone Number   \n",
      "1109                                                         7 Cups: Anxiety & Stress Chat   \n",
      "2609                                                       AC - Tips & News for Androidâ¢   \n",
      "8139                                     Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "9175                                                         Asana: organize team projects   \n",
      "11904                                                                          Bad Piggies   \n",
      "12011                                                       Badoo - Free Chat & Dating App   \n",
      "13229                                                                  Be A Legend: Soccer   \n",
      "14545                                                             BeyondMenu Food Delivery   \n",
      "18070                                                                       Bubble Shooter   \n",
      "20212                                                                  CMB Free Dating App   \n",
      "22086                                                       Calorie Counter - MyFitnessPal   \n",
      "22281                                                         Calorie Counter - MyNetDiary   \n",
      "23201                                   Candy Camera - selfie, beauty camera, photo editor   \n",
      "24871                                                       Cat Sim Online: Play with Cats   \n",
      "24876                                                       Cat Sim Online: Play with Cats   \n",
      "25214                                                            ChatVideo Meet new people   \n",
      "25460                                                         Checkout 51: Grocery coupons   \n",
      "26620                                                                        Citi MobileÂ®   \n",
      "26929                                                                         Clash Royale   \n",
      "28049                                                Color by Number â New Coloring Book   \n",
      "30543                                                                         Credit Karma   \n",
      "30992                                                       Crunchyroll - Everything Anime   \n",
      "31495                                   Cymera Camera- Photo Editor, Filter,Collage,Layout   \n",
      "33580  Delivery ClubâÐÐ¾ÑÑÐ°Ð²ÐºÐ° ÐµÐ´Ñ:Ð¿Ð¸ÑÑÐ°,ÑÑÑÐ¸,Ð±ÑÑÐ³ÐµÑ,ÑÐ°Ð»Ð°Ñ   \n",
      "41218                                    Evernote â Organizer, Planner for Notes & Memos   \n",
      "42843                                                                             Facebook   \n",
      "43065                                                                       Facebook Local   \n",
      "43066                                                                       Facebook Local   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "5                                                                                                 Best way   \n",
      "642    Thanks fixing notification problem new recent update I give 5 stars cause I miss calls texts any...   \n",
      "1109                                          Yeah 7 cups fine, glitchy sometimes, less features available   \n",
      "2609                                                    New TOS data collection.. I'm out!!! (Uninstalled)   \n",
      "8139                                                                                 One best apps. â¤ï¸   \n",
      "9175   The amazing user friendly. My concers receiving notifications gmail inbox becomes like mess. I w...   \n",
      "11904  great game. I completed ground hog day rise swine.brought little pig adventure found fifteen sku...   \n",
      "12011  The self works fine, intended purpose works. There real people. HOWEVER scam feeling still stron...   \n",
      "13229  Server Downloaded yesterday still able get past first loading screen cuz says server maintenance...   \n",
      "14545                                                                      Super easy order always correct   \n",
      "18070                                                                                      Nice good games   \n",
      "20212                             Invited two friends watched set profiles, never received beans inviting.   \n",
      "22086                                                              In 1 week I feet fitter healthier ever!   \n",
      "22281         Easiest way calorie count honest. Down 2lbs week since I started. Also, reliable motivating.   \n",
      "23201  New version candy camera bad want old candy camera ..once reset phn nd dt candy camera removed t...   \n",
      "24871                Love family tree generations! dragon sim u 2 children here... TONS!!!!! LOVED IT 100%   \n",
      "24876  It's cute I throw kittens make make pregnant baby cute I'll cute cute cute cute cute cute like b...   \n",
      "25214  Well wanna tell guys make rules dont follow. No nudity etc...then dont banned people whos showin...   \n",
      "25460  I like app. It gives back money daily groceries I like tha different brands variety yht items fa...   \n",
      "26620  The got stuck today login phase, I clear data reinstall. Even start-up incredibly slow. (Even \"r...   \n",
      "26929  Plz make compatible Mali G72 MP3. I playing game old Redmi note 3 adreno 510 GPU & phone running...   \n",
      "28049  Brilliant way relax keeps saying internet access. So disconnect device reconnect continue. Bit a...   \n",
      "30543  This Best. Credit Karma check scores everyday matter many times also dispute Direct check credit...   \n",
      "30992  Upgrading rating two stars four stars. The bug fixes seem resolved quite issues I facing app. A ...   \n",
      "31495                                                                                            Good like   \n",
      "33580                                                         I never managed to enter a promotional code.   \n",
      "41218  Pretty unhappy note taking allow simple printing let alone exporting pdf. I regret used thinking...   \n",
      "42843  This lot problems. The irritating thing tag someone video post, reply, go notifications pops vid...   \n",
      "43065  I decided give try hope keeping track summer events going on. At first confusing difficult use, ...   \n",
      "43066         Did show thing I wanted see literally show anything read going outside town. Totally useless   \n",
      "\n",
      "       New_ID  \\\n",
      "5           5   \n",
      "642       418   \n",
      "1109      509   \n",
      "2609     1156   \n",
      "8139     3456   \n",
      "9175     3877   \n",
      "11904    5147   \n",
      "12011    5215   \n",
      "13229    5925   \n",
      "14545    6265   \n",
      "18070    7756   \n",
      "20212    8561   \n",
      "22086    9247   \n",
      "22281    9369   \n",
      "23201    9445   \n",
      "24871    9996   \n",
      "24876    9999   \n",
      "25214   10215   \n",
      "25460   10371   \n",
      "26620   10598   \n",
      "26929   10804   \n",
      "28049   11015   \n",
      "30543   11918   \n",
      "30992   12215   \n",
      "31495   12432   \n",
      "33580   13075   \n",
      "41218   15815   \n",
      "42843   16539   \n",
      "43065   16671   \n",
      "43066   16672   \n",
      "\n",
      "                                                                                                       row  \n",
      "5      3*0.3888888888888889*0.0*10BestFoodsforYou*Bestway*5*3*0.3888888888888889*0.0*10BestFoodsforYou*...  \n",
      "642    3*0.3888888888888889*0.0*2ndLine-SecondPhoneNumber*Thanksfixingnotificationproblemnewrecentupdat...  \n",
      "1109   3*0.3888888888888889*0.0*7Cups:Anxiety&StressChat*Yeah7cupsfine,glitchysometimes,lessfeaturesava...  \n",
      "2609   3*0.3888888888888889*0.0*AC-Tips&NewsforAndroidâ¢*NewTOSdatacollection..I'mout!!!(Uninstalled)*...  \n",
      "8139   2*0.8518518518518517*0.9259259259259259*Any.do:To-dolist,Calendar,Reminders&Planner*Onebestapps....  \n",
      "9175   3*0.3888888888888889*0.0*Asana:organizeteamprojects*Theamazinguserfriendly.Myconcersreceivingnot...  \n",
      "11904  2*0.8888888888888888*0.6803995006242197*BadPiggies*greatgame.Icompletedgroundhogdayriseswine.bro...  \n",
      "12011  3*0.3888888888888889*0.0*Badoo-FreeChat&DatingApp*Theselfworksfine,intendedpurposeworks.Thererea...  \n",
      "13229  2*0.9111111111111111*1.0*BeALegend:Soccer*ServerDownloadedyesterdaystillablegetpastfirstloadings...  \n",
      "14545  3*0.3888888888888889*0.0*BeyondMenuFoodDelivery*Supereasyorderalwayscorrect*6265*3*0.38888888888...  \n",
      "18070  3*0.3888888888888889*0.0*BubbleShooter*Nicegoodgames*7756*3*0.3888888888888889*0.0*BubbleShooter...  \n",
      "20212  2*0.6554468637144565*0.5740550181793233*CMBFreeDatingApp*Invitedtwofriendswatchedsetprofiles,nev...  \n",
      "22086  1*0.3888888888888889*0.0*CalorieCounter-MyFitnessPal*In1weekIfeetfitterhealthierever!*9247*1*0.3...  \n",
      "22281  3*0.3888888888888889*0.0*CalorieCounter-MyNetDiary*Easiestwaycaloriecounthonest.Down2lbsweeksinc...  \n",
      "23201  3*0.3888888888888889*0.0*CandyCamera-selfie,beautycamera,photoeditor*Newversioncandycamerabadwan...  \n",
      "24871  3*0.3888888888888889*0.0*CatSimOnline:PlaywithCats*Lovefamilytreegenerations!dragonsimu2children...  \n",
      "24876  1*0.3888888888888889*0.0*CatSimOnline:PlaywithCats*It'scuteIthrowkittensmakemakepregnantbabycute...  \n",
      "25214  3*0.3888888888888889*0.0*ChatVideoMeetnewpeople*Wellwannatellguysmakerulesdontfollow.Nonudityetc...  \n",
      "25460  3*0.3888888888888889*0.0*Checkout51:Grocerycoupons*Ilikeapp.ItgivesbackmoneydailygroceriesIliket...  \n",
      "26620  3*0.3888888888888889*0.0*CitiMobileÂ®*Thegotstucktodayloginphase,Icleardatareinstall.Evenstart-u...  \n",
      "26929  3*0.3888888888888889*0.0*ClashRoyale*PlzmakecompatibleMaliG72MP3.IplayinggameoldRedminote3adreno...  \n",
      "28049  2*0.8597081930415263*0.8760393046107332*ColorbyNumberâNewColoringBook*Brilliantwayrelaxkeepssa...  \n",
      "30543  1*0.3888888888888889*0.0*CreditKarma*ThisBest.CreditKarmacheckscoreseverydaymattermanytimesalsod...  \n",
      "30992  2*1.0*1.0*Crunchyroll-EverythingAnime*Upgradingratingtwostarsfourstars.Thebugfixesseemresolvedqu...  \n",
      "31495  3*0.3888888888888889*0.0*CymeraCamera-PhotoEditor,Filter,Collage,Layout*Goodlike*12432*3*0.38888...  \n",
      "33580  3*0.3888888888888889*0.0*DeliveryClubâÐÐ¾ÑÑÐ°Ð²ÐºÐ°ÐµÐ´Ñ:Ð¿Ð¸ÑÑÐ°,ÑÑÑÐ¸,Ð±ÑÑÐ³ÐµÑ,...  \n",
      "41218  2*0.5771536762385612*0.7353308364544319*EvernoteâOrganizer,PlannerforNotes&Memos*Prettyunhappy...  \n",
      "42843  2*1.0*0.543200845322279*Facebook*Thislotproblems.Theirritatingthingtagsomeonevideopost,reply,gon...  \n",
      "43065  3*0.3888888888888889*0.0*FacebookLocal*Idecidedgivetryhopekeepingtracksummereventsgoingon.Atfirs...  \n",
      "43066  3*0.3888888888888889*0.0*FacebookLocal*DidshowthingIwantedseeliterallyshowanythingreadgoingoutsi...  \n",
      "\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "with indexes: [27, 314, 1330, 1751, 2587, 3673, 4512, 4525, 5170, 6923, 6955, 8201, 8875, 9110, 9165, 9368, 10602, 12149, 12340, 13023, 13045, 13150, 13471, 17167, 17425, 17777, 18481, 19767, 20850, 20919]\n",
      "\n",
      "Outliers:\n",
      "      Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "27            2            0.955556                0.907407   \n",
      "314           2            0.933333                0.790123   \n",
      "1330          3            0.388889                0.000000   \n",
      "1751          3            0.388889                0.000000   \n",
      "2587          2            0.918519                0.790123   \n",
      "3673          3            0.388889                0.000000   \n",
      "4512          3            0.388889                0.000000   \n",
      "4525          2            0.829958                0.735972   \n",
      "5170          1            0.388889                0.000000   \n",
      "6923          3            0.388889                0.000000   \n",
      "6955          3            0.388889                0.000000   \n",
      "8201          2            0.955556                0.888889   \n",
      "8875          3            0.388889                0.000000   \n",
      "9110          3            0.388889                0.000000   \n",
      "9165          3            0.388889                0.000000   \n",
      "9368          2            0.627714                0.582426   \n",
      "10602         2            0.785956                0.894356   \n",
      "12149         1            0.388889                0.000000   \n",
      "12340         3            0.388889                0.000000   \n",
      "13023         3            0.388889                0.000000   \n",
      "13045         1            0.388889                0.000000   \n",
      "13150         3            0.388889                0.000000   \n",
      "13471         3            0.388889                0.000000   \n",
      "17167         3            0.388889                0.000000   \n",
      "17425         3            0.388889                0.000000   \n",
      "17777         3            0.388889                0.000000   \n",
      "18481         3            0.388889                0.000000   \n",
      "19767         3            0.388889                0.000000   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "\n",
      "                                                     App  \\\n",
      "27                                 10 Best Foods for You   \n",
      "314                           1800 Contacts - Lens Store   \n",
      "1330                                         8 Ball Pool   \n",
      "1751                        8fit Workouts & Meal Planner   \n",
      "2587                     AC - Tips & News for Androidâ¢   \n",
      "3673                         Accounting App - Zoho Books   \n",
      "4512                                             Agar.io   \n",
      "4525                                             Agar.io   \n",
      "5170           Airway Ex - Intubate. Anesthetize. Train.   \n",
      "6923                        Amino: Communities and Chats   \n",
      "6955                                              Amtrak   \n",
      "8201   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "8875                               AppLock - Fingerprint   \n",
      "9110                                            Arrow.io   \n",
      "9165                       Asana: organize team projects   \n",
      "9368                                 Asphalt 8: Airborne   \n",
      "10602                          BBWCupid - BBW Dating App   \n",
      "12149                                        Banco ItaÃº   \n",
      "12340                   Bangla Newspaper â Prothom Alo   \n",
      "13023                                   Basketball Stars   \n",
      "13045                          Bathroom Decorating Ideas   \n",
      "13150                                 Battlelands Royale   \n",
      "13471                      Beauty Camera - Selfie Camera   \n",
      "17167                                         Bowmasters   \n",
      "17425                       Brain Waves - Binaural Beats   \n",
      "17777                                          Brilliant   \n",
      "18481                                  Buienradar - weer   \n",
      "19767  CBS Sports App - Scores, News, Stats & Watch Live   \n",
      "20850                        Calculator - unit converter   \n",
      "20919                     Calculator with Percent (Free)   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "27                                                                                          Healthy Eating   \n",
      "314                                               Took 5 seconds find rx get contacts ordered, convenient.   \n",
      "1330   I 700 hundred coins I new I 300 even I winning games player backing I played I waited player bac...   \n",
      "1751           Short intense workouts, perfect someone who's ready spend hours gym lots cash fitness plan!   \n",
      "2587                               The ads much flashing jumping around cannot even read articles. Deleted   \n",
      "3673                                                                                               Awesome   \n",
      "4512   All game great! I really enjoy years now. But thing keeping rating 5 stars. When \"create skin\" u...   \n",
      "4525   Your connection VERY VERY VERY BAD. When I home, I full connectio yet tell connection connection...   \n",
      "5170   Great detail! Might I ask , user could connect joystick app? If yes, help simulate airway evalua...   \n",
      "6923   This great! It's really fun mess around talk fellow people like things u! The downside logs rand...   \n",
      "6955                                                    Tickets itineraries load logging in. What good it?   \n",
      "8201   Not intuitive. Not even little bit. Share collaborate broken/badly bugged. Very easy make big me...   \n",
      "8875   Not reliable! When I reboot phone stops working. I start work making ur protected vulnerable. Pl...   \n",
      "9110                                                               It's good problems internet connections   \n",
      "9165                                                                                            It's mess.   \n",
      "9368   I can't seem continue progress new phone.I old samsung I bought another phone different brand tr...   \n",
      "10602                                    It's great view I hope y'all keep good work keep beautiful coming   \n",
      "12149                           Quick, handy is Copy / Paste's function of lines of code for easy payment.   \n",
      "12340                                                                         Too much ads . Too much ads.   \n",
      "13023                    Its great! But theres alot areas improve gameplay! Looking forward future updates   \n",
      "13045                                                                                           Waste time   \n",
      "13150  Really amazing game couple things still missing. Adding squad mode would awesome! Also make get ...   \n",
      "13471  I like except ads make impossible get much accomplished. I uninstall twice 'wish shopping app' a...   \n",
      "17167  Really like game far. Great gameplay lots fun. Edit: I took away star constant asking rate even ...   \n",
      "17425  Meh. I tried it. Frankly without lot blind testing I buy helpful brown noise appropriate music. ...   \n",
      "17777  It fun solving problems becomes money You guys take money presentation collection knowledge made...   \n",
      "18481       I need radar map. Lost days, found answer little upper right arrows. And works again. Perfect.   \n",
      "19767  This great recently. Now locks closes every single time open it. I've sent feedback couple weeks...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "\n",
      "       New_ID  \\\n",
      "27          5   \n",
      "314       101   \n",
      "1330      261   \n",
      "1751      401   \n",
      "2587      544   \n",
      "3673      743   \n",
      "4512      902   \n",
      "4525      905   \n",
      "5170     1036   \n",
      "6923     1369   \n",
      "6955     1380   \n",
      "8201     1663   \n",
      "8875     1779   \n",
      "9110     1837   \n",
      "9165     1848   \n",
      "9368     1897   \n",
      "10602    2190   \n",
      "12149    2556   \n",
      "12340    2617   \n",
      "13023    2821   \n",
      "13045    2824   \n",
      "13150    2857   \n",
      "13471    2960   \n",
      "17167    3565   \n",
      "17425    3644   \n",
      "17777    3706   \n",
      "18481    3820   \n",
      "19767    4079   \n",
      "20850    4281   \n",
      "20919    4282   \n",
      "\n",
      "                                                                                                       row  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "314    2*0.9333333333333333*0.7901234567901234*1800Contacts-LensStore*Took5secondsfindrxgetcontactsorde...  \n",
      "1330   3*0.3888888888888889*0.0*8BallPool*I700hundredcoinsInewI300evenIwinninggamesplayerbackingIplayed...  \n",
      "1751   3*0.3888888888888889*0.0*8fitWorkouts&MealPlanner*Shortintenseworkouts,perfectsomeonewho'sreadys...  \n",
      "2587   2*0.9185185185185185*0.7901234567901233*AC-Tips&NewsforAndroidâ¢*Theadsmuchflashingjumpingaroun...  \n",
      "3673   3*0.3888888888888889*0.0*AccountingApp-ZohoBooks*Awesome*743*3*0.3888888888888889*0.0*Accounting...  \n",
      "4512   3*0.3888888888888889*0.0*Agar.io*Allgamegreat!Ireallyenjoyyearsnow.Butthingkeepingrating5stars.W...  \n",
      "4525   2*0.8299580624542039*0.7359717577108886*Agar.io*YourconnectionVERYVERYVERYBAD.WhenIhome,Ifullcon...  \n",
      "5170   1*0.3888888888888889*0.0*AirwayEx-Intubate.Anesthetize.Train.*Greatdetail!MightIask,usercouldcon...  \n",
      "6923   3*0.3888888888888889*0.0*Amino:CommunitiesandChats*Thisgreat!It'sreallyfunmessaroundtalkfellowpe...  \n",
      "6955   3*0.3888888888888889*0.0*Amtrak*Ticketsitinerariesloadloggingin.Whatgoodit?*1380*3*0.38888888888...  \n",
      "8201   2*0.9555555555555555*0.8888888888888888*Any.do:To-dolist,Calendar,Reminders&Planner*Notintuitive...  \n",
      "8875   3*0.3888888888888889*0.0*AppLock-Fingerprint*Notreliable!WhenIrebootphonestopsworking.Istartwork...  \n",
      "9110   3*0.3888888888888889*0.0*Arrow.io*It'sgoodproblemsinternetconnections*1837*3*0.3888888888888889*...  \n",
      "9165   3*0.3888888888888889*0.0*Asana:organizeteamprojects*It'smess.*1848*3*0.3888888888888889*0.0*Asan...  \n",
      "9368   2*0.6277136970960085*0.5824264409512296*Asphalt8:Airborne*Ican'tseemcontinueprogressnewphone.Iol...  \n",
      "10602  2*0.7859563787163059*0.8943562610229276*BBWCupid-BBWDatingApp*It'sgreatviewIhopey'allkeepgoodwor...  \n",
      "12149  1*0.3888888888888889*0.0*BancoItaÃº*Quick,handyisCopy/Paste'sfunctionoflinesofcodeforeasypayment...  \n",
      "12340  3*0.3888888888888889*0.0*BanglaNewspaperâProthomAlo*Toomuchads.Toomuchads.*2617*3*0.3888888888...  \n",
      "13023  3*0.3888888888888889*0.0*BasketballStars*Itsgreat!Buttheresalotareasimprovegameplay!Lookingforwa...  \n",
      "13045  1*0.3888888888888889*0.0*BathroomDecoratingIdeas*Wastetime*2824*1*0.3888888888888889*0.0*Bathroo...  \n",
      "13150  3*0.3888888888888889*0.0*BattlelandsRoyale*Reallyamazinggamecouplethingsstillmissing.Addingsquad...  \n",
      "13471  3*0.3888888888888889*0.0*BeautyCamera-SelfieCamera*Ilikeexceptadsmakeimpossiblegetmuchaccomplish...  \n",
      "17167  3*0.3888888888888889*0.0*Bowmasters*Reallylikegamefar.Greatgameplaylotsfun.Edit:Itookawaystarcon...  \n",
      "17425  3*0.3888888888888889*0.0*BrainWaves-BinauralBeats*Meh.Itriedit.FranklywithoutlotblindtestingIbuy...  \n",
      "17777  3*0.3888888888888889*0.0*Brilliant*ItfunsolvingproblemsbecomesmoneyYouguystakemoneypresentationc...  \n",
      "18481  3*0.3888888888888889*0.0*Buienradar-weer*Ineedradarmap.Lostdays,foundanswerlittleupperrightarrow...  \n",
      "19767  3*0.3888888888888889*0.0*CBSSportsApp-Scores,News,Stats&WatchLive*Thisgreatrecently.Nowlocksclos...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "\n",
      "Outlier detection and removal done -- CPU time: 0.3515908718109131 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.371483\n",
       "Sentiment_Polarity        0.039849\n",
       "Sentiment_Subjectivity   -0.005547\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818172</td>\n",
       "      <td>0.855967</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.636168</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792242</td>\n",
       "      <td>0.660352</td>\n",
       "      <td>4279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.516755</td>\n",
       "      <td>4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4255 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "23       1.0            0.818172                0.855967       4\n",
       "28       1.0            0.738622                0.636168       6\n",
       "...      ...                 ...                     ...     ...\n",
       "20638    1.0            0.792242                0.660352    4279\n",
       "20639    1.0            0.911111                1.000000    4280\n",
       "20972    1.0            0.148148                0.516755    4283\n",
       "20998    1.0            0.388889                0.000000    4284\n",
       "21198    1.0            0.388889                0.000000    4285\n",
       "\n",
       "[4255 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4255, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4255, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.823\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0373\n",
      "Time:                        11:43:08   Log-Likelihood:                -20505.\n",
      "No. Observations:               16646   AIC:                         4.102e+04\n",
      "Df Residuals:                   16642   BIC:                         4.105e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3715      0.018     75.469      0.000       1.336       1.407\n",
      "Sentiment_Polarity         0.0398      0.029      1.395      0.163      -0.016       0.096\n",
      "Sentiment_Subjectivity    -0.0055      0.019     -0.290      0.772      -0.043       0.032\n",
      "New_ID                  3.369e-06   1.34e-06      2.523      0.012    7.52e-07    5.99e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4418.237   Durbin-Watson:                   1.752\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2888.526\n",
      "Skew:                          -0.907   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.065   Cond. No.                     4.86e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.86e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7091286823663995\n",
      "Regression done -- CPU time: 0.037042856216430664 seconds\n",
      "End Pipeline CPU time: 0.38886404037475586 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.03058791160583496 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.372401\n",
       "Sentiment_Polarity        0.040811\n",
       "Sentiment_Subjectivity   -0.005926\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>3376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708183</td>\n",
       "      <td>0.680230</td>\n",
       "      <td>3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>3372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16396    1.0            0.944444                0.864198    3375\n",
       "16398    1.0            0.557819                0.689521    3376\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "...      ...                 ...                     ...     ...\n",
       "16364    1.0            0.388889                0.000000    3370\n",
       "16366    1.0            0.708183                0.680230    3371\n",
       "16372    1.0            0.911111                0.907407    3372\n",
       "16377    1.0            0.388889                0.000000    3373\n",
       "16378    1.0            0.093567                0.806584    3374\n",
       "\n",
       "[4285 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.746\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0414\n",
      "Time:                        11:43:08   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16672   BIC:                         4.111e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3724      0.018     75.599      0.000       1.337       1.408\n",
      "Sentiment_Polarity         0.0408      0.029      1.429      0.153      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0059      0.019     -0.310      0.757      -0.043       0.032\n",
      "New_ID                  3.278e-06   1.33e-06      2.457      0.014    6.63e-07    5.89e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4396.236   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.242\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                     4.87e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.87e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7085140234413241\n",
      "Regression done -- CPU time: 0.040843963623046875 seconds\n",
      "End Pipeline CPU time: 0.07150602340698242 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "FIELDS:\n",
      "\n",
      "Sentiment: 2 failures  2 passes  type ✓  min_length ✗  max_length ✓  allowed_values ✗\n",
      "\n",
      "Sentiment_Polarity: 0 failures  3 passes  type ✓  min ✓  max ✓\n",
      "\n",
      "Sentiment_Subjectivity: 0 failures  4 passes  type ✓  min ✓  max ✓  sign ✓\n",
      "\n",
      "App: 0 failures  4 passes  type ✓  min_length ✓  max_length ✓  max_nulls ✓\n",
      "\n",
      "Translated_Review: 0 failures  3 passes  type ✓  min_length ✓  max_length ✓\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "Constraints passing: 16\n",
      "Constraints failing: 2\n",
      "                    field  failures  passes  type   min min_length   max  \\\n",
      "0               Sentiment         2       2  True   NaN      False   NaN   \n",
      "1      Sentiment_Polarity         0       3  True  True        NaN  True   \n",
      "2  Sentiment_Subjectivity         0       4  True  True        NaN  True   \n",
      "3                     App         0       4  True   NaN       True   NaN   \n",
      "4       Translated_Review         0       3  True   NaN       True   NaN   \n",
      "\n",
      "  max_length  sign max_nulls allowed_values  \n",
      "0       True   NaN       NaN          False  \n",
      "1        NaN   NaN       NaN            NaN  \n",
      "2        NaN  True       NaN            NaN  \n",
      "3       True   NaN      True            NaN  \n",
      "4       True   NaN       NaN            NaN  \n",
      "Row index with constraint failure:\n",
      "\n",
      "[0, 1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 17, 18, 19, 21, 22, 24, 25, 26, 31, 32, 34, 37, 38, 41, 43, 45, 48, 49, 51, 53, 54, 55, 56, 57, 59, 63, 65, 66, 67, 69, 71, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 105, 106, 108, 109, 110, 111, 113, 114, 116, 119, 120, 122, 124, 126, 127, 128, 130, 131, 132, 133, 134, 135, 138, 139, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 154, 155, 157, 158, 159, 160, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 180, 181, 182, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 198, 199, 201, 203, 204, 206, 207, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 241, 243, 245, 247, 249, 251, 254, 256, 258, 259, 262, 263, 265, 266, 267, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 291, 292, 294, 295, 296, 298, 299, 300, 302, 306, 307, 308, 310, 311, 312, 313, 315, 317, 318, 320, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 334, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 350, 353, 354, 356, 358, 359, 360, 361, 363, 364, 366, 367, 370, 371, 372, 373, 374, 375, 379, 381, 382, 383, 385, 388, 390, 391, 392, 394, 395, 397, 398, 400, 401, 402, 403, 404, 406, 410, 411, 413, 415, 417, 419, 420, 422, 423, 424, 428, 430, 431, 432, 433, 434, 436, 440, 441, 444, 446, 447, 448, 449, 450, 454, 455, 457, 458, 460, 461, 462, 463, 464, 466, 467, 468, 469, 470, 472, 473, 476, 477, 480, 482, 483, 484, 486, 487, 488, 493, 494, 497, 498, 499, 500, 504, 505, 506, 507, 510, 512, 514, 517, 520, 521, 522, 523, 524, 525, 527, 528, 529, 530, 531, 533, 534, 535, 537, 538, 540, 542, 543, 544, 545, 547, 549, 550, 553, 556, 557, 560, 561, 562, 563, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 595, 597, 598, 599, 601, 604, 605, 610, 611, 612, 613, 616, 617, 618, 619, 620, 621, 622, 624, 626, 627, 629, 630, 631, 633, 634, 636, 640, 641, 642, 644, 645, 649, 650, 652, 654, 656, 657, 658, 660, 662, 663, 664, 666, 667, 668, 669, 670, 673, 674, 675, 678, 679, 680, 682, 684, 687, 688, 689, 690, 692, 693, 695, 697, 698, 699, 701, 706, 708, 709, 710, 712, 717, 720, 725, 726, 727, 730, 877, 888, 890, 894, 899, 905, 909, 923, 928, 942, 946, 948, 951, 954, 970, 972, 978, 979, 981, 982, 988, 993, 995, 1008, 1013, 1015, 1023, 1034, 1037, 1038, 1039, 1041, 1044, 1046, 1057, 1060, 1063, 1066, 1077, 1080, 1091, 1104, 1109, 1114, 1131, 1154, 1155, 1157, 1160, 1167, 1175, 1177, 1187, 1188, 1193, 1197, 1200, 1204, 1209, 1215, 1221, 1226, 1228, 1233, 1235, 1236, 1243, 1252, 1253, 1256, 1257, 1262, 1264, 1265, 1273, 1275, 1283, 1297, 1310, 1320, 1325, 1327, 1328, 1331, 1333, 1334, 1335, 1337, 1340, 1341, 1347, 1348, 1350, 1352, 1353, 1355, 1356, 1357, 1358, 1360, 1362, 1364, 1366, 1367, 1370, 1371, 1372, 1374, 1375, 1376, 1378, 1379, 1380, 1382, 1383, 1384, 1389, 1390, 1391, 1393, 1394, 1395, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1407, 1408, 1410, 1411, 1412, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1423, 1424, 1425, 1429, 1430, 1431, 1434, 1435, 1437, 1438, 1440, 1441, 1443, 1444, 1445, 1448, 1450, 1453, 1454, 1455, 1456, 1457, 1464, 1467, 1469, 1470, 1471, 1474, 1476, 1477, 1479, 1481, 1482, 1483, 1485, 1486, 1488, 1489, 1494, 1495, 1496, 1497, 1498, 1499, 1502, 1503, 1505, 1507, 1508, 1509, 1510, 1511, 1512, 1514, 1516, 1517, 1520, 1522, 1524, 1527, 1529, 1530, 1531, 1534, 1535, 1538, 1540, 1544, 1546, 1548, 1551, 1552, 1555, 1556, 1559, 1560, 1562, 1563, 1564, 1565, 1567, 1569, 1570, 1572, 1573, 1578, 1579, 1581, 1584, 1587, 1588, 1589, 1592, 1595, 1596, 1597, 1598, 1600, 1602, 1603, 1605, 1610, 1611, 1615, 1616, 1618, 1619, 1620, 1622, 1623, 1624, 1625, 1628, 1630, 1631, 1632, 1633, 1634, 1637, 1638, 1639, 1640, 1642, 1644, 1645, 1646, 1648, 1649, 1651, 1653, 1656, 1659, 1661, 1662, 1663, 1664, 1667, 1669, 1670, 1671, 1674, 1675, 1677, 1678, 1679, 1680, 1687, 1691, 1692, 1693, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1714, 1715, 1716, 1717, 1722, 1723, 1725, 1726, 1727, 1729, 1731, 1733, 1735, 1737, 1738, 1739, 1740, 1741, 1743, 1744, 1745, 1747, 1748, 1749, 1750, 1752, 1756, 1758, 1759, 1760, 1761, 1762, 1763, 1767, 1768, 1769, 1770, 1773, 1774, 1777, 1778, 1779, 1780, 1781, 1782, 1784, 1787, 1788, 1790, 1792, 1793, 1795, 1796, 1797, 1798, 1800, 1803, 1805, 1806, 1807, 1808, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1818, 1819, 1820, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1832, 1834, 1835, 1836, 1839, 1842, 1843, 1846, 1847, 1849, 1850, 1852, 1853, 1855, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1867, 1868, 1869, 1870, 1871, 1872, 1875, 1877, 1878, 1880, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1900, 2048, 2055, 2057, 2058, 2063, 2066, 2073, 2075, 2085, 2092, 2094, 2097, 2098, 2125, 2127, 2129, 2130, 2134, 2137, 2139, 2145, 2149, 2151, 2154, 2158, 2161, 2162, 2166, 2168, 2169, 2180, 2181, 2182, 2189, 2194, 2196, 2198, 2202, 2207, 2210, 2211, 2213, 2217, 2218, 2220, 2226, 2228, 2233, 2237, 2240, 2246, 2249, 2251, 2252, 2253, 2256, 2259, 2275, 2276, 2277, 2282, 2290, 2291, 2293, 2294, 2297, 2298, 2299, 2301, 2304, 2305, 2308, 2309, 2310, 2313, 2314, 2315, 2316, 2317, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2331, 2332, 2335, 2336, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2349, 2350, 2354, 2355, 2356, 2360, 2361, 2362, 2365, 2370, 2372, 2374, 2375, 2380, 2381, 2382, 2384, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2396, 2398, 2401, 2402, 2403, 2405, 2406, 2407, 2408, 2409, 2410, 2412, 2415, 2416, 2417, 2418, 2419, 2421, 2423, 2424, 2425, 2426, 2427, 2428, 2431, 2433, 2437, 2438, 2441, 2443, 2445, 2446, 2447, 2448, 2450, 2453, 2454, 2455, 2456, 2458, 2459, 2460, 2461, 2462, 2463, 2466, 2467, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2481, 2482, 2483, 2485, 2486, 2487, 2488, 2489, 2490, 2493, 2494, 2495, 2496, 2497, 2499, 2500, 2501, 2502, 2503, 2506, 2508, 2509, 2510, 2512, 2517, 2519, 2520, 2522, 2523, 2524, 2527, 2528, 2529, 2530, 2532, 2534, 2535, 2537, 2538, 2539, 2540, 2541, 2543, 2544, 2545, 2547, 2548, 2550, 2552, 2553, 2554, 2555, 2558, 2560, 2563, 2564, 2565, 2570, 2571, 2576, 2577, 2581, 2583, 2584, 2585, 2592, 2593, 2594, 2596, 2597, 2599, 2603, 2604, 2605, 2607, 2609, 2614, 2615, 2616, 2617, 2619, 2621, 2623, 2625, 2627, 2628, 2629, 2631, 2633, 2636, 2638, 2640, 2644, 2646, 2647, 2649, 2650, 2651, 2652, 2653, 2654, 2657, 2658, 2660, 2661, 2668, 2670, 2672, 2676, 2679, 2690, 2693, 2694, 2810, 2815, 2816, 2817, 2819, 2820, 2821, 2822, 2824, 2826, 2827, 2828, 2832, 2833, 2841, 2845, 2848, 2849, 2850, 2851, 2852, 2853, 2855, 2856, 2857, 2858, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2874, 2876, 2877, 2878, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2888, 2889, 2890, 2891, 2893, 2894, 2896, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2908, 2909, 2911, 2912, 2915, 2916, 2919, 2921, 2922, 2926, 2928, 2930, 2931, 2933, 2934, 2935, 2936, 2937, 2939, 2944, 2945, 2946, 2948, 2951, 2952, 2953, 2954, 2956, 2957, 2958, 2960, 2961, 2962, 2963, 2964, 2965, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2976, 2977, 2978, 2981, 2982, 2983, 2985, 2989, 2990, 2991, 2997, 2998, 2999, 3000, 3002, 3004, 3007, 3009, 3010, 3011, 3013, 3014, 3015, 3017, 3018, 3020, 3021, 3024, 3025, 3026, 3027, 3028, 3031, 3032, 3034, 3035, 3038, 3040, 3042, 3043, 3044, 3045, 3049, 3051, 3052, 3056, 3060, 3062, 3065, 3066, 3072, 3076, 3077, 3078, 3079, 3080, 3081, 3083, 3084, 3086, 3087, 3088, 3090, 3091, 3093, 3095, 3096, 3097, 3099, 3101, 3103, 3104, 3105, 3107, 3108, 3110, 3112, 3113, 3115, 3116, 3118, 3119, 3120, 3122, 3123, 3124, 3125, 3127, 3129, 3130, 3131, 3132, 3136, 3137, 3139, 3141, 3142, 3143, 3144, 3147, 3148, 3149, 3151, 3152, 3154, 3157, 3159, 3162, 3163, 3166, 3167, 3170, 3172, 3176, 3177, 3179, 3181, 3182, 3183, 3187, 3190, 3191, 3193, 3195, 3196, 3198, 3199, 3200, 3204, 3205, 3208, 3210, 3213, 3219, 3232, 3335, 3338, 3344, 3347, 3354, 3358, 3359, 3361, 3362, 3366, 3367, 3373, 3375, 3379, 3386, 3387, 3388, 3391, 3392, 3394, 3395, 3398, 3403, 3406, 3409, 3413, 3414, 3415, 3416, 3417, 3420, 3422, 3423, 3425, 3427, 3429, 3431, 3433, 3434, 3436, 3437, 3438, 3439, 3443, 3445, 3447, 3452, 3453, 3455, 3461, 3465, 3466, 3467, 3468, 3470, 3474, 3477, 3484, 3485, 3487, 3498, 3499, 3504, 3506, 3507, 3509, 3512, 3513, 3515, 3517, 3519, 3521, 3525, 3528, 3529, 3530, 3533, 3534, 3536, 3538, 3540, 3541, 3544, 3545, 3547, 3548, 3549, 3551, 3553, 3554, 3555, 3556, 3557, 3559, 3562, 3563, 3567, 3569, 3570, 3573, 3575, 3577, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3589, 3590, 3591, 3593, 3594, 3595, 3597, 3601, 3602, 3603, 3605, 3606, 3609, 3611, 3612, 3614, 3616, 3618, 3619, 3620, 3621, 3622, 3627, 3630, 3633, 3636, 3637, 3638, 3639, 3640, 3642, 3643, 3645, 3646, 3651, 3655, 3656, 3661, 3662, 3663, 3666, 3667, 3668, 3669, 3671, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3686, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3699, 3700, 3701, 3702, 3703, 3705, 3706, 3707, 3708, 3709, 3712, 3713, 3714, 3716, 3720, 3723, 3726, 3729, 3732, 3737, 3738, 3739, 3740, 3741, 3743, 3746, 3750, 3751, 3753, 3756, 3758, 3759, 3762, 3763, 3765, 3768, 3770, 3773, 3774, 3777, 3780, 3782, 3783, 3784, 3786, 3794, 3795, 3796, 3798, 3801, 3802, 3803, 3807, 3808, 3809, 3810, 3811, 3816, 3817, 3819, 3821, 3822, 3842, 3939, 3949, 3950, 3951, 3953, 3955, 3958, 3961, 3966, 3968, 3970, 3971, 3973, 3976, 3978, 3979, 3982, 3985, 3986, 3987, 3989, 3991, 3994, 3996, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4009, 4011, 4012, 4013, 4017, 4020, 4021, 4022, 4023, 4024, 4027, 4029, 4033, 4036, 4037, 4038, 4039, 4044, 4045, 4046, 4047, 4049, 4050, 4051, 4052, 4053, 4054, 4057, 4060, 4061, 4062, 4065, 4067, 4069, 4070, 4072, 4075, 4077, 4078, 4079, 4080, 4081, 4084, 4086, 4089, 4093, 4094, 4095, 4098, 4099, 4101, 4102, 4104, 4107, 4110, 4111, 4112, 4113, 4115, 4118, 4120, 4121, 4122, 4123, 4124, 4125, 4128, 4130, 4131, 4132, 4133, 4134, 4135, 4137, 4139, 4140, 4142, 4144, 4145, 4146, 4148, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4160, 4161, 4162, 4165, 4166, 4167, 4168, 4170, 4171, 4172, 4174, 4175, 4177, 4178, 4179, 4180, 4181, 4183, 4185, 4186, 4188, 4192, 4197, 4198, 4201, 4202, 4204, 4210, 4211, 4212, 4213, 4215, 4218, 4219, 4220, 4221, 4223, 4226, 4228, 4229, 4230, 4231, 4234, 4236, 4237, 4240, 4241, 4243, 4245, 4246, 4248, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4261, 4263, 4264, 4266, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4278, 4279, 4280, 4281, 4284, 4286, 4287, 4291, 4292, 4295, 4296, 4297, 4298, 4301, 4303, 4314, 4316, 4317, 4319, 4321, 4322, 4326, 4331, 4333, 4335, 4347, 4348, 4351, 4353, 4356, 4357, 4361, 4362, 4363, 4366, 4370, 4371, 4378, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4491, 4499, 4502, 4503, 4516, 4517, 4518, 4522, 4523, 4526, 4529, 4530, 4535, 4537, 4539, 4542, 4543, 4544, 4547, 4549, 4553, 4556, 4557, 4561, 4562, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4576, 4579, 4583, 4584, 4585, 4586, 4589, 4591, 4592, 4593, 4594, 4600, 4601, 4612, 4615, 4618, 4619, 4621, 4623, 4625, 4626, 4627, 4633, 4635, 4639, 4641, 4642, 4645, 4646, 4649, 4654, 4657, 4658, 4659, 4660, 4661, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 4672, 4678, 4681, 4683, 4684, 4685, 4687, 4689, 4691, 4696, 4697, 4698, 4700, 4702, 4705, 4708, 4710, 4712, 4713, 4715, 4718, 4719, 4720, 4722, 4724, 4727, 4728, 4732, 4734, 4735, 4738, 4739, 4740, 4741, 4742, 4745, 4746, 4747, 4749, 4750, 4751, 4752, 4755, 4756, 4757, 4760, 4761, 4764, 4765, 4767, 4770, 4774, 4776, 4777, 4778, 4781, 4783, 4788, 4790, 4792, 4800, 4807, 4810, 4811, 4812, 4817, 4818, 4819, 4821, 4826, 4831, 4833, 4836, 4837, 4839, 4840, 4847, 4849, 4852, 4854, 4858, 4866, 4871, 4873, 4881, 4883, 4895, 4899, 4916, 4926, 4937, 4940, 4941, 4942, 4949, 4955, 4956, 4961, 4967, 4968, 4969, 4973, 4977, 4981, 4983, 4985, 4988, 4991, 4993, 4995, 4997, 4998, 5002, 5006, 5016, 5018, 5021, 5022, 5023, 5024, 5026, 5029, 5036, 5038, 5041, 5043, 5048, 5054, 5057, 5059, 5060, 5061, 5064, 5067, 5070, 5073, 5074, 5076, 5077, 5082, 5083, 5085, 5091, 5094, 5097, 5098, 5099, 5101, 5103, 5105, 5106, 5108, 5111, 5113, 5115, 5119, 5120, 5123, 5124, 5126, 5128, 5132, 5134, 5135, 5136, 5138, 5140, 5142, 5143, 5144, 5146, 5149, 5150, 5151, 5152, 5154, 5156, 5158, 5161, 5162, 5164, 5165, 5167, 5168, 5171, 5172, 5174, 5175, 5177, 5178, 5180, 5183, 5184, 5185, 5187, 5188, 5189, 5190, 5191, 5192, 5194, 5195, 5197, 5198, 5200, 5201, 5202, 5203, 5204, 5205, 5206, 5207, 5208, 5209, 5210, 5211, 5212, 5214, 5215, 5216, 5218, 5219, 5220, 5221, 5222, 5224, 5225, 5228, 5229, 5230, 5231, 5232, 5233, 5235, 5236, 5239, 5240, 5244, 5245, 5247, 5248, 5250, 5252, 5253, 5254, 5256, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5272, 5275, 5276, 5277, 5278, 5279, 5280, 5282, 5284, 5285, 5286, 5287, 5289, 5292, 5294, 5295, 5296, 5297, 5298, 5299, 5301, 5302, 5304, 5305, 5306, 5307, 5308, 5310, 5311, 5312, 5314, 5315, 5316, 5321, 5325, 5330, 5332, 5333, 5336, 5338, 5341, 5342, 5344, 5346, 5347, 5349, 5350, 5351, 5352, 5356, 5358, 5359, 5360, 5361, 5363, 5364, 5365, 5367, 5368, 5369, 5370, 5371, 5373, 5374, 5378, 5380, 5382, 5385, 5386, 5387, 5394, 5396, 5399, 5400, 5401, 5403, 5405, 5406, 5409, 5410, 5411, 5412, 5414, 5415, 5417, 5418, 5421, 5422, 5424, 5425, 5429, 5434, 5527, 5528, 5529, 5530, 5531, 5532, 5538, 5540, 5541, 5542, 5544, 5547, 5550, 5556, 5558, 5560, 5563, 5565, 5568, 5569, 5571, 5572, 5573, 5574, 5577, 5578, 5579, 5581, 5584, 5586, 5588, 5590, 5591, 5592, 5593, 5595, 5597, 5599, 5600, 5601, 5603, 5604, 5608, 5610, 5611, 5612, 5615, 5617, 5618, 5624, 5627, 5628, 5631, 5632, 5635, 5637, 5638, 5639, 5640, 5642, 5643, 5644, 5646, 5648, 5649, 5650, 5651, 5653, 5656, 5657, 5658, 5660, 5669, 5672, 5673, 5675, 5676, 5677, 5678, 5679, 5683, 5685, 5688, 5690, 5691, 5692, 5693, 5695, 5696, 5699, 5700, 5701, 5702, 5704, 5705, 5707, 5708, 5709, 5711, 5714, 5716, 5717, 5718, 5719, 5721, 5723, 5724, 5726, 5732, 5733, 5735, 5736, 5739, 5740, 5742, 5745, 5746, 5749, 5751, 5753, 5754, 5756, 5757, 5758, 5759, 5763, 5765, 5768, 5769, 5770, 5772, 5774, 5777, 5780, 5781, 5782, 5785, 5788, 5789, 5791, 5792, 5793, 5794, 5796, 5797, 5799, 5800, 5802, 5805, 5806, 5807, 5809, 5811, 5813, 5816, 5818, 5819, 5820, 5821, 5823, 5824, 5825, 5827, 5828, 5830, 5834, 5836, 5837, 5838, 5839, 5840, 5844, 5845, 5847, 5848, 5852, 5858, 5859, 5860, 5862, 5863, 5864, 5865, 5866, 5867, 5868, 5869, 5870, 5871, 5874, 5876, 5877, 5879, 5882, 5884, 5885, 5886, 5887, 5888, 5893, 5894, 5895, 5898, 5899, 5901, 5902, 5904, 5908, 5911, 5912, 5915, 5916, 5918, 5924, 5931, 5932, 6050, 6052, 6062, 6064, 6068, 6070, 6073, 6074, 6076, 6077, 6080, 6081, 6083, 6085, 6086, 6092, 6093, 6094, 6096, 6102, 6106, 6107, 6109, 6114, 6115, 6116, 6117, 6119, 6120, 6122, 6126, 6128, 6129, 6130, 6131, 6132, 6134, 6135, 6136, 6139, 6140, 6141, 6142, 6145, 6146, 6148, 6150, 6151, 6153, 6154, 6155, 6156, 6157, 6159, 6161, 6162, 6165, 6166, 6168, 6170, 6173, 6174, 6175, 6176, 6178, 6179, 6182, 6184, 6185, 6186, 6187, 6188, 6190, 6191, 6192, 6193, 6195, 6199, 6202, 6205, 6208, 6209, 6212, 6216, 6217, 6218, 6219, 6220, 6221, 6223, 6224, 6225, 6228, 6230, 6232, 6233, 6234, 6235, 6238, 6239, 6240, 6241, 6243, 6244, 6246, 6247, 6248, 6251, 6253, 6255, 6256, 6257, 6261, 6263, 6265, 6266, 6267, 6269, 6270, 6271, 6273, 6274, 6275, 6277, 6278, 6279, 6280, 6283, 6284, 6285, 6286, 6288, 6289, 6290, 6291, 6292, 6293, 6295, 6297, 6298, 6299, 6305, 6306, 6307, 6309, 6311, 6312, 6315, 6316, 6317, 6319, 6320, 6321, 6324, 6325, 6326, 6329, 6333, 6334, 6336, 6338, 6341, 6343, 6344, 6345, 6346, 6348, 6349, 6351, 6352, 6353, 6355, 6356, 6357, 6360, 6361, 6362, 6364, 6365, 6366, 6369, 6371, 6372, 6374, 6375, 6377, 6378, 6380, 6381, 6383, 6384, 6389, 6390, 6394, 6397, 6398, 6399, 6401, 6402, 6406, 6407, 6410, 6414, 6415, 6418, 6419, 6420, 6421, 6422, 6423, 6425, 6426, 6427, 6428, 6429, 6432, 6433, 6435, 6436, 6437, 6438, 6439, 6440, 6441, 6442, 6443, 6444, 6445, 6447, 6449, 6450, 6451, 6454, 6458, 6462, 6463, 6465, 6466, 6467, 6468, 6469, 6471, 6472, 6474, 6476, 6477, 6478, 6479, 6481, 6483, 6484, 6485, 6488, 6489, 6492, 6493, 6495, 6499, 6500, 6503, 6507, 6509, 6516, 6526, 6630, 6641, 6642, 6643, 6649, 6655, 6657, 6659, 6660, 6664, 6665, 6667, 6668, 6679, 6689, 6690, 6691, 6695, 6696, 6699, 6701, 6705, 6710, 6711, 6715, 6716, 6718, 6729, 6730, 6733, 6735, 6736, 6739, 6743, 6744, 6747, 6748, 6751, 6757, 6773, 6783, 6785, 6786, 6788, 6791, 6793, 6796, 6798, 6799, 6806, 6811, 6815, 6816, 6824, 6827, 6828, 6829, 6830, 6831, 6833, 6837, 6838, 6843, 6846, 6847, 6849, 6850, 6851, 6852, 6854, 6855, 6856, 6860, 6861, 6862, 6865, 6867, 6868, 6869, 6870, 6871, 6873, 6874, 6875, 6876, 6878, 6880, 6881, 6883, 6884, 6885, 6886, 6887, 6888, 6889, 6890, 6891, 6893, 6894, 6898, 6899, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6907, 6909, 6911, 6913, 6914, 6915, 6917, 6918, 6922, 6925, 6927, 6928, 6929, 6930, 6931, 6932, 6933, 6935, 6937, 6938, 6941, 6945, 6946, 6947, 6949, 6951, 6952, 6954, 6956, 6957, 6959, 6960, 6961, 6962, 6963, 6965, 6968, 6969, 6970, 6971, 6972, 6973, 6976, 6977, 6978, 6979, 6981, 6982, 6983, 6984, 6985, 6986, 6987, 6988, 6991, 6992, 6993, 6994, 6995, 6996, 6998, 6999, 7000, 7003, 7004, 7005, 7006, 7007, 7009, 7010, 7011, 7015, 7017, 7020, 7021, 7022, 7025, 7026, 7029, 7031, 7035, 7036, 7039, 7041, 7043, 7045, 7047, 7048, 7049, 7050, 7053, 7054, 7055, 7056, 7058, 7059, 7061, 7062, 7063, 7064, 7065, 7067, 7068, 7070, 7071, 7072, 7075, 7078, 7081, 7082, 7083, 7085, 7087, 7089, 7090, 7091, 7092, 7095, 7096, 7097, 7100, 7101, 7105, 7106, 7107, 7109, 7110, 7112, 7114, 7116, 7118, 7122, 7125, 7127, 7129, 7131, 7133, 7134, 7135, 7138, 7139, 7140, 7141, 7145, 7146, 7147, 7151, 7153, 7154, 7160, 7161, 7162, 7164, 7165, 7171, 7173, 7175, 7181, 7187, 7190, 7193, 7313, 7314, 7317, 7323, 7327, 7328, 7329, 7330, 7332, 7337, 7338, 7343, 7344, 7345, 7346, 7347, 7350, 7352, 7356, 7357, 7358, 7359, 7360, 7361, 7364, 7365, 7366, 7368, 7369, 7370, 7371, 7373, 7375, 7376, 7380, 7381, 7383, 7384, 7385, 7386, 7387, 7388, 7389, 7390, 7391, 7392, 7395, 7396, 7397, 7398, 7400, 7402, 7404, 7405, 7407, 7409, 7410, 7411, 7412, 7415, 7416, 7420, 7421, 7424, 7427, 7430, 7435, 7437, 7438, 7439, 7442, 7443, 7445, 7447, 7448, 7449, 7450, 7452, 7453, 7454, 7455, 7460, 7462, 7463, 7464, 7469, 7470, 7471, 7472, 7474, 7476, 7477, 7478, 7486, 7487, 7488, 7490, 7494, 7495, 7496, 7497, 7498, 7499, 7500, 7502, 7503, 7504, 7505, 7509, 7512, 7513, 7517, 7518, 7519, 7521, 7523, 7524, 7527, 7529, 7531, 7532, 7535, 7538, 7541, 7542, 7543, 7544, 7545, 7546, 7547, 7549, 7551, 7552, 7553, 7554, 7555, 7556, 7560, 7561, 7562, 7563, 7564, 7565, 7568, 7575, 7578, 7583, 7584, 7585, 7587, 7591, 7596, 7598, 7601, 7602, 7604, 7605, 7606, 7607, 7608, 7610, 7611, 7615, 7616, 7620, 7621, 7623, 7626, 7627, 7628, 7633, 7634, 7635, 7636, 7638, 7639, 7641, 7642, 7644, 7647, 7648, 7649, 7650, 7653, 7655, 7657, 7658, 7659, 7660, 7661, 7664, 7666, 7667, 7668, 7669, 7672, 7674, 7677, 7678, 7679, 7681, 7682, 7683, 7684, 7686, 7687, 7690, 7702, 7706, 7708, 7709, 7711, 7715, 7719, 7723, 7725, 7735, 7739, 7740, 7743, 7835, 7837, 7841, 7850, 7853, 7859, 7863, 7864, 7867, 7868, 7870, 7871, 7872, 7873, 7874, 7875, 7877, 7878, 7879, 7880, 7883, 7884, 7886, 7887, 7889, 7890, 7894, 7896, 7898, 7899, 7900, 7902, 7903, 7904, 7906, 7907, 7910, 7913, 7918, 7920, 7922, 7926, 7929, 7930, 7932, 7936, 7938, 7939, 7943, 7945, 7947, 7948, 7949, 7950, 7958, 7960, 7962, 7964, 7967, 7978, 7980, 7981, 7983, 7986, 7989, 7990, 7992, 7993, 7997, 7998, 7999, 8000, 8001, 8002, 8003, 8005, 8007, 8010, 8011, 8012, 8016, 8017, 8018, 8019, 8023, 8024, 8025, 8030, 8031, 8032, 8033, 8035, 8036, 8037, 8038, 8039, 8040, 8041, 8045, 8046, 8049, 8051, 8054, 8056, 8057, 8058, 8060, 8062, 8064, 8067, 8068, 8069, 8071, 8075, 8077, 8079, 8082, 8083, 8085, 8086, 8090, 8094, 8095, 8097, 8098, 8099, 8101, 8102, 8104, 8105, 8107, 8108, 8110, 8111, 8112, 8113, 8114, 8115, 8116, 8117, 8118, 8121, 8122, 8124, 8126, 8128, 8129, 8131, 8132, 8133, 8134, 8135, 8136, 8137, 8139, 8140, 8141, 8143, 8144, 8145, 8146, 8149, 8152, 8153, 8156, 8158, 8160, 8162, 8164, 8165, 8168, 8171, 8172, 8173, 8174, 8176, 8181, 8182, 8184, 8186, 8188, 8191, 8193, 8194, 8195, 8197, 8199, 8209, 8211, 8212, 8214, 8228, 8229, 8230, 8231, 8241, 8243, 8254, 8264, 8339, 8340, 8344, 8345, 8349, 8350, 8352, 8353, 8356, 8365, 8372, 8375, 8376, 8382, 8383, 8385, 8387, 8389, 8390, 8396, 8402, 8404, 8410, 8412, 8415, 8416, 8420, 8421, 8422, 8433, 8434, 8435, 8436, 8439, 8440, 8441, 8443, 8445, 8446, 8447, 8449, 8451, 8453, 8455, 8460, 8461, 8462, 8464, 8473, 8474, 8475, 8476, 8477, 8482, 8484, 8485, 8486, 8489, 8499, 8505, 8506, 8507, 8510, 8514, 8516, 8517, 8521, 8527, 8534, 8536, 8538, 8539, 8540, 8541, 8542, 8544, 8546, 8547, 8550, 8552, 8554, 8555, 8556, 8558, 8560, 8561, 8562, 8564, 8566, 8567, 8569, 8571, 8573, 8576, 8577, 8579, 8580, 8581, 8582, 8583, 8585, 8587, 8588, 8589, 8591, 8593, 8595, 8597, 8601, 8602, 8603, 8604, 8605, 8606, 8607, 8609, 8613, 8615, 8616, 8619, 8620, 8621, 8622, 8624, 8626, 8627, 8629, 8630, 8631, 8632, 8635, 8636, 8637, 8638, 8639, 8643, 8644, 8645, 8646, 8647, 8648, 8652, 8653, 8656, 8657, 8658, 8660, 8661, 8662, 8665, 8668, 8669, 8673, 8674, 8675, 8676, 8677, 8678, 8680, 8690, 8693, 8695, 8697, 8699, 8702, 8703, 8705, 8707, 8708, 8711, 8713, 8717, 8721, 8722, 8723, 8724, 8728, 8729, 8730, 8731, 8740, 8743, 8745, 8748, 8760, 8771, 8779, 8788, 8800, 8818, 8824, 8825, 8826, 8828, 8834, 8837, 8840, 8841, 8847, 8850, 8852, 8859, 8862, 8867, 8873, 8874, 8879, 8880, 8886, 8888, 8891, 8893, 8896, 8899, 8900, 8901, 8902, 8903, 8904, 8905, 8906, 8907, 8910, 8911, 8914, 8915, 8916, 8917, 8921, 8922, 8923, 8924, 8925, 8927, 8928, 8931, 8932, 8933, 8935, 8939, 8949, 8950, 8953, 8954, 8955, 8956, 8958, 8960, 8962, 8963, 8964, 8965, 8969, 8970, 8973, 8980, 8981, 8985, 8986, 8987, 8990, 8994, 8995, 8996, 8999, 9000, 9004, 9005, 9007, 9008, 9010, 9012, 9017, 9018, 9019, 9022, 9024, 9026, 9027, 9030, 9034, 9035, 9036, 9037, 9038, 9039, 9041, 9043, 9044, 9045, 9046, 9047, 9049, 9051, 9052, 9053, 9054, 9055, 9056, 9057, 9059, 9060, 9062, 9065, 9066, 9069, 9071, 9072, 9073, 9074, 9075, 9076, 9077, 9078, 9080, 9081, 9082, 9083, 9084, 9086, 9087, 9088, 9089, 9090, 9091, 9092, 9094, 9095, 9097, 9099, 9100, 9101, 9102, 9103, 9104, 9105, 9106, 9107, 9111, 9112, 9113, 9114, 9115, 9116, 9118, 9119, 9120, 9121, 9122, 9125, 9131, 9132, 9133, 9134, 9135, 9136, 9137, 9138, 9140, 9144, 9146, 9147, 9148, 9149, 9150, 9151, 9152, 9153, 9154, 9157, 9160, 9161, 9167, 9170, 9172, 9174, 9175, 9176, 9177, 9182, 9183, 9184, 9185, 9198, 9201, 9206, 9212, 9214, 9218, 9223, 9229, 9230, 9231, 9233, 9237, 9238, 9247, 9249, 9251, 9252, 9254, 9258, 9260, 9268, 9276, 9277, 9280, 9281, 9288, 9290, 9291, 9293, 9296, 9297, 9299, 9301, 9303, 9304, 9307, 9311, 9314, 9317, 9318, 9323, 9325, 9330, 9331, 9334, 9336, 9337, 9338, 9341, 9342, 9347, 9348, 9350, 9353, 9356, 9357, 9359, 9360, 9361, 9363, 9364, 9365, 9367, 9376, 9377, 9378, 9379, 9380, 9381, 9382, 9383, 9384, 9385, 9387, 9389, 9391, 9392, 9395, 9401, 9404, 9406, 9407, 9410, 9413, 9414, 9415, 9417, 9422, 9425, 9426, 9427, 9429, 9430, 9432, 9434, 9441, 9443, 9444, 9445, 9446, 9447, 9450, 9451, 9452, 9455, 9457, 9459, 9460, 9462, 9467, 9468, 9471, 9472, 9474, 9475, 9476, 9477, 9481, 9482, 9483, 9484, 9486, 9488, 9489, 9491, 9492, 9494, 9495, 9497, 9498, 9499, 9500, 9501, 9502, 9503, 9504, 9506, 9509, 9510, 9511, 9513, 9514, 9515, 9517, 9518, 9519, 9521, 9523, 9525, 9526, 9528, 9536, 9537, 9540, 9542, 9544, 9545, 9547, 9560, 9567, 9570, 9572, 9577, 9585, 9591, 9600, 9611, 9612, 9614, 9618, 9623, 9624, 9625, 9640, 9642, 9643, 9646, 9648, 9652, 9662, 9665, 9669, 9670, 9672, 9673, 9674, 9675, 9678, 9679, 9681, 9682, 9684, 9685, 9688, 9689, 9690, 9692, 9696, 9697, 9699, 9701, 9702, 9704, 9705, 9706, 9707, 9709, 9710, 9715, 9717, 9718, 9722, 9724, 9726, 9727, 9728, 9731, 9733, 9735, 9737, 9738, 9741, 9742, 9743, 9744, 9745, 9747, 9748, 9749, 9751, 9752, 9753, 9755, 9758, 9759, 9760, 9761, 9762, 9763, 9765, 9766, 9767, 9768, 9769, 9770, 9771, 9772, 9777, 9778, 9779, 9781, 9782, 9783, 9784, 9786, 9787, 9788, 9789, 9790, 9791, 9793, 9794, 9795, 9797, 9798, 9799, 9800, 9801, 9802, 9803, 9804, 9808, 9812, 9813, 9815, 9816, 9818, 9821, 9822, 9823, 9825, 9826, 9829, 9830, 9831, 9832, 9833, 9834, 9836, 9838, 9839, 9840, 9841, 9842, 9844, 9845, 9847, 9849, 9850, 9853, 9854, 9855, 9856, 9857, 9858, 9859, 9862, 9863, 9866, 9870, 9871, 9872, 9873, 9874, 9875, 9876, 9878, 9879, 9880, 9881, 9882, 9883, 9884, 9885, 9886, 9888, 9891, 9892, 9893, 9896, 9897, 9898, 9899, 9901, 9902, 9904, 9906, 9907, 9911, 9912, 9916, 9920, 9922, 9924, 9926, 9927, 9928, 9929, 9935, 9943, 9948, 9951, 9953, 9954, 10001, 10003, 10005, 10009, 10015, 10017, 10019, 10021, 10022, 10025, 10028, 10031, 10032, 10034, 10036, 10037, 10041, 10042, 10046, 10049, 10051, 10052, 10056, 10057, 10059, 10060, 10062, 10065, 10067, 10069, 10071, 10077, 10079, 10080, 10087, 10089, 10095, 10096, 10098, 10100, 10101, 10104, 10111, 10114, 10117, 10119, 10125, 10127, 10128, 10129, 10130, 10132, 10134, 10136, 10138, 10142, 10143, 10148, 10150, 10162, 10163, 10168, 10171, 10180, 10184, 10189, 10194, 10195, 10197, 10198, 10200, 10202, 10204, 10208, 10211, 10212, 10215, 10226, 10227, 10228, 10229, 10230, 10233, 10236, 10238, 10242, 10243, 10244, 10245, 10247, 10249, 10250, 10252, 10254, 10259, 10260, 10261, 10265, 10267, 10268, 10269, 10270, 10272, 10273, 10274, 10277, 10279, 10281, 10282, 10283, 10284, 10285, 10289, 10291, 10292, 10294, 10297, 10299, 10301, 10302, 10303, 10304, 10305, 10307, 10309, 10311, 10312, 10313, 10318, 10319, 10321, 10323, 10325, 10326, 10327, 10328, 10329, 10330, 10332, 10333, 10337, 10339, 10342, 10345, 10346, 10348, 10350, 10351, 10352, 10354, 10355, 10358, 10360, 10364, 10367, 10368, 10370, 10372, 10373, 10374, 10375, 10376, 10377, 10378, 10380, 10382, 10384, 10385, 10388, 10389, 10390, 10391, 10396, 10397, 10398, 10399, 10400, 10401, 10402, 10403, 10404, 10406, 10407, 10408, 10413, 10415, 10417, 10418, 10419, 10420, 10421, 10425, 10426, 10429, 10432, 10433, 10434, 10436, 10437, 10438, 10440, 10441, 10442, 10443, 10444, 10445, 10447, 10448, 10449, 10450, 10451, 10453, 10454, 10455, 10456, 10459, 10464, 10467, 10468, 10469, 10470, 10472, 10473, 10479, 10480, 10481, 10483, 10484, 10485, 10486, 10487, 10489, 10490, 10492, 10493, 10495, 10496, 10497, 10498, 10499, 10500, 10502, 10503, 10505, 10507, 10508, 10509, 10510, 10512, 10513, 10515, 10516, 10517, 10519, 10520, 10524, 10525, 10526, 10528, 10529, 10530, 10531, 10532, 10536, 10537, 10540, 10542, 10543, 10544, 10545, 10546, 10547, 10554, 10555, 10556, 10557, 10558, 10559, 10563, 10564, 10565, 10570, 10572, 10573, 10575, 10576, 10577, 10579, 10580, 10581, 10582, 10584, 10585, 10586, 10587, 10589, 10591, 10592, 10594, 10595, 10596, 10597, 10598, 10599, 10603, 10606, 10608, 10611, 10614, 10618, 10619, 10620, 10622, 10623, 10624, 10626, 10627, 10628, 10629, 10630, 10635, 10636, 10637, 10638, 10639, 10640, 10643, 10645, 10646, 10647, 10649, 10651, 10653, 10654, 10656, 10657, 10658, 10660, 10662, 10664, 10666, 10669, 10671, 10673, 10674, 10676, 10677, 10680, 10682, 10683, 10684, 10685, 10686, 10692, 10693, 10694, 10695, 10696, 10697, 10700, 10701, 10702, 10704, 10705, 10706, 10707, 10708, 10709, 10713, 10714, 10715, 10718, 10719, 10720, 10721, 10722, 10724, 10726, 10728, 10729, 10730, 10731, 10732, 10733, 10734, 10736, 10737, 10738, 10739, 10741, 10745, 10747, 10749, 10751, 10753, 10755, 10756, 10760, 10762, 10763, 10764, 10765, 10772, 10774, 10776, 10777, 10778, 10779, 10781, 10782, 10784, 10785, 10786, 10787, 10788, 10789, 10793, 10794, 10795, 10796, 10798, 10800, 10801, 10804, 10805, 10806, 10807, 10809, 10811, 10813, 10814, 10816, 10817, 10818, 10820, 10821, 10823, 10826, 10827, 10828, 10831, 10833, 10834, 10835, 10836, 10838, 10839, 10840, 10841, 10842, 10843, 10845, 10847, 10850, 10851, 10852, 10854, 10855, 10857, 10858, 10859, 10860, 10861, 10862, 10863, 10865, 10866, 10867, 10868, 10869, 10870, 10872, 10873, 10874, 10875, 10876, 10877, 10878, 10879, 10880, 10881, 10882, 10883, 10885, 10888, 10891, 10893, 10896, 10901, 10902, 10903, 10905, 10906, 10908, 10910, 10911, 10912, 10913, 10914, 10915, 10918, 10919, 10920, 10921, 10922, 10923, 10925, 10926, 10929, 10930, 10932, 10933, 10934, 10935, 10936, 10937, 10938, 10940, 10942, 10943, 10944, 10945, 10946, 10947, 10949, 10950, 10952, 10956, 10959, 10963, 10969, 10971, 10980, 10988, 10989, 10994, 10996, 10997, 11000, 11001, 11006, 11007, 11011, 11020, 11022, 11027, 11030, 11032, 11041, 11042, 11044, 11046, 11057, 11058, 11069, 11070, 11072, 11073, 11075, 11091, 11093, 11094, 11095, 11097, 11099, 11101, 11105, 11116, 11120, 11125, 11129, 11135, 11139, 11145, 11146, 11150, 11151, 11154, 11159, 11161, 11168, 11171, 11186, 11191, 11192, 11195, 11198, 11214, 11216, 11217, 11219, 11220, 11224, 11225, 11226, 11227, 11228, 11229, 11231, 11232, 11233, 11234, 11235, 11236, 11238, 11239, 11242, 11244, 11246, 11247, 11248, 11251, 11252, 11253, 11254, 11255, 11256, 11257, 11261, 11262, 11263, 11264, 11265, 11271, 11273, 11274, 11275, 11276, 11277, 11279, 11281, 11283, 11284, 11285, 11286, 11287, 11288, 11289, 11290, 11292, 11294, 11295, 11299, 11304, 11305, 11306, 11307, 11309, 11310, 11311, 11312, 11314, 11315, 11316, 11318, 11320, 11321, 11322, 11323, 11324, 11325, 11329, 11330, 11332, 11333, 11334, 11335, 11336, 11342, 11348, 11349, 11350, 11352, 11353, 11356, 11357, 11358, 11361, 11362, 11363, 11364, 11366, 11368, 11369, 11371, 11372, 11373, 11374, 11375, 11376, 11377, 11378, 11379, 11382, 11383, 11384, 11386, 11390, 11391, 11394, 11396, 11397, 11402, 11404, 11406, 11407, 11408, 11409, 11410, 11413, 11419, 11421, 11423, 11425, 11427, 11432, 11434, 11436, 11437, 11442, 11443, 11445, 11447, 11448, 11451, 11454, 11458, 11461, 11466, 11468, 11469, 11471, 11472, 11474, 11475, 11476, 11478, 11480, 11484, 11486, 11487, 11488, 11491, 11492, 11493, 11494, 11495, 11497, 11498, 11500, 11502, 11504, 11505, 11506, 11508, 11509, 11510, 11511, 11514, 11516, 11517, 11518, 11520, 11521, 11524, 11525, 11526, 11528, 11529, 11532, 11533, 11534, 11537, 11539, 11540, 11541, 11542, 11543, 11544, 11547, 11560, 11656, 11657, 11658, 11659, 11660, 11666, 11667, 11669, 11670, 11673, 11674, 11679, 11680, 11681, 11682, 11683, 11685, 11687, 11690, 11693, 11694, 11695, 11696, 11698, 11700, 11702, 11704, 11705, 11706, 11708, 11712, 11713, 11714, 11716, 11717, 11718, 11719, 11721, 11722, 11723, 11724, 11726, 11727, 11728, 11731, 11732, 11733, 11736, 11741, 11742, 11745, 11746, 11747, 11748, 11749, 11755, 11756, 11757, 11760, 11762, 11764, 11765, 11767, 11770, 11772, 11773, 11774, 11777, 11779, 11781, 11787, 11790, 11793, 11796, 11798, 11799, 11800, 11802, 11806, 11808, 11809, 11810, 11812, 11813, 11814, 11815, 11821, 11823, 11825, 11827, 11830, 11831, 11832, 11833, 11836, 11837, 11840, 11841, 11842, 11844, 11845, 11848, 11849, 11850, 11851, 11852, 11853, 11857, 11858, 11863, 11865, 11866, 11869, 11871, 11872, 11874, 11875, 11880, 11881, 11885, 11887, 11890, 11895, 11897, 11899, 11900, 11902, 11903, 11904, 11906, 11907, 11909, 11910, 11911, 11914, 11915, 11917, 11918, 11922, 11923, 11924, 11926, 11927, 11929, 11931, 11932, 11933, 11934, 11935, 11938, 11939, 11941, 11944, 11946, 11948, 11949, 11950, 11951, 11952, 11953, 11955, 11956, 11957, 11958, 11959, 11963, 11966, 11967, 11968, 11969, 11970, 11971, 11972, 11974, 11975, 11976, 11977, 11978, 11979, 11980, 11981, 11982, 11985, 11986, 11987, 11988, 11990, 11991, 11993, 11997, 11998, 11999, 12002, 12005, 12009, 12010, 12011, 12012, 12013, 12016, 12018, 12020, 12021, 12022, 12023, 12026, 12027, 12030, 12031, 12032, 12034, 12035, 12036, 12038, 12039, 12040, 12041, 12042, 12045, 12047, 12048, 12049, 12051, 12052, 12053, 12054, 12056, 12057, 12058, 12059, 12060, 12061, 12064, 12065, 12066, 12067, 12068, 12069, 12073, 12074, 12076, 12077, 12078, 12079, 12082, 12083, 12084, 12085, 12086, 12089, 12092, 12098, 12099, 12100, 12101, 12102, 12103, 12108, 12111, 12112, 12115, 12116, 12117, 12118, 12119, 12121, 12122, 12123, 12127, 12129, 12130, 12131, 12132, 12133, 12134, 12135, 12136, 12137, 12138, 12139, 12141, 12142, 12143, 12144, 12145, 12146, 12150, 12153, 12156, 12157, 12162, 12165, 12166, 12167, 12168, 12169, 12170, 12171, 12172, 12173, 12174, 12176, 12177, 12178, 12179, 12180, 12181, 12183, 12184, 12185, 12186, 12187, 12189, 12190, 12191, 12192, 12194, 12195, 12196, 12199, 12202, 12203, 12204, 12205, 12207, 12210, 12211, 12212, 12213, 12214, 12215, 12216, 12220, 12221, 12225, 12226, 12227, 12229, 12230, 12232, 12235, 12236, 12237, 12238, 12240, 12241, 12242, 12243, 12245, 12246, 12247, 12251, 12253, 12254, 12255, 12256, 12258, 12260, 12261, 12262, 12263, 12264, 12265, 12268, 12270, 12271, 12272, 12273, 12274, 12275, 12277, 12278, 12279, 12280, 12281, 12282, 12283, 12286, 12288, 12289, 12291, 12293, 12294, 12295, 12296, 12297, 12298, 12299, 12300, 12302, 12303, 12304, 12305, 12306, 12307, 12308, 12309, 12311, 12313, 12314, 12316, 12317, 12319, 12320, 12323, 12325, 12328, 12329, 12330, 12332, 12335, 12336, 12337, 12338, 12339, 12341, 12342, 12343, 12344, 12345, 12346, 12347, 12351, 12353, 12355, 12356, 12357, 12359, 12363, 12364, 12365, 12366, 12367, 12368, 12370, 12372, 12373, 12374, 12375, 12376, 12377, 12378, 12380, 12382, 12385, 12387, 12388, 12390, 12392, 12394, 12395, 12397, 12399, 12400, 12401, 12403, 12408, 12410, 12413, 12414, 12416, 12417, 12418, 12419, 12420, 12421, 12422, 12423, 12424, 12426, 12427, 12429, 12430, 12431, 12432, 12433, 12434, 12439, 12440, 12446, 12447, 12448, 12450, 12452, 12455, 12456, 12457, 12463, 12465, 12469, 12471, 12472, 12473, 12478, 12480, 12484, 12487, 12490, 12493, 12494, 12495, 12496, 12498, 12499, 12502, 12503, 12511, 12514, 12515, 12516, 12518, 12520, 12523, 12525, 12526, 12527, 12528, 12532, 12537, 12538, 12542, 12543, 12547, 12555, 12560, 12566, 12567, 12569, 12584, 12593, 12596, 12599, 12600, 12603, 12604, 12605, 12607, 12608, 12609, 12610, 12611, 12614, 12615, 12616, 12619, 12620, 12624, 12626, 12629, 12630, 12632, 12633, 12634, 12638, 12639, 12640, 12649, 12650, 12651, 12653, 12655, 12656, 12658, 12660, 12661, 12663, 12666, 12667, 12670, 12671, 12672, 12673, 12674, 12676, 12677, 12678, 12681, 12682, 12683, 12685, 12689, 12690, 12691, 12692, 12694, 12695, 12696, 12697, 12698, 12699, 12700, 12701, 12704, 12705, 12707, 12708, 12709, 12711, 12712, 12716, 12717, 12719, 12720, 12721, 12723, 12724, 12728, 12729, 12730, 12731, 12732, 12733, 12734, 12735, 12737, 12739, 12741, 12743, 12745, 12747, 12749, 12751, 12752, 12753, 12754, 12755, 12757, 12760, 12761, 12762, 12763, 12765, 12767, 12768, 12770, 12771, 12774, 12775, 12776, 12777, 12781, 12782, 12784, 12785, 12788, 12789, 12790, 12793, 12794, 12795, 12796, 12797, 12798, 12801, 12802, 12803, 12804, 12809, 12810, 12811, 12812, 12813, 12814, 12815, 12816, 12818, 12819, 12820, 12822, 12824, 12826, 12827, 12829, 12831, 12832, 12834, 12835, 12836, 12837, 12838, 12840, 12843, 12844, 12845, 12847, 12848, 12851, 12852, 12853, 12854, 12855, 12856, 12857, 12858, 12859, 12860, 12862, 12867, 12871, 12875, 12878, 12879, 12881, 12883, 12885, 12887, 12889, 12890, 12891, 12893, 12896, 12897, 12899, 12901, 12902, 12905, 12906, 12913, 12915, 12917, 12919, 12920, 12921, 12922, 12926, 12928, 12930, 12931, 12932, 12934, 12935, 12936, 12937, 12938, 12947, 12948, 12949, 12950, 12951, 12953, 12956, 12957, 12958, 12959, 12960, 12961, 12962, 12963, 12965, 12966, 12967, 12969, 12970, 12972, 12976, 12977, 12979, 12980, 12981, 12984, 12985, 12986, 12987, 12989, 12993, 12995, 12996, 12997, 12998, 13004, 13006, 13009, 13013, 13015, 13016, 13017, 13018, 13020, 13022, 13024, 13026, 13027, 13028, 13029, 13030, 13031, 13032, 13033, 13034, 13036, 13038, 13039, 13040, 13041, 13042, 13043, 13044, 13046, 13047, 13050, 13051, 13053, 13054, 13055, 13056, 13057, 13058, 13059, 13060, 13061, 13062, 13064, 13066, 13072, 13073, 13075, 13077, 13078, 13082, 13083, 13085, 13088, 13089, 13094, 13095, 13096, 13098, 13099, 13100, 13101, 13103, 13106, 13107, 13109, 13110, 13113, 13114, 13118, 13119, 13120, 13122, 13126, 13127, 13128, 13130, 13131, 13132, 13133, 13135, 13136, 13138, 13139, 13140, 13141, 13143, 13145, 13146, 13148, 13155, 13156, 13157, 13159, 13160, 13163, 13165, 13166, 13167, 13171, 13172, 13173, 13174, 13176, 13177, 13178, 13179, 13180, 13182, 13183, 13186, 13188, 13191, 13192, 13195, 13196, 13198, 13199, 13200, 13201, 13202, 13203, 13204, 13205, 13210, 13211, 13213, 13214, 13216, 13217, 13221, 13222, 13223, 13224, 13225, 13226, 13227, 13228, 13229, 13230, 13233, 13234, 13235, 13236, 13237, 13240, 13241, 13243, 13244, 13248, 13249, 13250, 13251, 13254, 13256, 13257, 13258, 13260, 13261, 13262, 13263, 13264, 13265, 13266, 13271, 13272, 13273, 13275, 13277, 13278, 13279, 13280, 13282, 13283, 13284, 13285, 13286, 13287, 13288, 13289, 13291, 13293, 13294, 13295, 13296, 13299, 13300, 13301, 13302, 13303, 13306, 13309, 13310, 13312, 13313, 13314, 13316, 13317, 13318, 13321, 13323, 13325, 13327, 13329, 13330, 13331, 13332, 13334, 13336, 13338, 13339, 13340, 13342, 13343, 13344, 13345, 13348, 13349, 13352, 13354, 13356, 13357, 13358, 13359, 13360, 13361, 13363, 13364, 13366, 13367, 13368, 13370, 13371, 13374, 13376, 13378, 13379, 13381, 13382, 13388, 13389, 13392, 13393, 13394, 13396, 13398, 13400, 13403, 13406, 13407, 13408, 13409, 13410, 13411, 13412, 13413, 13414, 13415, 13416, 13417, 13418, 13419, 13421, 13423, 13424, 13425, 13428, 13429, 13430, 13431, 13432, 13433, 13436, 13439, 13440, 13445, 13450, 13451, 13452, 13453, 13454, 13455, 13456, 13457, 13459, 13462, 13464, 13465, 13466, 13467, 13468, 13469, 13470, 13472, 13475, 13477, 13478, 13479, 13482, 13484, 13485, 13486, 13489, 13490, 13491, 13492, 13493, 13495, 13498, 13499, 13504, 13505, 13506, 13507, 13509, 13733, 13843, 13874, 14080, 14095, 14100, 14170, 14296, 14297, 14298, 14299, 14302, 14303, 14304, 14306, 14308, 14310, 14311, 14313, 14315, 14316, 14320, 14324, 14325, 14327, 14328, 14329, 14330, 14331, 14332, 14333, 14336, 14337, 14338, 14340, 14342, 14345, 14346, 14347, 14348, 14349, 14351, 14352, 14353, 14355, 14356, 14357, 14358, 14360, 14362, 14364, 14365, 14366, 14367, 14368, 14370, 14371, 14373, 14374, 14375, 14376, 14377, 14379, 14380, 14382, 14383, 14384, 14385, 14386, 14387, 14389, 14390, 14391, 14392, 14393, 14394, 14396, 14398, 14400, 14404, 14405, 14406, 14409, 14410, 14412, 14414, 14415, 14416, 14417, 14418, 14419, 14422, 14425, 14426, 14427, 14428, 14429, 14431, 14433, 14434, 14435, 14439, 14442, 14445, 14447, 14450, 14451, 14452, 14455, 14456, 14457, 14460, 14461, 14462, 14463, 14465, 14466, 14469, 14472, 14474, 14475, 14476, 14478, 14480, 14481, 14482, 14483, 14485, 14486, 14487, 14488, 14489, 14493, 14494, 14495, 14498, 14501, 14502, 14504, 14508, 14509, 14510, 14512, 14513, 14516, 14517, 14518, 14520, 14521, 14522, 14523, 14527, 14528, 14529, 14531, 14535, 14536, 14538, 14540, 14541, 14542, 14543, 14544, 14545, 14547, 14549, 14550, 14552, 14554, 14555, 14556, 14557, 14559, 14560, 14563, 14566, 14569, 14570, 14571, 14572, 14574, 14575, 14577, 14578, 14579, 14580, 14581, 14582, 14585, 14586, 14588, 14589, 14590, 14592, 14593, 14599, 14601, 14602, 14604, 14605, 14608, 14611, 14613, 14615, 14619, 14624, 14625, 14626, 14629, 14630, 14632, 14633, 14634, 14635, 14637, 14639, 14640, 14646, 14647, 14648, 14649, 14652, 14653, 14654, 14656, 14657, 14658, 14659, 14661, 14662, 14664, 14665, 14666, 14668, 14669, 14670, 14673, 14674, 14675, 14676, 14677, 14678, 14679, 14681, 14682, 14683, 14684, 14685, 14686, 14688, 14689, 14690, 14691, 14695, 14696, 14697, 14698, 14702, 14703, 14704, 14705, 14707, 14711, 14713, 14714, 14715, 14716, 14720, 14723, 14726, 14727, 14728, 14731, 14732, 14733, 14735, 14738, 14739, 14740, 14741, 14743, 14744, 14745, 14746, 14747, 14748, 14749, 14750, 14751, 14754, 14759, 14760, 14761, 14762, 14763, 14764, 14765, 14766, 14767, 14769, 14770, 14771, 14772, 14774, 14775, 14776, 14778, 14779, 14781, 14782, 14784, 14787, 14788, 14791, 14793, 14794, 14795, 14796, 14797, 14798, 14800, 14801, 14803, 14804, 14805, 14806, 14807, 14808, 14811, 14812, 14813, 14814, 14815, 14816, 14817, 14818, 14820, 14824, 14826, 14827, 14828, 14829, 14832, 14833, 14834, 14835, 14836, 14837, 14839, 14840, 14841, 14842, 14844, 14846, 14848, 14849, 14850, 14851, 14853, 14854, 14855, 14856, 14858, 14859, 14860, 14861, 14862, 14863, 14866, 14867, 14868, 14870, 14871, 14873, 14874, 14877, 14880, 14883, 14884, 14886, 14887, 14889, 14890, 14891, 14892, 14895, 14896, 14897, 14898, 14900, 14902, 14904, 14906, 14907, 14908, 14909, 14911, 14912, 14914, 14915, 14916, 14917, 14918, 14919, 14920, 14922, 14923, 14925, 14926, 14929, 14932, 14934, 14937, 14938, 14939, 14940, 14942, 14943, 14945, 14946, 14947, 14948, 14953, 14955, 14956, 14958, 14960, 14961, 14962, 14963, 14964, 14965, 14966, 14967, 14968, 14969, 14973, 14974, 14975, 14976, 14978, 14980, 14982, 14983, 14984, 14985, 14986, 14987, 14989, 14990, 14991, 14994, 14995, 14997, 14998, 15001, 15003, 15004, 15006, 15007, 15008, 15009, 15013, 15015, 15016, 15017, 15018, 15019, 15020, 15021, 15023, 15024, 15025, 15026, 15028, 15030, 15033, 15035, 15037, 15038, 15039, 15040, 15042, 15043, 15044, 15046, 15049, 15053, 15055, 15056, 15058, 15059, 15061, 15063, 15065, 15066, 15067, 15068, 15070, 15071, 15072, 15073, 15074, 15076, 15077, 15078, 15079, 15080, 15081, 15082, 15083, 15085, 15086, 15087, 15088, 15104, 15106, 15107, 15108, 15110, 15112, 15883, 15884, 15888, 15889, 15891, 15893, 15894, 15895, 15896, 15897, 15898, 15899, 15900, 15904, 15907, 15908, 15909, 15910, 15911, 15913, 15914, 15917, 15918, 15919, 15920, 15921, 15922, 15923, 15924, 15925, 15927, 15929, 15932, 15934, 15937, 15940, 15941, 15943, 15944, 15949, 15950, 15954, 15955, 15956, 15958, 15959, 15962, 15963, 15964, 15965, 15967, 15968, 15969, 15970, 15972, 15974, 15975, 15977, 15978, 15979, 15980, 15981, 15982, 15983, 15984, 15986, 15987, 15988, 15989, 15993, 15995, 15997, 15998, 16000, 16001, 16002, 16003, 16004, 16005, 16006, 16007, 16008, 16009, 16010, 16011, 16013, 16016, 16017, 16019, 16020, 16021, 16022, 16023, 16025, 16026, 16027, 16029, 16031, 16032, 16033, 16034, 16035, 16037, 16040, 16041, 16043, 16044, 16046, 16047, 16049, 16050, 16051, 16052, 16053, 16055, 16056, 16057, 16058, 16059, 16060, 16064, 16066, 16068, 16069, 16071, 16074, 16075, 16076, 16077, 16078, 16080, 16081, 16082, 16083, 16084, 16085, 16086, 16087, 16088, 16089, 16090, 16092, 16093, 16095, 16096, 16097, 16098, 16100, 16102, 16104, 16105, 16106, 16109, 16110, 16114, 16115, 16117, 16121, 16123, 16124, 16125, 16127, 16130, 16131, 16132, 16133, 16136, 16138, 16139, 16142, 16144, 16145, 16148, 16149, 16151, 16152, 16153, 16156, 16157, 16158, 16159, 16161, 16162, 16163, 16167, 16168, 16169, 16170, 16171, 16172, 16175, 16177, 16179, 16181, 16182, 16184, 16185, 16186, 16187, 16190, 16192, 16195, 16196, 16197, 16198, 16199, 16200, 16201, 16205, 16206, 16207, 16208, 16209, 16210, 16212, 16214, 16215, 16217, 16218, 16219, 16221, 16223, 16224, 16225, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233, 16234, 16235, 16240, 16242, 16244, 16245, 16246, 16248, 16253, 16254, 16256, 16258, 16260, 16261, 16262, 16264, 16267, 16269, 16270, 16272, 16273, 16274, 16275, 16276, 16277, 16278, 16279, 16281, 16282, 16283, 16287, 16290, 16291, 16292, 16293, 16294, 16297, 16298, 16300, 16301, 16302, 16304, 16305, 16306, 16307, 16312, 16313, 16317, 16318, 16320, 16321, 16324, 16327, 16329, 16330, 16331, 16334, 16335, 16336, 16337, 16338, 16339, 16340, 16341, 16342, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351, 16352, 16354, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16365, 16367, 16368, 16369, 16370, 16371, 16373, 16374, 16375, 16376, 16379, 16380, 16381, 16382, 16383, 16384, 16385, 16386, 16387, 16388, 16389, 16390, 16391, 16392, 16393, 16394, 16395, 16397, 16399, 16400, 16401, 16402, 16403, 16404, 16406, 16407, 16409, 16410, 16411, 16412, 16414, 16415, 16416, 16418, 16420, 16421, 16422, 16423, 16424, 16425, 16427, 16429, 16431, 16432, 16434, 16435, 16436, 16437, 16438, 16439, 16440, 16441, 16442, 16443, 16444, 16446, 16447, 16449, 16450, 16452, 16453, 16455, 16456, 16457, 16458, 16459, 16460, 16461, 16462, 16464, 16465, 16466, 16467, 16468, 16470, 16471, 16472, 16475, 16477, 16478, 16480, 16481, 16483, 16484, 16485, 16486, 16488, 16489, 16490, 16491, 16492, 16493, 16498, 16499, 16501, 16502, 16503, 16507, 16508, 16510, 16512, 16513, 16515, 16516, 16517, 16518, 16521, 16522, 16524, 16525, 16526, 16528, 16529, 16533, 16535, 16536, 16537, 16539, 16541, 16543, 16544, 16547, 16550, 16552, 16553, 16554, 16715, 16718, 16720, 16721, 16722, 16724, 16728, 16729, 16730, 16731, 16733, 16737, 16738, 16739, 16745, 16746, 16747, 16748, 16749, 16750, 16752, 16753, 16756, 16757, 16758, 16761, 16762, 16763, 16764, 16770, 16771, 16772, 16773, 16774, 16775, 16776, 16777, 16778, 16779, 16780, 16781, 16783, 16784, 16785, 16788, 16790, 16791, 16793, 16795, 16796, 16799, 16801, 16802, 16803, 16804, 16806, 16807, 16808, 16812, 16813, 16814, 16816, 16817, 16819, 16820, 16821, 16822, 16823, 16824, 16825, 16826, 16829, 16830, 16831, 16834, 16835, 16838, 16839, 16840, 16843, 16844, 16846, 16849, 16850, 16851, 16853, 16854, 16855, 16856, 16857, 16859, 16862, 16863, 16867, 16868, 16869, 16870, 16871, 16872, 16874, 16875, 16876, 16877, 16879, 16880, 16882, 16883, 16885, 16886, 16887, 16888, 16889, 16891, 16892, 16895, 16896, 16897, 16899, 16900, 16901, 16903, 16904, 16905, 16906, 16907, 16908, 16909, 16910, 16911, 16914, 16915, 16917, 16918, 16919, 16920, 16921, 16922, 16923, 16924, 16925, 16928, 16929, 16930, 16932, 16934, 16935, 16937, 16938, 16939, 16940, 16941, 16943, 16944, 16946, 16949, 16951, 16953, 16955, 16956, 16957, 16958, 16959, 16962, 16963, 16964, 16965, 16967, 16968, 16969, 16975, 16977, 16978, 16979, 16980, 16983, 16984, 16986, 16987, 16989, 16990, 16993, 16994, 16995, 16996, 16997, 17001, 17002, 17003, 17004, 17005, 17008, 17010, 17011, 17015, 17016, 17020, 17022, 17028, 17030, 17031, 17032, 17033, 17035, 17036, 17039, 17040, 17042, 17044, 17045, 17047, 17048, 17049, 17050, 17051, 17052, 17053, 17056, 17057, 17058, 17059, 17060, 17065, 17066, 17068, 17069, 17072, 17073, 17074, 17075, 17076, 17077, 17079, 17080, 17081, 17082, 17083, 17085, 17088, 17089, 17090, 17095, 17096, 17097, 17098, 17099, 17101, 17102, 17103, 17104, 17105, 17106, 17107, 17108, 17110, 17111, 17114, 17117, 17118, 17122, 17123, 17125, 17126, 17128, 17129, 17131, 17132, 17134, 17135, 17137, 17138, 17139, 17140, 17141, 17142, 17143, 17144, 17145, 17146, 17147, 17148, 17150, 17152, 17153, 17154, 17155, 17156, 17157, 17158, 17159, 17160, 17161, 17162, 17164, 17165, 17166, 17168, 17169, 17170, 17171, 17172, 17174, 17175, 17176, 17177, 17179, 17181, 17182, 17183, 17184, 17185, 17187, 17188, 17189, 17191, 17192, 17193, 17195, 17196, 17201, 17202, 17203, 17204, 17206, 17207, 17208, 17209, 17212, 17213, 17214, 17215, 17216, 17218, 17219, 17221, 17222, 17223, 17224, 17225, 17226, 17227, 17228, 17229, 17230, 17234, 17235, 17236, 17238, 17240, 17241, 17244, 17245, 17246, 17247, 17249, 17250, 17251, 17252, 17253, 17254, 17255, 17256, 17258, 17259, 17260, 17261, 17262, 17264, 17265, 17267, 17271, 17272, 17273, 17274, 17276, 17280, 17281, 17282, 17284, 17285, 17286, 17287, 17288, 17289, 17292, 17294, 17295, 17296, 17297, 17298, 17300, 17303, 17305, 17306, 17307, 17308, 17309, 17310, 17311, 17312, 17313, 17316, 17317, 17320, 17321, 17322, 17325, 17326, 17328, 17329, 17330, 17332, 17333, 17337, 17338, 17339, 17340, 17341, 17342, 17343, 17344, 17346, 17347, 17348, 17349, 17351, 17352, 17353, 17356, 17358, 17359, 17360, 17361, 17362, 17365, 17367, 17368, 17369, 17372, 17373, 17374, 17376, 17377, 17380, 17381, 17383, 17384, 17385, 17386, 17387, 17388, 17389, 17392, 17394, 17396, 17398, 17399, 17403, 17404, 17405, 17406, 17409, 17410, 17411, 17413, 17416, 17417, 17420, 17423, 17424, 17426, 17427, 17428, 17429, 17430, 17431, 17432, 17433, 17434, 17435, 17436, 17440, 17441, 17442, 17443, 17444, 17445, 17446, 17448, 17451, 17452, 17453, 17455, 17457, 17458, 17462, 17463, 17465, 17466, 17467, 17468, 17472, 17474, 17476, 17478, 17479, 17480, 17483, 17484, 17487, 17488, 17491, 17493, 17494, 17497, 17500, 17502, 17503, 17506, 17507, 17510, 17512, 17515, 17517, 17519, 17522, 17523, 17524, 17525, 17526, 17527, 17529, 17534, 17537, 17538, 17539, 17541, 17542, 17545, 17546, 17549, 17550, 17551, 17719, 17720, 17721, 17727, 17733, 17734, 17737, 17741, 17742, 17743, 17746, 17748, 17754, 17759, 17762, 17765, 17769, 17781, 17783, 17785, 17789, 17793, 17796, 17805, 17808, 17815, 17820, 17822, 17824, 17835, 17836, 17844, 17848, 17849, 17854, 17855, 17858, 17861, 17867, 17869, 17875, 17876, 17877, 17881, 17882, 17885, 17887, 17888, 17889, 17892, 17897, 17900, 17904, 17916, 17917, 17920, 17921, 17923, 17924, 17928, 17929, 17930, 17932, 17934, 17935, 17938, 17940, 17941, 17942, 17948, 17951, 17952, 17953, 17955, 17956, 17957, 17959, 17960, 17961, 17965, 17966, 17967, 17969, 17971, 17972, 17973, 17975, 17977, 17978, 17981, 17982, 17983, 17985, 17986, 17987, 17988, 17990, 17991, 17997, 18002, 18003, 18004, 18006, 18008, 18010, 18011, 18012, 18013, 18014, 18017, 18018, 18019, 18020, 18021, 18022, 18023, 18024, 18025, 18026, 18027, 18028, 18030, 18031, 18032, 18033, 18035, 18037, 18038, 18040, 18041, 18042, 18043, 18046, 18047, 18048, 18049, 18052, 18055, 18057, 18060, 18067, 18070, 18072, 18074, 18075, 18076, 18077, 18078, 18079, 18083, 18086, 18087, 18091, 18098, 18100, 18102, 18105, 18106, 18107, 18111, 18112, 18114, 18116, 18118, 18119, 18121, 18122, 18124, 18125, 18128, 18129, 18131, 18133, 18134, 18135, 18136, 18138, 18146, 18147, 18148, 18149, 18154, 18162, 18166, 18167, 18168, 18169, 18178, 18182, 18184, 18188, 18189, 18190, 18196, 18198, 18200, 18201, 18209, 18210, 18212, 18215, 18218, 18224, 18225, 18229, 18237, 18246, 18247, 18256, 18271, 18272, 18274, 18326, 18330, 18333, 18337, 18343, 18347, 18352, 18361, 18371, 18377, 18381, 18386, 18388, 18390, 18391, 18392, 18393, 18406, 18407, 18410, 18413, 18415, 18419, 18420, 18422, 18424, 18425, 18427, 18428, 18429, 18432, 18433, 18437, 18438, 18440, 18442, 18445, 18449, 18453, 18454, 18455, 18456, 18459, 18461, 18462, 18463, 18465, 18468, 18470, 18475, 18476, 18477, 18479, 18480, 18483, 18484, 18489, 18490, 18493, 18494, 18496, 18497, 18498, 18499, 18500, 18501, 18502, 18503, 18507, 18512, 18514, 18515, 18516, 18518, 18519, 18520, 18523, 18524, 18525, 18526, 18527, 18529, 18531, 18532, 18533, 18534, 18535, 18536, 18537, 18539, 18540, 18541, 18542, 18543, 18544, 18546, 18549, 18551, 18552, 18553, 18557, 18563, 18564, 18566, 18567, 18569, 18570, 18575, 18578, 18579, 18581, 18583, 18585, 18587, 18588, 18589, 18590, 18591, 18592, 18593, 18594, 18595, 18596, 18598, 18599, 18600, 18602, 18603, 18604, 18605, 18606, 18607, 18611, 18613, 18617, 18618, 18620, 18623, 18624, 18626, 18627, 18628, 18630, 18632, 18634, 18641, 18643, 18644, 18646, 18650, 18652, 18653, 18656, 18660, 18661, 18662, 18663, 18664, 18665, 18670, 18672, 18675, 18676, 18680, 18681, 18682, 18684, 18686, 18687, 18699, 18706, 18713, 18718, 18795, 18802, 18810, 18811, 18812, 18815, 18816, 18820, 18823, 18826, 18828, 18830, 18833, 18835, 18838, 18839, 18841, 18842, 18843, 18844, 18847, 18849, 18850, 18851, 18854, 18855, 18858, 18867, 18869, 18871, 18872, 18874, 18878, 18879, 18881, 18883, 18887, 18888, 18889, 18890, 18892, 18893, 18894, 18895, 18899, 18900, 18901, 18902, 18903, 18904, 18905, 18906, 18907, 18908, 18910, 18911, 18912, 18913, 18914, 18918, 18919, 18921, 18923, 18924, 18925, 18927, 18929, 18930, 18931, 18933, 18935, 18938, 18940, 18942, 18943, 18946, 18948, 18949, 18951, 18952, 18955, 18957, 18958, 18961, 18963, 18964, 18965, 18967, 18970, 18971, 18973, 18976, 18980, 18982, 18986, 18987, 18990, 18991, 18992, 18993, 18994, 18997, 18998, 19000, 19002, 19003, 19004, 19005, 19007, 19008, 19009, 19011, 19016, 19017, 19020, 19022, 19024, 19026, 19027, 19028, 19029, 19030, 19033, 19036, 19037, 19038, 19039, 19042, 19043, 19045, 19049, 19050, 19053, 19055, 19056, 19057, 19058, 19061, 19062, 19065, 19066, 19069, 19070, 19072, 19074, 19075, 19079, 19080, 19082, 19084, 19087, 19089, 19090, 19091, 19092, 19093, 19094, 19096, 19099, 19100, 19101, 19105, 19106, 19107, 19109, 19110, 19111, 19112, 19113, 19115, 19117, 19120, 19123, 19125, 19126, 19128, 19129, 19131, 19133, 19134, 19136, 19137, 19139, 19141, 19143, 19145, 19147, 19148, 19149, 19150, 19153, 19154, 19155, 19156, 19157, 19158, 19159, 19160, 19162, 19163, 19165, 19166, 19167, 19168, 19169, 19171, 19173, 19174, 19175, 19180, 19182, 19183, 19185, 19189, 19192, 19197, 19199, 19200, 19201, 19204, 19205, 19208, 19210, 19211, 19215, 19217, 19218, 19219, 19221, 19222, 19223, 19224, 19226, 19227, 19228, 19230, 19231, 19232, 19234, 19235, 19237, 19238, 19239, 19240, 19243, 19244, 19246, 19247, 19248, 19249, 19250, 19255, 19257, 19260, 19261, 19262, 19263, 19265, 19266, 19267, 19270, 19273, 19274, 19275, 19277, 19278, 19279, 19280, 19283, 19284, 19285, 19286, 19290, 19293, 19294, 19295, 19296, 19297, 19300, 19301, 19302, 19303, 19305, 19306, 19311, 19329, 19468, 19470, 19475, 19478, 19480, 19487, 19490, 19497, 19499, 19502, 19503, 19506, 19507, 19508, 19509, 19521, 19524, 19528, 19529, 19531, 19532, 19534, 19539, 19546, 19548, 19549, 19554, 19556, 19558, 19561, 19562, 19563, 19572, 19573, 19575, 19576, 19581, 19582, 19584, 19586, 19592, 19598, 19600, 19604, 19609, 19614, 19615, 19619, 19620, 19624, 19627, 19629, 19630, 19632, 19633, 19642, 19644, 19646, 19648, 19649, 19656, 19657, 19661, 19663, 19669, 19670, 19672, 19673, 19675, 19676, 19681, 19682, 19685, 19686, 19693, 19695, 19697, 19699, 19700, 19701, 19702, 19703, 19706, 19707, 19708, 19709, 19710, 19712, 19713, 19717, 19718, 19720, 19721, 19722, 19724, 19725, 19729, 19730, 19733, 19734, 19735, 19736, 19737, 19739, 19740, 19742, 19744, 19747, 19749, 19752, 19753, 19754, 19758, 19759, 19760, 19761, 19764, 19765, 19766, 19769, 19771, 19772, 19773, 19775, 19778, 19779, 19780, 19781, 19783, 19784, 19785, 19787, 19788, 19792, 19793, 19795, 19796, 19798, 19799, 19800, 19802, 19807, 19808, 19810, 19812, 19813, 19814, 19815, 19816, 19818, 19821, 19824, 19825, 19826, 19827, 19828, 19830, 19838, 19839, 19846, 19854, 19856, 19857, 19858, 19859, 19860, 19861, 19862, 19865, 19866, 19868, 19870, 19872, 19876, 19879, 19880, 19882, 19883, 19884, 19887, 19890, 19891, 19892, 19893, 19894, 19899, 19900, 19912, 19913, 19918, 19919, 19924, 19926, 19927, 19928, 19930, 19935, 19951, 19952, 20061, 20062, 20064, 20065, 20072, 20074, 20075, 20076, 20078, 20084, 20089, 20091, 20094, 20098, 20104, 20105, 20106, 20107, 20108, 20110, 20111, 20112, 20113, 20114, 20115, 20116, 20117, 20118, 20119, 20122, 20123, 20124, 20126, 20128, 20129, 20130, 20133, 20137, 20138, 20139, 20144, 20147, 20149, 20150, 20152, 20153, 20154, 20159, 20160, 20162, 20163, 20164, 20165, 20167, 20169, 20170, 20171, 20174, 20175, 20176, 20178, 20179, 20180, 20181, 20189, 20190, 20192, 20195, 20197, 20198, 20201, 20202, 20204, 20208, 20209, 20211, 20212, 20219, 20222, 20223, 20224, 20225, 20227, 20228, 20229, 20230, 20231, 20233, 20234, 20235, 20237, 20238, 20239, 20240, 20245, 20246, 20247, 20248, 20249, 20251, 20252, 20253, 20254, 20255, 20257, 20259, 20260, 20262, 20265, 20268, 20270, 20272, 20273, 20274, 20276, 20283, 20284, 20285, 20286, 20287, 20288, 20289, 20293, 20294, 20296, 20297, 20299, 20301, 20304, 20305, 20306, 20309, 20311, 20313, 20315, 20317, 20318, 20319, 20320, 20322, 20324, 20325, 20326, 20329, 20330, 20333, 20334, 20335, 20336, 20337, 20338, 20339, 20341, 20344, 20345, 20346, 20347, 20349, 20350, 20351, 20352, 20353, 20354, 20355, 20356, 20357, 20359, 20360, 20362, 20363, 20365, 20366, 20367, 20368, 20371, 20374, 20375, 20377, 20378, 20380, 20381, 20382, 20384, 20385, 20386, 20389, 20390, 20392, 20395, 20396, 20400, 20402, 20403, 20404, 20407, 20408, 20409, 20410, 20411, 20412, 20415, 20417, 20419, 20420, 20424, 20426, 20428, 20429, 20430, 20431, 20434, 20438, 20439, 20440, 20445, 20447, 20449, 20451, 20452, 20458, 20459, 20460, 20462, 20463, 20464, 20465, 20466, 20472, 20473, 20475, 20476, 20477, 20478, 20480, 20481, 20483, 20484, 20485, 20487, 20488, 20489, 20490, 20492, 20496, 20497, 20498, 20499, 20500, 20507, 20508, 20509, 20511, 20512, 20513, 20514, 20515, 20516, 20517, 20519, 20520, 20521, 20523, 20524, 20525, 20526, 20527, 20528, 20532, 20533, 20534, 20536, 20537, 20539, 20540, 20544, 20545, 20547, 20549, 20551, 20552, 20554, 20556, 20558, 20559, 20561, 20562, 20563, 20564, 20566, 20567, 20568, 20569, 20571, 20572, 20573, 20574, 20575, 20577, 20579, 20581, 20582, 20583, 20584, 20585, 20591, 20592, 20593, 20597, 20598, 20599, 20601, 20602, 20605, 20606, 20607, 20608, 20609, 20613, 20614, 20621, 20625, 20627, 20630, 20632, 20633, 20634, 20635, 20637, 20640, 20642, 20645, 20649, 20805, 20814, 20816, 20827, 20888, 20893, 20937, 20994, 21039, 21086, 21108, 21127, 21140, 21157, 21227, 21238, 21279, 21351, 21368, 21388, 21409, 21434, 21451, 21452, 21456, 21459, 21460, 21461, 21462, 21463, 21464, 21465, 21466, 21468, 21469, 21471, 21472, 21475, 21477, 21482, 21484, 21486, 21487, 21488, 21490, 21491, 21492, 21494, 21495, 21497, 21500, 21501, 21502, 21503, 21504, 21506, 21507, 21508, 21509, 21510, 21512, 21513, 21514, 21515, 21516, 21517, 21519, 21520, 21522, 21525, 21526, 21528, 21529, 21530, 21532, 21538, 21539, 21540, 21541, 21542, 21543, 21544, 21545, 21546, 21547, 21548, 21550, 21554, 21555, 21561, 21562, 21563, 21564, 21566, 21568, 21569, 21570, 21571, 21572, 21573, 21574, 21577, 21578, 21579, 21580, 21583, 21584, 21585, 21586, 21587, 21588, 21590, 21591, 21594, 21597, 21598, 21599, 21600, 21601, 21602, 21603, 21608, 21609, 21610, 21611, 21612, 21613, 21614, 21616, 21617, 21618, 21620, 21621, 21624, 21625, 21626, 21629, 21630, 21631, 21634, 21637, 21639, 21640, 21641, 21642, 21643, 21644, 21647, 21648, 21651, 21653, 21654, 21655, 21658, 21659, 21660, 21661, 21663, 21664, 21667, 21668, 21669, 21670, 21671, 21672, 21674, 21677, 21678, 21679, 21680, 21681, 21682, 21683, 21684, 21686, 21687, 21688, 21690, 21693, 21694, 21696, 21697, 21698, 21700, 21702, 21703, 21704, 21706, 21707, 21709, 21710, 21711, 21713, 21716, 21718, 21720, 21725, 21726, 21727, 21729, 21730, 21735, 21737, 21738, 21739, 21740, 21742, 21743, 21744, 21745, 21747, 21748, 21750, 21752, 21754, 21755, 21757, 21758, 21759, 21760, 21761, 21762, 21763, 21765, 21766, 21767, 21769, 21771, 21773, 21774, 21775, 21776, 21779, 21781, 21782, 21784, 21785, 21786, 21787, 21788, 21789, 21790, 21791, 21793, 21794, 21797, 21799, 21800, 21802, 21803, 21804, 21805, 21806, 21807, 21808, 21813, 21814, 21818, 21819, 21820, 21822, 21823, 21825, 21829, 21831, 21832, 21834, 21835, 21836, 21837, 21838, 21839, 21842, 21846, 21851, 21853, 21854, 21855, 21856, 21858, 21860, 21861, 21862, 21863, 21864, 21865, 21866, 21869, 21870, 21871, 21872, 21873, 21874, 21875, 21876, 21877, 21879, 21881, 21883, 21884, 21885, 21887, 21889, 21890, 21891, 21892, 21893, 21896, 21898, 21900, 21903, 21904, 21905, 21906, 21908, 21911, 21914, 21915, 21916, 21917, 21918, 21919, 21920, 21921, 21922, 21923, 21925, 21926, 21929, 21930, 21932, 21934, 21935, 21936, 21937, 21938, 21939, 21940, 21942, 21943, 21944, 21945, 21946, 21947, 21948, 21949, 21950, 21951, 21953, 21955, 21957, 21958, 21959, 21962, 21963, 21965, 21967, 21971, 21972, 21975, 21978, 21980, 21981, 21983, 21985, 21986, 21988, 21989, 21990, 21991, 21993, 21995, 21996, 21997, 22000, 22001, 22002, 22003, 22004, 22006, 22008, 22009, 22011, 22012, 22016, 22019, 22020, 22021, 22022, 22023, 22024, 22025, 22026, 22027, 22028, 22030, 22031, 22032, 22034, 22035, 22038, 22039, 22042, 22043, 22045, 22048, 22050, 22052, 22054, 22057, 22058, 22060, 22061, 22062, 22063, 22064, 22066, 22067, 22068, 22069, 22070, 22071, 22072, 22074, 22077, 22078, 22081, 22082, 22084, 22085, 22086, 22088, 22089, 22090, 22093, 22094, 22095, 22097, 22098, 22099, 22104, 22105, 22108, 22109, 22110, 22111, 22113, 22117, 22118, 22120, 22121, 22125, 22126, 22127, 22128, 22129, 22130, 22134, 22135, 22137, 22138, 22139, 22140, 22142, 22143, 22147, 22149, 22150, 22151, 22154, 22155, 22156, 22158, 22160, 22163, 22164, 22168, 22171, 22172, 22173, 22174, 22176, 22180, 22181, 22182, 22183, 22184, 22186, 22187, 22189, 22191, 22193, 22195, 22196, 22197, 22198, 22199, 22200, 22201, 22202, 22203, 22205, 22206, 22208, 22209, 22210, 22211, 22212, 22214, 22216, 22217, 22218, 22220, 22222, 22223, 22224, 22225, 22227, 22228, 22229, 22230, 22231, 22232, 22233, 22235, 22236, 22237, 22239, 22243, 22244, 22245, 22246, 22248, 22249, 22251, 22253, 22254, 22255, 22256, 22258, 22260, 22261, 22262, 22263, 22266, 22267, 22269, 22271, 22272, 22273, 22275, 22280, 22281, 22284, 22285, 22286, 22287, 22289, 22290, 22291, 22292, 22293, 22295, 22296, 22297, 22304, 23109, 23110, 23111, 23112, 23113, 23114, 23115, 23118, 23120, 23121, 23123, 23124, 23127, 23129, 23132, 23133, 23135, 23137, 23139, 23142, 23143, 23146, 23147, 23148, 23149, 23150, 23151, 23152, 23153, 23155, 23156, 23157, 23158, 23160, 23162, 23163, 23164, 23167, 23170, 23172, 23173, 23174, 23176, 23178, 23179, 23180, 23182, 23184, 23185, 23187, 23188, 23189, 23190, 23192, 23193, 23194, 23195, 23196, 23197, 23198, 23199, 23200, 23201, 23202, 23203, 23205, 23209, 23210, 23211, 23212, 23215, 23216, 23217, 23219, 23220, 23221, 23222, 23223, 23224, 23226, 23227, 23229, 23230, 23231, 23234, 23235, 23236, 23237, 23238, 23240, 23241, 23244, 23247, 23250, 23253, 23254, 23255, 23256, 23257, 23258, 23259, 23261, 23262, 23265, 23266, 23267, 23268, 23269, 23270, 23272, 23273, 23274, 23276, 23277, 23278, 23279, 23281, 23282, 23283, 23285, 23290, 23291, 23293, 23294, 23297, 23299, 23300, 23301, 23302, 23303, 23304, 23305, 23306, 23307, 23308, 23309, 23310, 23312, 23314, 23315, 23316, 23317, 23318, 23319, 23322, 23323, 23324, 23325, 23326, 23327, 23328, 23330, 23332, 23333, 23336, 23337, 23338, 23340, 23341, 23343, 23344, 23345, 23346, 23349, 23351, 23352, 23354, 23355, 23359, 23360, 23361, 23362, 23363, 23364, 23366, 23368, 23369, 23370, 23373, 23374, 23375, 23377, 23378, 23379, 23380, 23381, 23384, 23386, 23387, 23388, 23389, 23390, 23391, 23396, 23397, 23398, 23399, 23400, 23401, 23402, 23406, 23407, 23408, 23409, 23412, 23414, 23415, 23416, 23418, 23419, 23420, 23421, 23422, 23423, 23424, 23425, 23426, 23427, 23428, 23429, 23430, 23431, 23433, 23436, 23438, 23439, 23440, 23442, 23443, 23445, 23447, 23448, 23449, 23450, 23452, 23453, 23454, 23455, 23456, 23457, 23459, 23460, 23461, 23462, 23463, 23465, 23467, 23468, 23470, 23474, 23475, 23478, 23479, 23480, 23481, 23482, 23483, 23484, 23485, 23487, 23488, 23489, 23493, 23494, 23495, 23496, 23497, 23498, 23499, 23502, 23503, 23504, 23505, 23507, 23508, 23509, 23511, 23514, 23516, 23517, 23518, 23519, 23521, 23523, 23525, 23527, 23528, 23529, 23530, 23531, 23532, 23533, 23534, 23535, 23536, 23537, 23538, 23539, 23540, 23541, 23543, 23546, 23547, 23548, 23549, 23551, 23553, 23554, 23555, 23556, 23557, 23558, 23559, 23560, 23561, 23563, 23564, 23566, 23568, 23569, 23570, 23571, 23573, 23574, 23575, 23576, 23577, 23579, 23580, 23583, 23584, 23586, 23587, 23589, 23591, 23592, 23596, 23598, 23602, 23603, 23604, 23605, 23606, 23610, 23615, 23616, 23618, 23619, 23620, 23621, 23622, 23623, 23624, 23626, 23629, 23631, 23632, 23633, 23634, 23638, 23639, 23640, 23641, 23644, 23645, 23648, 23649, 23650, 23651, 23652, 23654, 23656, 23657, 23658, 23660, 23664, 23665, 23666, 23667, 23671, 23672, 23673, 23674, 23675, 23678, 23679, 23681, 23684, 23685, 23686, 23687, 23688, 23689, 23692, 23693, 23694, 23696, 23697, 23698, 23701, 23703, 23704, 23705, 23706, 23707, 23709, 23712, 23713, 23714, 23715, 23716, 23719, 23720, 23721, 23722, 23723, 23725, 23727, 23728, 23733, 23734, 23737, 23738, 23742, 23743, 23745, 23748, 23749, 23750, 23751, 23753, 23754, 23755, 23760, 23763, 23768, 23769, 23770, 23777, 23778, 23780, 23783, 23789, 23790, 23791, 23792, 23793, 23794, 23795, 23798, 23799, 23802, 23804, 23805, 23806, 23809, 23810, 23811, 23814, 23816, 23821, 23823, 23825, 23827, 23828, 23831, 23832, 23835, 23836, 23837, 23838, 23839, 23840, 23842, 23844, 23845, 23846, 23847, 23848, 23851, 23852, 23853, 23854, 23855, 23856, 23857, 23859, 23860, 23861, 23862, 23863, 23864, 23865, 23867, 23868, 23869, 23870, 23871, 23872, 23873, 23874, 23875, 23877, 23879, 23884, 23885, 23886, 23887, 23888, 23892, 23894, 23895, 23898, 23899, 23900, 23901, 23902, 23903, 23904, 23905, 23907, 23908, 23909, 23911, 23912, 23913, 23915, 23916, 23917, 23921, 23922, 23923, 23924, 23926, 23927, 23929, 23930, 23933, 23934, 23935, 23936, 23937, 23939, 23941, 23943, 23945, 23946, 23952, 23955, 23957, 23958, 23959, 23960, 23962, 23964, 23969, 23970, 23972, 23974, 23976, 23978, 23980, 23981, 23983, 23984, 23987, 23989, 23992, 23995, 23996, 23998, 24000, 24001, 24002, 24003, 24005, 24006, 24007, 24008, 24010, 24012, 24013, 24014, 24017, 24020, 24021, 24823, 24824, 24825, 24826, 24830, 24831, 24834, 24836, 24837, 24844, 24846, 24847, 24848, 24850, 24851, 24852, 24853, 24854, 24855, 24856, 24857, 24858, 24859, 24863, 24866, 24867, 24869, 24871, 24872, 24873, 24876, 24878, 24879, 24880, 24881, 24882, 24883, 24884, 24885, 24886, 24892, 24893, 24894, 24896, 24898, 24900, 24901, 24902, 24904, 24909, 24912, 24915, 24916, 24918, 24919, 24921, 24922, 24923, 24927, 24928, 24930, 24932, 24933, 24934, 24935, 24936, 24937, 24938, 24941, 24943, 24944, 24945, 24946, 24947, 24948, 24950, 24951, 24952, 24953, 24956, 24959, 24960, 24961, 24962, 24965, 24967, 24968, 24969, 24970, 24972, 24973, 24974, 24975, 24976, 24977, 24978, 24979, 24981, 24982, 24983, 24984, 24985, 24986, 24987, 24988, 24989, 24990, 24993, 24994, 24996, 24997, 25000, 25002, 25007, 25010, 25011, 25014, 25015, 25016, 25017, 25019, 25020, 25021, 25022, 25023, 25024, 25025, 25026, 25028, 25029, 25030, 25031, 25032, 25037, 25038, 25039, 25040, 25041, 25042, 25045, 25046, 25048, 25049, 25051, 25052, 25053, 25054, 25055, 25058, 25059, 25060, 25062, 25063, 25064, 25067, 25068, 25069, 25070, 25073, 25074, 25075, 25076, 25077, 25080, 25081, 25082, 25084, 25087, 25089, 25090, 25091, 25092, 25094, 25095, 25096, 25097, 25098, 25100, 25101, 25103, 25105, 25108, 25109, 25110, 25111, 25114, 25115, 25116, 25117, 25120, 25121, 25122, 25123, 25124, 25128, 25130, 25132, 25134, 25135, 25140, 25143, 25144, 25146, 25147, 25151, 25152, 25153, 25154, 25156, 25157, 25160, 25162, 25163, 25165, 25166, 25167, 25168, 25169, 25170, 25172, 25173, 25174, 25175, 25177, 25178, 25179, 25180, 25182, 25184, 25187, 25188, 25189, 25192, 25193, 25195, 25196, 25198, 25199, 25200, 25201, 25202, 25203, 25204, 25205, 25209, 25212, 25214, 25215, 25218, 25219, 25222, 25224, 25225, 25226, 25227, 25229, 25230, 25233, 25234, 25236, 25237, 25239, 25241, 25242, 25243, 25244, 25246, 25247, 25248, 25249, 25250, 25251, 25253, 25254, 25256, 25257, 25259, 25260, 25263, 25264, 25265, 25266, 25270, 25271, 25272, 25273, 25274, 25275, 25276, 25277, 25279, 25281, 25282, 25285, 25287, 25291, 25293, 25295, 25297, 25300, 25301, 25302, 25304, 25305, 25309, 25310, 25313, 25314, 25315, 25316, 25317, 25318, 25320, 25322, 25325, 25327, 25328, 25329, 25330, 25331, 25333, 25334, 25335, 25337, 25338, 25340, 25342, 25343, 25344, 25345, 25346, 25348, 25349, 25350, 25351, 25353, 25354, 25355, 25358, 25361, 25362, 25364, 25366, 25367, 25368, 25369, 25371, 25372, 25375, 25376, 25378, 25379, 25381, 25382, 25383, 25384, 25385, 25386, 25387, 25388, 25390, 25391, 25392, 25395, 25397, 25398, 25399, 25402, 25403, 25408, 25409, 25411, 25413, 25414, 25415, 25416, 25418, 25420, 25421, 25422, 25424, 25425, 25426, 25427, 25429, 25430, 25431, 25433, 25435, 25436, 25437, 25438, 25439, 25440, 25441, 25443, 25447, 25448, 25450, 25454, 25455, 25459, 25460, 25461, 25464, 25465, 25466, 25467, 25470, 25472, 25473, 25479, 25489, 25496, 25498, 26288, 26289, 26290, 26291, 26293, 26294, 26295, 26296, 26298, 26299, 26301, 26303, 26304, 26306, 26308, 26309, 26311, 26313, 26314, 26315, 26317, 26319, 26320, 26321, 26322, 26325, 26326, 26327, 26328, 26329, 26330, 26331, 26332, 26333, 26335, 26337, 26338, 26341, 26343, 26344, 26345, 26349, 26350, 26351, 26354, 26357, 26358, 26359, 26361, 26362, 26363, 26365, 26367, 26368, 26369, 26370, 26371, 26373, 26375, 26376, 26377, 26378, 26381, 26382, 26383, 26384, 26385, 26387, 26389, 26390, 26391, 26392, 26393, 26394, 26395, 26396, 26397, 26399, 26402, 26403, 26405, 26406, 26407, 26410, 26411, 26413, 26414, 26415, 26416, 26417, 26418, 26420, 26423, 26426, 26427, 26428, 26429, 26433, 26436, 26438, 26444, 26445, 26446, 26449, 26450, 26451, 26452, 26453, 26454, 26457, 26458, 26459, 26460, 26461, 26464, 26465, 26467, 26468, 26469, 26473, 26474, 26475, 26478, 26479, 26480, 26482, 26483, 26487, 26488, 26489, 26490, 26494, 26496, 26497, 26499, 26501, 26502, 26503, 26504, 26505, 26506, 26508, 26509, 26511, 26512, 26513, 26514, 26515, 26516, 26517, 26518, 26519, 26522, 26523, 26524, 26526, 26528, 26529, 26530, 26531, 26532, 26533, 26535, 26536, 26539, 26540, 26541, 26542, 26543, 26545, 26546, 26548, 26549, 26550, 26553, 26554, 26555, 26556, 26557, 26559, 26561, 26563, 26564, 26565, 26567, 26572, 26573, 26574, 26575, 26576, 26580, 26581, 26584, 26585, 26588, 26589, 26591, 26595, 26600, 26601, 26602, 26603, 26606, 26607, 26608, 26609, 26610, 26611, 26612, 26613, 26614, 26616, 26618, 26619, 26620, 26625, 26626, 26627, 26628, 26630, 26633, 26635, 26636, 26637, 26638, 26639, 26640, 26644, 26645, 26646, 26649, 26651, 26652, 26653, 26656, 26657, 26658, 26659, 26660, 26661, 26664, 26665, 26666, 26667, 26670, 26672, 26673, 26676, 26677, 26678, 26679, 26680, 26681, 26682, 26683, 26684, 26685, 26688, 26689, 26690, 26691, 26692, 26694, 26695, 26698, 26699, 26701, 26703, 26704, 26705, 26706, 26707, 26708, 26709, 26710, 26711, 26712, 26713, 26714, 26715, 26716, 26717, 26722, 26723, 26724, 26725, 26727, 26728, 26729, 26730, 26731, 26732, 26733, 26734, 26735, 26738, 26739, 26740, 26741, 26742, 26743, 26744, 26746, 26747, 26748, 26749, 26750, 26752, 26754, 26756, 26757, 26758, 26759, 26760, 26762, 26765, 26766, 26767, 26769, 26770, 26771, 26772, 26774, 26776, 26778, 26779, 26780, 26781, 26783, 26786, 26787, 26789, 26792, 26794, 26795, 26797, 26798, 26799, 26800, 26801, 26803, 26804, 26806, 26807, 26808, 26809, 26810, 26813, 26814, 26815, 26816, 26817, 26819, 26820, 26823, 26830, 26833, 26835, 26836, 26837, 26841, 26843, 26844, 26845, 26846, 26847, 26848, 26849, 26850, 26852, 26853, 26854, 26855, 26856, 26858, 26859, 26860, 26861, 26865, 26871, 26872, 26873, 26877, 26879, 26880, 26881, 26882, 26883, 26886, 26887, 26888, 26889, 26890, 26893, 26894, 26895, 26896, 26897, 26898, 26899, 26900, 26903, 26904, 26905, 26906, 26907, 26908, 26910, 26911, 26912, 26913, 26915, 26916, 26917, 26919, 26920, 26922, 26923, 26924, 26925, 26929, 26930, 26932, 26935, 26936, 26937, 26938, 26939, 26940, 26941, 26942, 26944, 26946, 26948, 26949, 26950, 26951, 26952, 26953, 26954, 26955, 26956, 26958, 26963, 26966, 26967, 26969, 26971, 26972, 26974, 26975, 26978, 26979, 26980, 26981, 26983, 26985, 26986, 26987, 26989, 26990, 26993, 26994, 26996, 26997, 26998, 26999, 27001, 27003, 27004, 27010, 27011, 27012, 27013, 27017, 27018, 27019, 27020, 27021, 27022, 27023, 27024, 27025, 27027, 27028, 27029, 27030, 27031, 27826, 27827, 27828, 27832, 27833, 27834, 27837, 27838, 27841, 27842, 27845, 27846, 27847, 27849, 27851, 27853, 27854, 27855, 27856, 27857, 27858, 27859, 27861, 27865, 27868, 27869, 27870, 27873, 27874, 27878, 27879, 27880, 27882, 27883, 27885, 27887, 27888, 27889, 27890, 27891, 27893, 27894, 27895, 27900, 27901, 27904, 27905, 27910, 27911, 27912, 27913, 27915, 27916, 27918, 27920, 27923, 27924, 27926, 27927, 27928, 27929, 27930, 27931, 27933, 27934, 27935, 27936, 27937, 27939, 27940, 27941, 27942, 27943, 27944, 27945, 27946, 27948, 27950, 27951, 27953, 27954, 27956, 27957, 27959, 27960, 27961, 27962, 27965, 27967, 27968, 27970, 27972, 27973, 27975, 27976, 27978, 27979, 27980, 27981, 27983, 27984, 27988, 27989, 27990, 27993, 27994, 27995, 27996, 27997, 27999, 28000, 28001, 28002, 28004, 28006, 28012, 28013, 28014, 28015, 28016, 28018, 28019, 28024, 28025, 28026, 28027, 28029, 28030, 28031, 28032, 28033, 28034, 28036, 28038, 28039, 28040, 28041, 28042, 28043, 28044, 28045, 28046, 28048, 28049, 28050, 28052, 28053, 28054, 28056, 28057, 28058, 28062, 28065, 28067, 28068, 28073, 28075, 28080, 28082, 28084, 28085, 28086, 28095, 28096, 28097, 28098, 28100, 28101, 28102, 28106, 28108, 28110, 28112, 28114, 28115, 28117, 28119, 28121, 28122, 28123, 28124, 28126, 28127, 28128, 28129, 28133, 28134, 28136, 28138, 28141, 28143, 28145, 28146, 28147, 28148, 28149, 28150, 28151, 28152, 28155, 28156, 28158, 28160, 28162, 28165, 28169, 28172, 28173, 28176, 28177, 28178, 28179, 28180, 28181, 28183, 28185, 28190, 28192, 28193, 28194, 28195, 28198, 28203, 28204, 28205, 28206, 28208, 28209, 28210, 28211, 28212, 28215, 28216, 28218, 28220, 28221, 28222, 28223, 28224, 28227, 28229, 28232, 28233, 28234, 28235, 28236, 28237, 28238, 28240, 28242, 28243, 28247, 28248, 28249, 28252, 28253, 28254, 28257, 28260, 28263, 28265, 28267, 28268, 28269, 28271, 28272, 28273, 28274, 28275, 28276, 28280, 28281, 28282, 28283, 28289, 28291, 28293, 28294, 28296, 28301, 28302, 28303, 28305, 28307, 28308, 28309, 28312, 28317, 28319, 28321, 28322, 28324, 28325, 28327, 28328, 28329, 28333, 28334, 28338, 28344, 28345, 28347, 28348, 28349, 28350, 28351, 28352, 28354, 28357, 28359, 28360, 28361, 28364, 28365, 28366, 28367, 28369, 28373, 28374, 28375, 28377, 28379, 28380, 28381, 28384, 28387, 28388, 28389, 28394, 28395, 28397, 28398, 28399, 28402, 28403, 28405, 28406, 28408, 28409, 28410, 28412, 28414, 28415, 28417, 28420, 28422, 28423, 28427, 28428, 28429, 28432, 28433, 28435, 28436, 28437, 28438, 28439, 28440, 28441, 28444, 28445, 28447, 28448, 28449, 28450, 28451, 28452, 28455, 28456, 28457, 28458, 28460, 28461, 28462, 28464, 28466, 28467, 28470, 28471, 28472, 28473, 28475, 28476, 28477, 28478, 28479, 28482, 28484, 28485, 28486, 28488, 28490, 28492, 28495, 28496, 28497, 28498, 28500, 28503, 28504, 28505, 28507, 28508, 28510, 28512, 28513, 28514, 28515, 28516, 28518, 28519, 28520, 28523, 28524, 28525, 28526, 28527, 28528, 28529, 28530, 28531, 28532, 28533, 28534, 28536, 28537, 28538, 28539, 28542, 28543, 28545, 28546, 28547, 28549, 28551, 28557, 28558, 28563, 28564, 28565, 28570, 28572, 28573, 28575, 28576, 28577, 28578, 28581, 28584, 28587, 28590, 28592, 28593, 28594, 28597, 28599, 28600, 28601, 28602, 28603, 28604, 28605, 28606, 28607, 28608, 28609, 28611, 28614, 28615, 28618, 28619, 28620, 28622, 28623, 28624, 28626, 28627, 28628, 28629, 28630, 28631, 28632, 28633, 28635, 28640, 28642, 28643, 28644, 28645, 28646, 28647, 28648, 28649, 28650, 28653, 28654, 28655, 28656, 28657, 28658, 28659, 28660, 28661, 28662, 28667, 28669, 28670, 28672, 28673, 28675, 28676, 28677, 28678, 28679, 28683, 28689, 28693, 28694, 28878, 28880, 28881, 28883, 28884, 28885, 28886, 28888, 28889, 28890, 28891, 28892, 28893, 28894, 28895, 28896, 28897, 28899, 28901, 28902, 28903, 28904, 28905, 28907, 28908, 28909, 28910, 28911, 28912, 28915, 28916, 28919, 28922, 28923, 28924, 28926, 28927, 28929, 28930, 28932, 28933, 28935, 28938, 28939, 28940, 28941, 28942, 28943, 28947, 28948, 28950, 28951, 28952, 28953, 28957, 28958, 28959, 28960, 28961, 28963, 28965, 28970, 28971, 28976, 28977, 28978, 28981, 28983, 28985, 28986, 28987, 28988, 28990, 28992, 28993, 28995, 28996, 28997, 28999, 29000, 29002, 29004, 29005, 29006, 29007, 29008, 29009, 29011, 29013, 29014, 29015, 29016, 29017, 29019, 29020, 29021, 29022, 29023, 29025, 29028, 29029, 29030, 29032, 29033, 29034, 29038, 29039, 29040, 29043, 29044, 29045, 29046, 29047, 29048, 29049, 29051, 29052, 29053, 29057, 29058, 29062, 29063, 29065, 29066, 29067, 29069, 29070, 29072, 29074, 29075, 29076, 29077, 29079, 29080, 29081, 29083, 29084, 29086, 29087, 29088, 29091, 29092, 29093, 29095, 29096, 29098, 29101, 29102, 29103, 29104, 29107, 29109, 29110, 29111, 29112, 29114, 29115, 29118, 29119, 29120, 29121, 29122, 29123, 29125, 29132, 29133, 29134, 29135, 29136, 29139, 29140, 29142, 29143, 29144, 29145, 29148, 29150, 29152, 29153, 29155, 29157, 29158, 29159, 29160, 29161, 29162, 29164, 29165, 29167, 29168, 29169, 29170, 29171, 29172, 29174, 29175, 29176, 29177, 29178, 29179, 29182, 29185, 29188, 29189, 29190, 29191, 29192, 29196, 29199, 29201, 29202, 29203, 29205, 29206, 29207, 29208, 29213, 29215, 29217, 29218, 29219, 29220, 29222, 29224, 29225, 29226, 29230, 29233, 29234, 29235, 29239, 29241, 29245, 29246, 29247, 29251, 29252, 29253, 29255, 29257, 29258, 29259, 29260, 29261, 29263, 29264, 29265, 29268, 29271, 29274, 29277, 29278, 29281, 29283, 29284, 29286, 29289, 29292, 29293, 29295, 29297, 29300, 29301, 29302, 29303, 29305, 29309, 29310, 29311, 29312, 29313, 29314, 29315, 29316, 29319, 29320, 29323, 29324, 29325, 29327, 29328, 29329, 29330, 29331, 29333, 29335, 29338, 29339, 29340, 29341, 29343, 29347, 29348, 29349, 29350, 29351, 29353, 29354, 29356, 29357, 29358, 29360, 29361, 29362, 29363, 29366, 29369, 29373, 29374, 29377, 29380, 29381, 29383, 29384, 29387, 29391, 29392, 29393, 29394, 29395, 29396, 29400, 29401, 29402, 29404, 29407, 29408, 29409, 29411, 29412, 29413, 29414, 29416, 29421, 29423, 29424, 29427, 29430, 29431, 29437, 29438, 29439, 29440, 29441, 29442, 29443, 29444, 29445, 29446, 29448, 29449, 29450, 29453, 29454, 29456, 29457, 29458, 29461, 29462, 29464, 29466, 29467, 29469, 29470, 29471, 29472, 29473, 29475, 29476, 29478, 29482, 29483, 29485, 29487, 29489, 29491, 29493, 29495, 29496, 29497, 29498, 29499, 29500, 29501, 29502, 29506, 29508, 29509, 29511, 29514, 29515, 29516, 29518, 29519, 29520, 29525, 29526, 29527, 29528, 29531, 29532, 29533, 29534, 29535, 29537, 29539, 29542, 29543, 29544, 29546, 29547, 29548, 29550, 29552, 29556, 29557, 29558, 29560, 29561, 29562, 29563, 29564, 29565, 29568, 29570, 29572, 29573, 29574, 29576, 29579, 29581, 29585, 29586, 29587, 29590, 29594, 29596, 29597, 29598, 29599, 29601, 29605, 29606, 29607, 29608, 29609, 29613, 29615, 29617, 29619, 29620, 29622, 29623, 29624, 29626, 29628, 29632, 29633, 29634, 29635, 29637, 29638, 29639, 29640, 29641, 29643, 29644, 29646, 29647, 29648, 29650, 29651, 29652, 29653, 29654, 29656, 29657, 29658, 29663, 29665, 29666, 29669, 29670, 29671, 29672, 29673, 29674, 29675, 29676, 29678, 29679, 29681, 29683, 29686, 29688, 29689, 29690, 29692, 29694, 29695, 29696, 29697, 29699, 29701, 29702, 29704, 29706, 29724, 30511, 30512, 30515, 30518, 30519, 30520, 30521, 30523, 30524, 30525, 30527, 30529, 30530, 30531, 30532, 30533, 30536, 30537, 30540, 30542, 30543, 30544, 30546, 30548, 30549, 30550, 30551, 30553, 30554, 30557, 30558, 30565, 30566, 30567, 30568, 30570, 30572, 30573, 30575, 30576, 30577, 30578, 30579, 30580, 30581, 30583, 30584, 30586, 30587, 30589, 30591, 30593, 30595, 30596, 30597, 30599, 30601, 30604, 30606, 30607, 30610, 30611, 30612, 30613, 30614, 30615, 30616, 30618, 30619, 30623, 30625, 30626, 30628, 30629, 30631, 30632, 30633, 30635, 30636, 30637, 30642, 30645, 30646, 30648, 30649, 30650, 30651, 30653, 30654, 30655, 30657, 30658, 30659, 30660, 30661, 30662, 30663, 30664, 30665, 30666, 30668, 30669, 30670, 30671, 30672, 30673, 30674, 30675, 30676, 30677, 30678, 30679, 30681, 30682, 30683, 30685, 30686, 30687, 30688, 30690, 30691, 30692, 30693, 30695, 30696, 30697, 30699, 30700, 30701, 30702, 30703, 30705, 30706, 30707, 30708, 30709, 30714, 30715, 30716, 30717, 30721, 30722, 30723, 30724, 30725, 30726, 30727, 30728, 30730, 30731, 30732, 30733, 30735, 30737, 30739, 30740, 30741, 30744, 30745, 30746, 30747, 30749, 30751, 30752, 30754, 30755, 30757, 30758, 30760, 30762, 30764, 30767, 30768, 30769, 30770, 30771, 30774, 30775, 30776, 30777, 30778, 30780, 30782, 30783, 30784, 30785, 30787, 30789, 30790, 30791, 30792, 30793, 30795, 30796, 30797, 30800, 30801, 30802, 30803, 30805, 30806, 30807, 30808, 30810, 30814, 30818, 30819, 30820, 30822, 30824, 30825, 30830, 30831, 30833, 30836, 30837, 30838, 30840, 30841, 30843, 30845, 30846, 30847, 30848, 30849, 30850, 30851, 30853, 30854, 30855, 30856, 30857, 30858, 30859, 30860, 30863, 30866, 30868, 30869, 30873, 30874, 30875, 30877, 30878, 30879, 30880, 30883, 30885, 30886, 30887, 30889, 30890, 30891, 30893, 30894, 30895, 30897, 30899, 30902, 30903, 30905, 30906, 30907, 30913, 30918, 30919, 30920, 30921, 30922, 30923, 30924, 30925, 30926, 30927, 30928, 30929, 30930, 30931, 30932, 30935, 30936, 30937, 30938, 30939, 30940, 30941, 30943, 30944, 30945, 30948, 30949, 30950, 30952, 30953, 30954, 30956, 30958, 30959, 30961, 30962, 30965, 30966, 30968, 30971, 30972, 30973, 30975, 30976, 30980, 30981, 30983, 30984, 30985, 30986, 30987, 30989, 30990, 30992, 30993, 30994, 30995, 30996, 30997, 30998, 30999, 31001, 31002, 31004, 31005, 31007, 31009, 31011, 31013, 31014, 31015, 31016, 31017, 31018, 31019, 31020, 31021, 31022, 31023, 31024, 31025, 31026, 31027, 31028, 31029, 31030, 31033, 31034, 31035, 31037, 31038, 31040, 31041, 31043, 31045, 31046, 31047, 31048, 31049, 31053, 31055, 31056, 31057, 31058, 31061, 31062, 31063, 31066, 31068, 31069, 31070, 31071, 31072, 31074, 31077, 31078, 31080, 31081, 31082, 31083, 31087, 31090, 31093, 31095, 31098, 31099, 31100, 31101, 31103, 31104, 31105, 31106, 31108, 31109, 31110, 31111, 31113, 31114, 31115, 31117, 31118, 31119, 31120, 31121, 31123, 31126, 31127, 31128, 31130, 31134, 31136, 31139, 31141, 31144, 31145, 31147, 31148, 31151, 31152, 31153, 31157, 31159, 31163, 31165, 31166, 31168, 31169, 31172, 31174, 31177, 31178, 31179, 31181, 31185, 31186, 31187, 31189, 31190, 31192, 31194, 31196, 31198, 31200, 31203, 31204, 31205, 31206, 31208, 31209, 31210, 31211, 31214, 31215, 31217, 31218, 31219, 31221, 31223, 31224, 31225, 31226, 31227, 31228, 31232, 31233, 31234, 31235, 31236, 31237, 31238, 31239, 31242, 31244, 31245, 31246, 31248, 31249, 31250, 31252, 31388, 31390, 31393, 31394, 31395, 31396, 31397, 31398, 31399, 31401, 31404, 31405, 31407, 31412, 31414, 31421, 31423, 31426, 31427, 31428, 31431, 31436, 31437, 31438, 31439, 31440, 31447, 31448, 31449, 31451, 31452, 31454, 31455, 31456, 31457, 31458, 31459, 31461, 31462, 31466, 31469, 31470, 31475, 31476, 31478, 31484, 31485, 31488, 31489, 31491, 31493, 31495, 31497, 31499, 31506, 31508, 31516, 31519, 31522, 31523, 31529, 31531, 31533, 31536, 31539, 31540, 31541, 31548, 31550, 31553, 31554, 31558, 31561, 31562, 31564, 31566, 31570, 31574, 31578, 31580, 31582, 31584, 31585, 31586, 31587, 31588, 31589, 31590, 31592, 31593, 31594, 31595, 31596, 31597, 31599, 31600, 31603, 31606, 31609, 31611, 31612, 31613, 31615, 31616, 31617, 31618, 31619, 31620, 31622, 31624, 31627, 31629, 31631, 31632, 31633, 31634, 31635, 31637, 31638, 31645, 31646, 31647, 31650, 31652, 31654, 31656, 31658, 31659, 31660, 31661, 31664, 31665, 31667, 31669, 31671, 31672, 31673, 31674, 31675, 31676, 31678, 31680, 31681, 31684, 31685, 31688, 31689, 31693, 31698, 31699, 31700, 31701, 31703, 31705, 31708, 31711, 31715, 31717, 31718, 31719, 31720, 31724, 31726, 31727, 31728, 31731, 31732, 31733, 31736, 31739, 31740, 31741, 31744, 31745, 31746, 31747, 31748, 31750, 31751, 31752, 31753, 31754, 31756, 31758, 31759, 31762, 31765, 31767, 31769, 31772, 31774, 31775, 31776, 31777, 31778, 31779, 31781, 31782, 31785, 31786, 31792, 31794, 31796, 31797, 31798, 31802, 31803, 31804, 31806, 31807, 31808, 31809, 31811, 31813, 31815, 31816, 31817, 31818, 31820, 31823, 31824, 31825, 31827, 31831, 31832, 31834, 31837, 31839, 31842, 31848, 31851, 31853, 31854, 31859, 31860, 31867, 31868, 31877, 31878, 31879, 31881, 31883, 31884, 31887, 31891, 31897, 31902, 31905, 31908, 31910, 31912, 31913, 31915, 31916, 31922, 31925, 31930, 31932, 31939, 31944, 31947, 32081, 32082, 32083, 32086, 32087, 32089, 32091, 32096, 32100, 32101, 32103, 32104, 32105, 32109, 32111, 32116, 32119, 32120, 32124, 32125, 32127, 32128, 32130, 32131, 32132, 32136, 32139, 32143, 32144, 32145, 32147, 32148, 32150, 32153, 32154, 32155, 32156, 32158, 32159, 32160, 32161, 32162, 32164, 32165, 32167, 32168, 32169, 32171, 32172, 32174, 32177, 32178, 32179, 32180, 32184, 32185, 32186, 32188, 32191, 32192, 32193, 32194, 32195, 32196, 32197, 32200, 32201, 32203, 32205, 32206, 32209, 32211, 32212, 32213, 32214, 32216, 32219, 32220, 32221, 32222, 32223, 32224, 32225, 32228, 32230, 32232, 32233, 32234, 32235, 32236, 32237, 32238, 32241, 32242, 32246, 32247, 32248, 32250, 32251, 32252, 32253, 32255, 32256, 32257, 32258, 32260, 32263, 32264, 32266, 32267, 32268, 32269, 32270, 32272, 32275, 32277, 32279, 32287, 32288, 32289, 32290, 32292, 32293, 32294, 32295, 32298, 32299, 32300, 32301, 32304, 32305, 32306, 32307, 32308, 32309, 32310, 32312, 32313, 32321, 32326, 32328, 32329, 32333, 32335, 32336, 32337, 32338, 32339, 32341, 32342, 32343, 32345, 32348, 32349, 32350, 32351, 32352, 32353, 32354, 32355, 32357, 32358, 32359, 32360, 32361, 32362, 32364, 32366, 32369, 32370, 32371, 32372, 32373, 32374, 32375, 32376, 32377, 32379, 32380, 32382, 32384, 32385, 32390, 32391, 32393, 32399, 32400, 32401, 32403, 32404, 32405, 32408, 32409, 32410, 32411, 32412, 32413, 32418, 32420, 32421, 32422, 32423, 32424, 32427, 32428, 32429, 32431, 32432, 32433, 32434, 32435, 32437, 32439, 32441, 32442, 32444, 32445, 32447, 32450, 32451, 32452, 32454, 32456, 32457, 32459, 32460, 32463, 32465, 32467, 32469, 32470, 32471, 32472, 32473, 32474, 32477, 32481, 32483, 32484, 32491, 32492, 32493, 32494, 32496, 32498, 32500, 32501, 32502, 32503, 32505, 32506, 32507, 32510, 32511, 32513, 32520, 32522, 32523, 32524, 32525, 32526, 32527, 32530, 32532, 32534, 32535, 32536, 32537, 32538, 32539, 32540, 32542, 32544, 32545, 32546, 32549, 32550, 32553, 32556, 32557, 32559, 32560, 32562, 32563, 32564, 32569, 32571, 32572, 32573, 32574, 32575, 32577, 32578, 32579, 32580, 32583, 32584, 32585, 32586, 32589, 32590, 32591, 32593, 32594, 32595, 32596, 32598, 32600, 32601, 32602, 32603, 32605, 32606, 32607, 32608, 32611, 32612, 32614, 32615, 32616, 32619, 32620, 32621, 32622, 32623, 32626, 32628, 32629, 32630, 32632, 32634, 32635, 32636, 32641, 32642, 32644, 32645, 32649, 32650, 32651, 32654, 32655, 32656, 32658, 32659, 32660, 32662, 32663, 32665, 32669, 32670, 32671, 32673, 32674, 32675, 32676, 32678, 32680, 32681, 32683, 32685, 32686, 32687, 32688, 32690, 32692, 32693, 32694, 32695, 32697, 32698, 32699, 32705, 32707, 32712, 32716, 32722, 32877, 32910, 32914, 32916, 32957, 32968, 32987, 32991, 33015, 33018, 33028, 33050, 33057, 33062, 33074, 33099, 33104, 33112, 33187, 33202, 33228, 33230, 33244, 33252, 33258, 33271, 33273, 33288, 33301, 33328, 33362, 33377, 33382, 33386, 33403, 33416, 33445, 33456, 33465, 33467, 33478, 33483, 33486, 33502, 33550, 33562, 33564, 33565, 33567, 33570, 33571, 33572, 33573, 33576, 33578, 33579, 33580, 33581, 33583, 33584, 33585, 33588, 33590, 33592, 33593, 33595, 33596, 33597, 33599, 33600, 33601, 33602, 33603, 33606, 33607, 33608, 33609, 33610, 33612, 33613, 33614, 33615, 33616, 33617, 33618, 33620, 33621, 33622, 33624, 33625, 33627, 33628, 33630, 33633, 33634, 33635, 33638, 33639, 33641, 33642, 33644, 33648, 33649, 33650, 33651, 33652, 33653, 33654, 33655, 33657, 33658, 33659, 33660, 33662, 33663, 33664, 33665, 33666, 33667, 33668, 33671, 33672, 33673, 33674, 33675, 33676, 33677, 33678, 33679, 33680, 33681, 33683, 33684, 33685, 33686, 33687, 33690, 33692, 33693, 33696, 33697, 33698, 33699, 33700, 33701, 33704, 33705, 33708, 33710, 33711, 33712, 33713, 33718, 33719, 33721, 33724, 33727, 33728, 33730, 33731, 33732, 33733, 33736, 33739, 33743, 33744, 33748, 33750, 33751, 33752, 33753, 33754, 33755, 33756, 33757, 33758, 33759, 33763, 33764, 33765, 33766, 33768, 33769, 33771, 33772, 33773, 33774, 33775, 33776, 33777, 33778, 33779, 33781, 33782, 33785, 33786, 33788, 33789, 33790, 33791, 33792, 33793, 33794, 33796, 33798, 33799, 33803, 33804, 33805, 33807, 33809, 33810, 33812, 33813, 33814, 33815, 33817, 33818, 33819, 33820, 33821, 33823, 33824, 33825, 33826, 33828, 33829, 33831, 33832, 33833, 33834, 33835, 33836, 33837, 33838, 33840, 33841, 33843, 33846, 33847, 33849, 33850, 33851, 33852, 33853, 33854, 33856, 33861, 33863, 33864, 33865, 33866, 33868, 33869, 33871, 33873, 33875, 33878, 33880, 33881, 33884, 33885, 33887, 33890, 33892, 33895, 33898, 33899, 33900, 33901, 33902, 33905, 33907, 33909, 33911, 33913, 33915, 33916, 33918, 33919, 33920, 33921, 33922, 33924, 33927, 33932, 33933, 33934, 33935, 33936, 33940, 33941, 33942, 33943, 33945, 33947, 33953, 33955, 33956, 33957, 33958, 33960, 33963, 33964, 33965, 33968, 33969, 33970, 33971, 33973, 33974, 33978, 33985, 33986, 33989, 33990, 33991, 33995, 33997, 34000, 34003, 34004, 34008, 34009, 34010, 34020, 34025, 34029, 34031, 34033, 34034, 34035, 34037, 34040, 34041, 34042, 34043, 34046, 34047, 34050, 34060, 34061, 34063, 34064, 34066, 34067, 34068, 34069, 34072, 34073, 34074, 34077, 34080, 34088, 34089, 34096, 34098, 34104, 34105, 34112, 34118, 34119, 34120, 34121, 34124, 34262, 34265, 34268, 34269, 34270, 34274, 34276, 34279, 34280, 34282, 34283, 34288, 34289, 34291, 34292, 34293, 34297, 34298, 34299, 34300, 34303, 34304, 34306, 34308, 34312, 34316, 34317, 34318, 34319, 34322, 34324, 34325, 34326, 34327, 34328, 34329, 34330, 34332, 34335, 34336, 34338, 34339, 34340, 34341, 34343, 34345, 34347, 34348, 34351, 34352, 34353, 34357, 34359, 34363, 34369, 34370, 34371, 34374, 34376, 34378, 34385, 34386, 34389, 34390, 34393, 34394, 34396, 34398, 34399, 34400, 34401, 34402, 34403, 34404, 34405, 34406, 34407, 34414, 34415, 34416, 34417, 34421, 34422, 34426, 34431, 34434, 34438, 34443, 34445, 34446, 34452, 34456, 34458, 34463, 34464, 34467, 34470, 34471, 34472, 34473, 34476, 34477, 34480, 34483, 34486, 34488, 34489, 34490, 34491, 34492, 34495, 34499, 34500, 34505, 34506, 34510, 34511, 34512, 34514, 34515, 34516, 34518, 34519, 34520, 34521, 34523, 34525, 34526, 34528, 34529, 34531, 34533, 34534, 34539, 34543, 34546, 34552, 34554, 34555, 34556, 34557, 34558, 34561, 34562, 34565, 34569, 34572, 34574, 34576, 34577, 34579, 34580, 34581, 34585, 34586, 34589, 34590, 34592, 34593, 34595, 34596, 34598, 34599, 34601, 34602, 34603, 34605, 34608, 34610, 34611, 34614, 34615, 34616, 34618, 34620, 34622, 34623, 34624, 34626, 34627, 34628, 34629, 34631, 34632, 34635, 34636, 34639, 34641, 34643, 34651, 34665, 34667, 34668, 34669, 34673, 34681, 34685, 34808, 34832, 34833, 34835, 34837, 34838, 34842, 34844, 34847, 34849, 34852, 34856, 34860, 34861, 34862, 34866, 34867, 34868, 34870, 34872, 34873, 34877, 34878, 34880, 34881, 34883, 34886, 34887, 34888, 34889, 34891, 34894, 34896, 34898, 34899, 34901, 34902, 34906, 34907, 34909, 34911, 34914, 34915, 34917, 34919, 34921, 34925, 34928, 34929, 34930, 34934, 34936, 34937, 34939, 34940, 34943, 34944, 34947, 34948, 34952, 34954, 34956, 34960, 34961, 34962, 34963, 34964, 34965, 34967, 34968, 34974, 34975, 34977, 34978, 34979, 34980, 34982, 34983, 34984, 34985, 34987, 34988, 34989, 34992, 34993, 34994, 34995, 34996, 34997, 34999, 35000, 35001, 35003, 35005, 35006, 35007, 35008, 35009, 35010, 35011, 35012, 35013, 35015, 35016, 35020, 35025, 35026, 35028, 35031, 35032, 35034, 35035, 35036, 35037, 35039, 35040, 35043, 35046, 35047, 35048, 35050, 35053, 35054, 35055, 35056, 35057, 35058, 35059, 35060, 35061, 35062, 35064, 35065, 35066, 35067, 35068, 35070, 35071, 35074, 35075, 35077, 35079, 35081, 35084, 35087, 35088, 35089, 35090, 35092, 35093, 35094, 35096, 35098, 35099, 35102, 35104, 35105, 35106, 35107, 35109, 35114, 35116, 35118, 35120, 35122, 35124, 35125, 35126, 35129, 35131, 35132, 35134, 35138, 35139, 35140, 35144, 35145, 35146, 35149, 35150, 35152, 35154, 35155, 35156, 35157, 35158, 35159, 35160, 35161, 35163, 35165, 35167, 35170, 35171, 35173, 35174, 35175, 35182, 35183, 35188, 35189, 35192, 35196, 35197, 35198, 35199, 35201, 35202, 35203, 35205, 35206, 35208, 35209, 35210, 35211, 35212, 35216, 35218, 35220, 35224, 35225, 35226, 35227, 35231, 35233, 35234, 35235, 35238, 35239, 35242, 35244, 35245, 35248, 35249, 35250, 35251, 35252, 35255, 35257, 35260, 35265, 35268, 35274, 35275, 35279, 35280, 35281, 35286, 35290, 35291, 35292, 35293, 35295, 35297, 35300, 35305, 35306, 35308, 35311, 35313, 35314, 35315, 35317, 35319, 35322, 35326, 35327, 35329, 35331, 35332, 35334, 35335, 35340, 35341, 35343, 35345, 35356, 35357, 35362, 35366, 35368, 35369, 35371, 35374, 35376, 35384, 35387, 35543, 35554, 35558, 35563, 35566, 35567, 35568, 35569, 35571, 35576, 35578, 35580, 35581, 35582, 35583, 35584, 35585, 35586, 35589, 35590, 35592, 35593, 35594, 35595, 35596, 35599, 35601, 35602, 35603, 35604, 35605, 35608, 35611, 35612, 35614, 35616, 35618, 35619, 35620, 35621, 35622, 35623, 35624, 35626, 35627, 35630, 35631, 35633, 35636, 35638, 35639, 35641, 35643, 35644, 35645, 35646, 35649, 35651, 35654, 35656, 35657, 35658, 35659, 35660, 35661, 35662, 35663, 35664, 35665, 35666, 35667, 35668, 35669, 35670, 35671, 35672, 35673, 35674, 35675, 35676, 35677, 35678, 35680, 35681, 35682, 35685, 35686, 35687, 35690, 35691, 35692, 35694, 35699, 35701, 35703, 35705, 35707, 35709, 35710, 35712, 35714, 35715, 35716, 35717, 35718, 35719, 35720, 35721, 35722, 35723, 35724, 35726, 35727, 35729, 35730, 35732, 35733, 35735, 35737, 35738, 35740, 35745, 35748, 35749, 35750, 35754, 35755, 35756, 35757, 35759, 35760, 35761, 35763, 35764, 35765, 35767, 35768, 35769, 35770, 35774, 35776, 35777, 35779, 35781, 35782, 35783, 35784, 35785, 35786, 35787, 35789, 35791, 35792, 35793, 35794, 35795, 35796, 35798, 35799, 35800, 35802, 35803, 35805, 35806, 35807, 35808, 35812, 35815, 35816, 35818, 35819, 35820, 35821, 35823, 35827, 35831, 35832, 35833, 35834, 35835, 35836, 35837, 35839, 35840, 35842, 35843, 35845, 35846, 35847, 35848, 35849, 35850, 35851, 35852, 35854, 35855, 35856, 35857, 35860, 35863, 35864, 35867, 35868, 35869, 35872, 35873, 35874, 35875, 35877, 35878, 35879, 35881, 35882, 35883, 35884, 35885, 35886, 35888, 35889, 35891, 35893, 35894, 35896, 35897, 35898, 35899, 35900, 35901, 35902, 35903, 35904, 35905, 35906, 35907, 35908, 35909, 35910, 35911, 35914, 35916, 35918, 35919, 35921, 35922, 35923, 35924, 35925, 35926, 35928, 35929, 35930, 35931, 35932, 35934, 35936, 35937, 35938, 35939, 35944, 35948, 35949, 35954, 35955, 35956, 35957, 35958, 35961, 35962, 35964, 35966, 35967, 35969, 35970, 35971, 35973, 35975, 35976, 35978, 35980, 35983, 35984, 35985, 35986, 35988, 35989, 35990, 35991, 35992, 35995, 35996, 35997, 35999, 36001, 36003, 36004, 36005, 36006, 36007, 36008, 36009, 36011, 36012, 36013, 36014, 36016, 36017, 36018, 36019, 36021, 36024, 36025, 36028, 36029, 36030, 36031, 36032, 36034, 36035, 36036, 36037, 36038, 36039, 36040, 36041, 36043, 36044, 36046, 36049, 36051, 36052, 36053, 36054, 36057, 36058, 36060, 36061, 36062, 36063, 36064, 36067, 36068, 36069, 36070, 36071, 36072, 36073, 36075, 36078, 36079, 36080, 36081, 36082, 36084, 36086, 36089, 36092, 36094, 36098, 36101, 36105, 36109, 36110, 36111, 36112, 36113, 36116, 36118, 36119, 36120, 36121, 36122, 36123, 36125, 36126, 36127, 36128, 36130, 36131, 36133, 36134, 36135, 36140, 36141, 36142, 36143, 36144, 36146, 36148, 36150, 36153, 36154, 36155, 36156, 36157, 36158, 36159, 36160, 36161, 36163, 36164, 36165, 36167, 36168, 36171, 36173, 36174, 36175, 36176, 36177, 36179, 36180, 36181, 36182, 36183, 36184, 36185, 36188, 36192, 36197, 36200, 36201, 36203, 36205, 36209, 36213, 36215, 36221, 36224, 36550, 36556, 36686, 36810, 36849, 36853, 36955, 37010, 37011, 37012, 37015, 37018, 37026, 37027, 37029, 37030, 37032, 37033, 37034, 37035, 37036, 37037, 37038, 37042, 37043, 37044, 37048, 37050, 37051, 37055, 37056, 37057, 37062, 37064, 37065, 37067, 37068, 37069, 37071, 37073, 37074, 37078, 37081, 37084, 37085, 37087, 37089, 37090, 37091, 37095, 37097, 37100, 37101, 37102, 37104, 37105, 37108, 37110, 37114, 37115, 37119, 37120, 37122, 37124, 37125, 37126, 37127, 37130, 37131, 37133, 37135, 37136, 37139, 37140, 37142, 37144, 37145, 37147, 37149, 37150, 37151, 37152, 37155, 37157, 37159, 37160, 37161, 37163, 37164, 37166, 37167, 37169, 37170, 37171, 37172, 37173, 37178, 37179, 37180, 37181, 37182, 37184, 37185, 37186, 37191, 37192, 37193, 37194, 37195, 37196, 37197, 37198, 37199, 37200, 37202, 37203, 37204, 37207, 37209, 37211, 37212, 37213, 37214, 37221, 37223, 37224, 37225, 37226, 37227, 37229, 37230, 37231, 37232, 37233, 37235, 37236, 37237, 37239, 37241, 37242, 37243, 37247, 37248, 37249, 37250, 37253, 37256, 37257, 37258, 37260, 37264, 37267, 37271, 37272, 37273, 37274, 37275, 37276, 37277, 37278, 37280, 37281, 37283, 37287, 37288, 37292, 37293, 37295, 37296, 37297, 37298, 37300, 37302, 37303, 37304, 37305, 37307, 37309, 37310, 37311, 37315, 37316, 37318, 37319, 37321, 37322, 37323, 37325, 37327, 37328, 37329, 37330, 37331, 37333, 37334, 37336, 37338, 37341, 37343, 37344, 37346, 37349, 37351, 37352, 37354, 37357, 37358, 37360, 37363, 37364, 37365, 37367, 37370, 37371, 37373, 37374, 37376, 37377, 37378, 37379, 37380, 37381, 37382, 37383, 37384, 37387, 37388, 37389, 37392, 37394, 37396, 37401, 37402, 37404, 37405, 37406, 37407, 37408, 37409, 37410, 37413, 37414, 37415, 37417, 37419, 37420, 37423, 37424, 37428, 37430, 37431, 37432, 37433, 37435, 37436, 37438, 37440, 37443, 37445, 37449, 37452, 37455, 37457, 37459, 37462, 37463, 37464, 37465, 37466, 37469, 37470, 37471, 37472, 37473, 37474, 37475, 37480, 37485, 37486, 37488, 37490, 37491, 37492, 37493, 37494, 37496, 37497, 37498, 37499, 37500, 37501, 37502, 37503, 37507, 37509, 37510, 37511, 37512, 37513, 37514, 37517, 37520, 37521, 37522, 37523, 37524, 37525, 37528, 37529, 37530, 37531, 37532, 37533, 37534, 37535, 37536, 37539, 37540, 37541, 37543, 37548, 37549, 37551, 37552, 37553, 37555, 37556, 37557, 37558, 37562, 37563, 37564, 37567, 37568, 37570, 37574, 37575, 37576, 37577, 37578, 37579, 37580, 37581, 37583, 37584, 37586, 37587, 37588, 37591, 37592, 37594, 37595, 37597, 37598, 37600, 37601, 37604, 37605, 37608, 37610, 37612, 37614, 37616, 37618, 37621, 37622, 37625, 37626, 37627, 37628, 37629, 37632, 37634, 37635, 37636, 37640, 37641, 37642, 37643, 37644, 37645, 37646, 37647, 37649, 37650, 37652, 37655, 37656, 37657, 37660, 37661, 37662, 37663, 37664, 37665, 37666, 37669, 37670, 37672, 37674, 37675, 37676, 37677, 37678, 37679, 37680, 37681, 37682, 37684, 37687, 37688, 37689, 37691, 37694, 37695, 37697, 37699, 37701, 37702, 37703, 37704, 37705, 37706, 37707, 37708, 37709, 37711, 37713, 37714, 37715, 37716, 37717, 37718, 37719, 37720, 37721, 37723, 37724, 37725, 37726, 37728, 37729, 37730, 37731, 37732, 37733, 37734, 37735, 37736, 37738, 37739, 37740, 37741, 37742, 37743, 37745, 37747, 37748, 37749, 37750, 37752, 37754, 37755, 37756, 37757, 37758, 37759, 37761, 37763, 37764, 37765, 37767, 37771, 37773, 37774, 37775, 37776, 37777, 37778, 37780, 37781, 37783, 37785, 37786, 37788, 37789, 37791, 37792, 37798, 37801, 37803, 37805, 37806, 37808, 37809, 37810, 37812, 37813, 37815, 37818, 37819, 37820, 37822, 37824, 37825, 37826, 37828, 37829, 37830, 37831, 37833, 37834, 37838, 37839, 37842, 37845, 37847, 37848, 37849, 37851, 37852, 37854, 37855, 37856, 37858, 37859, 37860, 37862, 37863, 37864, 37868, 37869, 37871, 37873, 37874, 37875, 37876, 37877, 37878, 37881, 37882, 37883, 37885, 38688, 38689, 38690, 38691, 38692, 38694, 38695, 38696, 38697, 38698, 38700, 38702, 38705, 38706, 38707, 38709, 38712, 38713, 38714, 38715, 38718, 38720, 38721, 38723, 38725, 38729, 38733, 38734, 38736, 38741, 38742, 38743, 38744, 38747, 38749, 38750, 38751, 38752, 38753, 38754, 38755, 38756, 38757, 38758, 38759, 38761, 38763, 38766, 38767, 38768, 38769, 38770, 38771, 38774, 38775, 38776, 38778, 38780, 38782, 38783, 38785, 38786, 38789, 38790, 38791, 38792, 38794, 38795, 38797, 38799, 38800, 38801, 38802, 38803, 38804, 38805, 38809, 38810, 38811, 38813, 38814, 38816, 38817, 38818, 38819, 38820, 38823, 38824, 38826, 38827, 38828, 38829, 38830, 38834, 38836, 38838, 38839, 38842, 38843, 38844, 38845, 38846, 38847, 38848, 38849, 38850, 38852, 38853, 38854, 38855, 38859, 38861, 38863, 38864, 38865, 38866, 38868, 38870, 38871, 38872, 38873, 38874, 38875, 38876, 38877, 38879, 38881, 38882, 38884, 38885, 38886, 38890, 38891, 38894, 38895, 38898, 38899, 38900, 38901, 38903, 38904, 38905, 38908, 38910, 38911, 38912, 38913, 38915, 38917, 38918, 38919, 38920, 38921, 38924, 38927, 38932, 38933, 38935, 38937, 38938, 38940, 38941, 38942, 38943, 38944, 38946, 38948, 38949, 38950, 38952, 38953, 38954, 38955, 38956, 38957, 38961, 38963, 38964, 38965, 38966, 38968, 38970, 38971, 38972, 38973, 38975, 38976, 38977, 38978, 38981, 38984, 38985, 38986, 38987, 38988, 38989, 38991, 38992, 38993, 38994, 38995, 38996, 38999, 39000, 39001, 39004, 39006, 39007, 39008, 39010, 39011, 39012, 39014, 39017, 39018, 39019, 39021, 39024, 39025, 39026, 39028, 39029, 39030, 39031, 39032, 39033, 39034, 39035, 39036, 39037, 39038, 39039, 39040, 39041, 39042, 39045, 39046, 39047, 39048, 39049, 39050, 39051, 39052, 39055, 39056, 39057, 39059, 39062, 39063, 39066, 39068, 39070, 39071, 39072, 39073, 39074, 39075, 39076, 39077, 39078, 39079, 39084, 39086, 39087, 39088, 39090, 39091, 39094, 39095, 39098, 39100, 39101, 39105, 39106, 39108, 39109, 39111, 39112, 39113, 39114, 39115, 39116, 39117, 39118, 39119, 39120, 39123, 39124, 39125, 39126, 39127, 39128, 39129, 39130, 39131, 39134, 39138, 39139, 39140, 39141, 39142, 39144, 39145, 39146, 39147, 39148, 39152, 39154, 39156, 39157, 39158, 39159, 39160, 39161, 39162, 39163, 39164, 39165, 39167, 39168, 39169, 39172, 39173, 39174, 39175, 39178, 39181, 39184, 39185, 39186, 39189, 39190, 39192, 39194, 39195, 39196, 39198, 39200, 39202, 39204, 39207, 39208, 39209, 39210, 39212, 39213, 39215, 39218, 39220, 39221, 39222, 39225, 39226, 39228, 39229, 39230, 39231, 39232, 39233, 39234, 39235, 39236, 39238, 39239, 39240, 39241, 39243, 39247, 39249, 39250, 39252, 39253, 39254, 39256, 39257, 39258, 39261, 39262, 39269, 39270, 39271, 39272, 39273, 39275, 39278, 39280, 39284, 39285, 39286, 39287, 39289, 39291, 39292, 39294, 39295, 39296, 39298, 39299, 39300, 39301, 39302, 39303, 39304, 39307, 39310, 39312, 39313, 39316, 39317, 39318, 39320, 39321, 39325, 39327, 39329, 39330, 39331, 39333, 39335, 39340, 39344, 39345, 39346, 39350, 39352, 39353, 39357, 39360, 39363, 39364, 39367, 39369, 39370, 39374, 39375, 39376, 39381, 39386, 39387, 39389, 39391, 39392, 39393, 39396, 39398, 39399, 39400, 39401, 39402, 39407, 39408, 39409, 39411, 39412, 39413, 39414, 39415, 39416, 39418, 39419, 39420, 39421, 39423, 39426, 39427, 39428, 39429, 39430, 39432, 39433, 39434, 39435, 39438, 39440, 39444, 39448, 39451, 39453, 39457, 39467, 39470, 40237, 40238, 40239, 40240, 40241, 40242, 40243, 40244, 40248, 40249, 40250, 40251, 40253, 40257, 40262, 40263, 40264, 40265, 40268, 40270, 40271, 40272, 40273, 40274, 40280, 40281, 40283, 40284, 40285, 40287, 40289, 40291, 40294, 40295, 40297, 40299, 40301, 40304, 40305, 40306, 40308, 40309, 40311, 40312, 40314, 40315, 40316, 40317, 40318, 40320, 40321, 40323, 40324, 40325, 40326, 40328, 40329, 40330, 40331, 40333, 40334, 40336, 40340, 40342, 40343, 40344, 40345, 40346, 40347, 40348, 40349, 40351, 40352, 40354, 40355, 40357, 40358, 40359, 40361, 40364, 40366, 40367, 40368, 40371, 40372, 40373, 40374, 40377, 40378, 40379, 40380, 40381, 40382, 40383, 40384, 40385, 40386, 40387, 40388, 40389, 40390, 40393, 40396, 40399, 40401, 40404, 40405, 40409, 40411, 40412, 40413, 40414, 40416, 40418, 40420, 40423, 40425, 40426, 40428, 40429, 40431, 40434, 40435, 40436, 40437, 40438, 40439, 40441, 40443, 40445, 40446, 40449, 40450, 40451, 40452, 40453, 40455, 40459, 40460, 40463, 40467, 40468, 40469, 40472, 40478, 40480, 40482, 40483, 40484, 40486, 40487, 40488, 40496, 40497, 40498, 40499, 40500, 40501, 40502, 40503, 40504, 40506, 40507, 40508, 40509, 40513, 40514, 40515, 40516, 40517, 40521, 40522, 40524, 40525, 40526, 40531, 40532, 40536, 40538, 40540, 40541, 40542, 40545, 40547, 40549, 40550, 40551, 40552, 40553, 40555, 40557, 40558, 40559, 40560, 40561, 40562, 40563, 40564, 40565, 40566, 40567, 40569, 40570, 40573, 40574, 40575, 40576, 40577, 40578, 40579, 40580, 40581, 40582, 40585, 40586, 40587, 40588, 40589, 40590, 40591, 40594, 40595, 40596, 40597, 40598, 40599, 40600, 40601, 40602, 40604, 40606, 40608, 40610, 40611, 40614, 40618, 40619, 40620, 40621, 40622, 40625, 40628, 40629, 40632, 40634, 40635, 40636, 40638, 40640, 40641, 40643, 40644, 40647, 40649, 40650, 40651, 40655, 40656, 40657, 40659, 40660, 40661, 40662, 40663, 40667, 40668, 40669, 40670, 40671, 40672, 40674, 40675, 40676, 40679, 40682, 40683, 40685, 40686, 40687, 40690, 40691, 40692, 40694, 40695, 40697, 40698, 40699, 40700, 40701, 40702, 40704, 40706, 40707, 40708, 40709, 40713, 40714, 40715, 40718, 40719, 40720, 40721, 40723, 40726, 40727, 40729, 40731, 40732, 40733, 40735, 40738, 40739, 40740, 40741, 40743, 40744, 40746, 40747, 40750, 40751, 40754, 40755, 40756, 40757, 40758, 40759, 40760, 40761, 40762, 40763, 40764, 40765, 40768, 40769, 40770, 40771, 40772, 40773, 40774, 40776, 40778, 40780, 40781, 40784, 40787, 40790, 40791, 40794, 40798, 40799, 40800, 40801, 40802, 40805, 40806, 40807, 40808, 40809, 40813, 40815, 40817, 40818, 40819, 40820, 40821, 40822, 40823, 40824, 40826, 40829, 40831, 40832, 40833, 40834, 40836, 40837, 40839, 40840, 40842, 40843, 40844, 40846, 40847, 40849, 40850, 40853, 40854, 40859, 40860, 40861, 40862, 40863, 40871, 40872, 40873, 40874, 40875, 40877, 40878, 40879, 40881, 40883, 40884, 40885, 40886, 40890, 40892, 40893, 40895, 40896, 40897, 40899, 40902, 40903, 40904, 40907, 40908, 40909, 40910, 40911, 40912, 40913, 40914, 40915, 40916, 40920, 40921, 40922, 40923, 40924, 40925, 40926, 40927, 40929, 40931, 40932, 40933, 40936, 40937, 40938, 40940, 40941, 40942, 40945, 40946, 40949, 40950, 40951, 40952, 40955, 40956, 40961, 40970, 40976, 40978, 40981, 40982, 40984, 40986, 40987, 40988, 40990, 40991, 40994, 40995, 40997, 40999, 41175, 41176, 41177, 41178, 41179, 41181, 41183, 41184, 41185, 41186, 41188, 41189, 41190, 41191, 41193, 41194, 41195, 41196, 41197, 41198, 41200, 41201, 41203, 41206, 41207, 41211, 41214, 41216, 41218, 41219, 41221, 41223, 41226, 41229, 41230, 41231, 41232, 41233, 41235, 41238, 41240, 41241, 41245, 41247, 41248, 41249, 41250, 41252, 41254, 41255, 41256, 41257, 41258, 41259, 41260, 41262, 41263, 41264, 41265, 41266, 41270, 41273, 41274, 41276, 41278, 41279, 41281, 41282, 41284, 41285, 41287, 41288, 41289, 41291, 41298, 41300, 41302, 41307, 41310, 41316, 41318, 41321, 41327, 41328, 41331, 41332, 41334, 41335, 41336, 41337, 41338, 41339, 41344, 41345, 41351, 41354, 41356, 41357, 41358, 41362, 41366, 41367, 41368, 41370, 41371, 41372, 41374, 41375, 41378, 41380, 41383, 41385, 41386, 41387, 41388, 41389, 41392, 41394, 41396, 41399, 41400, 41402, 41403, 41406, 41407, 41410, 41412, 41413, 41415, 41418, 41420, 41422, 41423, 41427, 41428, 41429, 41430, 41431, 41433, 41434, 41438, 41441, 41444, 41446, 41448, 41449, 41450, 41451, 41452, 41453, 41454, 41458, 41459, 41461, 41462, 41464, 41465, 41466, 41467, 41469, 41470, 41471, 41474, 41476, 41477, 41479, 41480, 41481, 41483, 41485, 41486, 41487, 41491, 41495, 41496, 41497, 41502, 41503, 41505, 41507, 41508, 41509, 41510, 41511, 41512, 41514, 41516, 41517, 41518, 41519, 41520, 41521, 41522, 41524, 41528, 41529, 41530, 41533, 41534, 41538, 41539, 41546, 41553, 41557, 41558, 41560, 41561, 41562, 41563, 41565, 41566, 41568, 41573, 41574, 41578, 41585, 41593, 41723, 41724, 41727, 41728, 41729, 41732, 41733, 41735, 41739, 41742, 41745, 41748, 41750, 41751, 41752, 41754, 41757, 41759, 41762, 41763, 41772, 41773, 41774, 41775, 41779, 41780, 41781, 41782, 41783, 41785, 41787, 41794, 41795, 41796, 41798, 41799, 41800, 41801, 41802, 41804, 41806, 41807, 41808, 41809, 41810, 41812, 41813, 41814, 41816, 41817, 41819, 41821, 41822, 41825, 41826, 41827, 41829, 41830, 41833, 41835, 41836, 41839, 41840, 41841, 41842, 41843, 41844, 41845, 41849, 41851, 41853, 41854, 41855, 41856, 41857, 41858, 41861, 41865, 41866, 41867, 41869, 41870, 41871, 41875, 41876, 41877, 41878, 41879, 41880, 41881, 41882, 41885, 41888, 41889, 41890, 41891, 41893, 41895, 41896, 41898, 41899, 41900, 41902, 41903, 41904, 41907, 41908, 41909, 41911, 41912, 41913, 41914, 41915, 41916, 41917, 41920, 41921, 41922, 41923, 41927, 41928, 41930, 41931, 41933, 41934, 41935, 41937, 41938, 41939, 41940, 41941, 41944, 41946, 41948, 41949, 41950, 41951, 41952, 41953, 41954, 41955, 41959, 41961, 41963, 41966, 41969, 41970, 41972, 41974, 41976, 41977, 41979, 41982, 41985, 41986, 41987, 41989, 41990, 41992, 41993, 41994, 41995, 41996, 41997, 41999, 42001, 42002, 42004, 42005, 42006, 42007, 42008, 42009, 42010, 42011, 42012, 42014, 42016, 42017, 42019, 42020, 42022, 42023, 42024, 42026, 42027, 42029, 42032, 42033, 42035, 42037, 42038, 42039, 42040, 42041, 42043, 42045, 42046, 42047, 42048, 42049, 42050, 42051, 42052, 42054, 42056, 42057, 42059, 42061, 42062, 42063, 42064, 42065, 42066, 42067, 42069, 42071, 42072, 42073, 42074, 42077, 42078, 42079, 42081, 42082, 42083, 42086, 42088, 42089, 42092, 42093, 42094, 42096, 42098, 42099, 42100, 42101, 42102, 42103, 42104, 42105, 42107, 42108, 42109, 42110, 42111, 42112, 42113, 42114, 42115, 42116, 42117, 42118, 42120, 42121, 42122, 42123, 42124, 42126, 42127, 42128, 42129, 42131, 42132, 42133, 42134, 42136, 42138, 42139, 42140, 42142, 42143, 42144, 42146, 42147, 42149, 42150, 42151, 42152, 42153, 42154, 42157, 42158, 42159, 42162, 42163, 42164, 42165, 42166, 42167, 42168, 42169, 42170, 42174, 42176, 42177, 42179, 42180, 42182, 42183, 42184, 42185, 42188, 42189, 42190, 42191, 42193, 42194, 42196, 42197, 42198, 42200, 42202, 42206, 42210, 42211, 42213, 42215, 42216, 42217, 42218, 42219, 42220, 42221, 42223, 42226, 42230, 42233, 42234, 42235, 42237, 42238, 42239, 42240, 42241, 42242, 42244, 42245, 42246, 42247, 42250, 42253, 42254, 42256, 42257, 42260, 42262, 42263, 42265, 42266, 42267, 42268, 42269, 42270, 42271, 42272, 42274, 42275, 42276, 42277, 42278, 42280, 42282, 42283, 42284, 42287, 42288, 42289, 42290, 42293, 42294, 42295, 42296, 42297, 42298, 42301, 42303, 42304, 42306, 42308, 42310, 42312, 42314, 42315, 42316, 42318, 42320, 42322, 42324, 42325, 42326, 42328, 42331, 42332, 42333, 42334, 42335, 42336, 42337, 42339, 42340, 42341, 42342, 42343, 42344, 42345, 42346, 42347, 42348, 42349, 42350, 42351, 42353, 42356, 42357, 42360, 42361, 42362, 42363, 42364, 42365, 42366, 42371, 42373, 42375, 42376, 42378, 42379, 42387, 42390, 42395, 42398, 42400, 42402, 42404, 42405, 42406, 42408, 42412, 42413, 42417, 42418, 42420, 42422, 42423, 42424, 42425, 42426, 42427, 42428, 42429, 42432, 42436, 42438, 42439, 42440, 42442, 42443, 42449, 42451, 42452, 42454, 42455, 42456, 42458, 42459, 42462, 42466, 42469, 42474, 42475, 42650, 42652, 42653, 42655, 42659, 42664, 42667, 42670, 42672, 42687, 42689, 42691, 42695, 42702, 42704, 42714, 42718, 42720, 42721, 42724, 42727, 42734, 42735, 42743, 42745, 42746, 42747, 42749, 42751, 42752, 42756, 42758, 42759, 42766, 42768, 42770, 42772, 42773, 42774, 42776, 42779, 42781, 42785, 42789, 42791, 42795, 42797, 42803, 42804, 42816, 42817, 42820, 42823, 42829, 42830, 42831, 42833, 42834, 42835, 42837, 42838, 42840, 42841, 42842, 42843, 42844, 42845, 42846, 42850, 42852, 42853, 42854, 42855, 42859, 42861, 42862, 42863, 42864, 42866, 42868, 42869, 42870, 42871, 42872, 42874, 42876, 42878, 42882, 42883, 42884, 42885, 42886, 42888, 42889, 42890, 42891, 42892, 42893, 42895, 42897, 42903, 42904, 42906, 42907, 42908, 42910, 42912, 42914, 42915, 42916, 42917, 42919, 42920, 42922, 42925, 42926, 42927, 42929, 42930, 42933, 42934, 42935, 42936, 42938, 42939, 42941, 42943, 42944, 42945, 42947, 42948, 42949, 42951, 42953, 42954, 42955, 42956, 42959, 42960, 42962, 42963, 42964, 42965, 42966, 42967, 42969, 42970, 42971, 42973, 42974, 42975, 42976, 42977, 42979, 42980, 42982, 42983, 42984, 42985, 42987, 42988, 42989, 42990, 42991, 42994, 42996, 42997, 42998, 43000, 43001, 43002, 43004, 43006, 43009, 43014, 43017, 43020, 43021, 43025, 43026, 43027, 43028, 43030, 43031, 43038, 43043, 43045, 43046, 43050, 43054, 43056, 43057, 43059, 43061, 43062, 43064, 43065, 43066, 43070, 43072, 43075, 43076]\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "FIELDS:\n",
      "\n",
      "Sentiment: 2 failures  2 passes  type ✓  min_length ✗  max_length ✓  allowed_values ✗\n",
      "\n",
      "Sentiment_Polarity: 0 failures  3 passes  type ✓  min ✓  max ✓\n",
      "\n",
      "Sentiment_Subjectivity: 0 failures  4 passes  type ✓  min ✓  max ✓  sign ✓\n",
      "\n",
      "App: 0 failures  4 passes  type ✓  min_length ✓  max_length ✓  max_nulls ✓\n",
      "\n",
      "Translated_Review: 0 failures  3 passes  type ✓  min_length ✓  max_length ✓\n",
      "\n",
      "SUMMARY:\n",
      "\n",
      "Constraints passing: 16\n",
      "Constraints failing: 2\n",
      "                    field  failures  passes  type   min min_length   max  \\\n",
      "0               Sentiment         2       2  True   NaN      False   NaN   \n",
      "1      Sentiment_Polarity         0       3  True  True        NaN  True   \n",
      "2  Sentiment_Subjectivity         0       4  True  True        NaN  True   \n",
      "3                     App         0       4  True   NaN       True   NaN   \n",
      "4       Translated_Review         0       3  True   NaN       True   NaN   \n",
      "\n",
      "  max_length  sign max_nulls allowed_values  \n",
      "0       True   NaN       NaN          False  \n",
      "1        NaN   NaN       NaN            NaN  \n",
      "2        NaN  True       NaN            NaN  \n",
      "3       True   NaN      True            NaN  \n",
      "4       True   NaN       NaN            NaN  \n",
      "Row index with constraint failure:\n",
      "\n",
      "[10, 16, 20, 23, 27, 28, 29, 30, 33, 35, 36, 39, 40, 42, 44, 46, 47, 50, 52, 58, 60, 61, 62, 64, 68, 70, 74, 76, 80, 84, 92, 95, 96, 101, 103, 104, 112, 117, 118, 121, 123, 125, 129, 136, 137, 140, 145, 149, 153, 156, 161, 162, 163, 164, 167, 171, 177, 178, 179, 183, 184, 188, 195, 196, 200, 202, 205, 208, 209, 210, 221, 224, 225, 227, 228, 238, 239, 240, 242, 244, 246, 248, 250, 252, 253, 255, 257, 260, 261, 264, 272, 283, 290, 293, 297, 301, 303, 304, 305, 309, 314, 316, 319, 321, 324, 333, 335, 346, 347, 348, 349, 351, 352, 355, 357, 365, 369, 376, 377, 378, 380, 384, 386, 387, 389, 393, 396, 399, 408, 412, 416, 421, 425, 429, 435, 437, 439, 442, 443, 445, 451, 452, 453, 456, 459, 465, 471, 474, 475, 478, 479, 481, 485, 489, 490, 491, 492, 495, 496, 501, 502, 503, 508, 509, 511, 513, 515, 516, 518, 519, 526, 532, 536, 541, 546, 548, 551, 552, 554, 555, 559, 564, 565, 566, 567, 568, 581, 594, 596, 602, 603, 606, 607, 608, 609, 614, 615, 623, 625, 632, 635, 637, 638, 639, 643, 646, 647, 648, 651, 653, 655, 659, 661, 665, 671, 672, 676, 677, 681, 683, 685, 686, 691, 696, 705, 707, 715, 718, 719, 729, 734, 872, 882, 896, 931, 980, 1020, 1021, 1024, 1030, 1048, 1051, 1065, 1069, 1090, 1098, 1117, 1123, 1132, 1148, 1173, 1201, 1206, 1216, 1234, 1244, 1255, 1263, 1284, 1326, 1330, 1332, 1336, 1338, 1339, 1342, 1343, 1344, 1345, 1349, 1354, 1359, 1363, 1365, 1368, 1373, 1381, 1385, 1387, 1388, 1396, 1406, 1413, 1419, 1422, 1427, 1428, 1433, 1436, 1439, 1446, 1447, 1451, 1452, 1459, 1460, 1461, 1462, 1463, 1465, 1466, 1468, 1472, 1473, 1475, 1478, 1480, 1484, 1487, 1490, 1491, 1492, 1493, 1500, 1501, 1504, 1506, 1513, 1518, 1519, 1521, 1525, 1533, 1537, 1539, 1542, 1545, 1547, 1549, 1557, 1558, 1561, 1566, 1568, 1571, 1574, 1575, 1576, 1577, 1580, 1582, 1583, 1585, 1586, 1590, 1591, 1593, 1599, 1601, 1604, 1606, 1607, 1608, 1609, 1613, 1614, 1617, 1621, 1626, 1627, 1629, 1635, 1641, 1643, 1647, 1650, 1654, 1655, 1657, 1658, 1660, 1665, 1666, 1668, 1672, 1673, 1681, 1682, 1683, 1684, 1685, 1686, 1688, 1689, 1694, 1695, 1702, 1703, 1713, 1718, 1719, 1721, 1724, 1728, 1730, 1732, 1734, 1736, 1742, 1746, 1751, 1753, 1754, 1755, 1757, 1764, 1765, 1766, 1771, 1772, 1783, 1785, 1786, 1789, 1791, 1794, 1799, 1801, 1802, 1809, 1817, 1821, 1831, 1833, 1837, 1838, 1840, 1841, 1845, 1848, 1851, 1854, 1856, 1857, 1873, 1874, 1876, 1879, 1881, 2054, 2074, 2078, 2080, 2110, 2122, 2140, 2144, 2155, 2170, 2176, 2177, 2204, 2208, 2223, 2224, 2227, 2232, 2234, 2247, 2250, 2262, 2268, 2279, 2288, 2289, 2292, 2295, 2296, 2300, 2302, 2303, 2306, 2311, 2312, 2318, 2334, 2337, 2348, 2351, 2352, 2353, 2359, 2364, 2366, 2367, 2371, 2373, 2376, 2377, 2378, 2383, 2393, 2394, 2395, 2397, 2400, 2404, 2411, 2413, 2414, 2420, 2422, 2429, 2430, 2435, 2436, 2442, 2449, 2451, 2452, 2457, 2465, 2468, 2491, 2498, 2504, 2505, 2507, 2513, 2514, 2515, 2518, 2521, 2526, 2531, 2533, 2542, 2546, 2549, 2551, 2556, 2557, 2559, 2561, 2562, 2567, 2568, 2573, 2575, 2578, 2579, 2580, 2586, 2587, 2589, 2591, 2595, 2598, 2600, 2601, 2602, 2606, 2608, 2610, 2613, 2620, 2622, 2624, 2626, 2630, 2632, 2634, 2642, 2643, 2645, 2656, 2662, 2663, 2664, 2665, 2667, 2677, 2683, 2695, 2809, 2814, 2823, 2831, 2837, 2846, 2847, 2854, 2860, 2862, 2863, 2864, 2873, 2879, 2897, 2907, 2910, 2913, 2914, 2918, 2920, 2923, 2924, 2925, 2938, 2941, 2947, 2966, 2975, 2979, 2984, 2986, 2987, 2994, 2995, 2996, 3006, 3012, 3023, 3029, 3033, 3037, 3039, 3047, 3048, 3053, 3054, 3055, 3057, 3059, 3061, 3067, 3068, 3069, 3070, 3074, 3075, 3082, 3085, 3089, 3092, 3102, 3109, 3114, 3117, 3126, 3128, 3133, 3134, 3135, 3145, 3150, 3153, 3155, 3156, 3158, 3160, 3165, 3169, 3174, 3180, 3185, 3186, 3188, 3192, 3206, 3218, 3222, 3227, 3233, 3334, 3369, 3370, 3374, 3377, 3382, 3383, 3389, 3397, 3401, 3405, 3428, 3432, 3435, 3441, 3442, 3444, 3448, 3451, 3454, 3457, 3460, 3478, 3482, 3489, 3490, 3491, 3494, 3495, 3496, 3500, 3501, 3503, 3526, 3537, 3542, 3546, 3550, 3552, 3558, 3561, 3564, 3565, 3568, 3571, 3572, 3576, 3578, 3586, 3587, 3588, 3592, 3596, 3599, 3604, 3608, 3613, 3615, 3617, 3624, 3625, 3626, 3628, 3629, 3632, 3635, 3641, 3644, 3647, 3648, 3649, 3652, 3658, 3659, 3660, 3664, 3670, 3672, 3673, 3674, 3685, 3698, 3704, 3710, 3711, 3715, 3717, 3718, 3721, 3722, 3724, 3725, 3727, 3730, 3736, 3742, 3745, 3748, 3752, 3755, 3760, 3761, 3764, 3767, 3769, 3771, 3775, 3778, 3779, 3781, 3793, 3841, 3942, 3946, 3952, 3957, 3962, 3974, 3983, 3984, 3988, 3990, 3993, 3995, 3998, 4006, 4007, 4008, 4010, 4014, 4018, 4028, 4032, 4035, 4041, 4043, 4048, 4058, 4059, 4064, 4068, 4073, 4076, 4083, 4085, 4087, 4088, 4090, 4091, 4097, 4100, 4103, 4105, 4106, 4108, 4109, 4126, 4127, 4129, 4136, 4141, 4143, 4147, 4149, 4150, 4151, 4159, 4163, 4169, 4173, 4176, 4182, 4189, 4193, 4194, 4195, 4200, 4203, 4205, 4207, 4208, 4214, 4216, 4217, 4222, 4224, 4225, 4232, 4233, 4238, 4239, 4242, 4244, 4247, 4260, 4262, 4267, 4268, 4269, 4277, 4282, 4285, 4288, 4289, 4290, 4293, 4294, 4299, 4302, 4304, 4306, 4307, 4309, 4310, 4311, 4312, 4313, 4315, 4320, 4323, 4324, 4325, 4328, 4329, 4330, 4337, 4340, 4344, 4345, 4352, 4354, 4365, 4367, 4368, 4480, 4490, 4493, 4512, 4514, 4524, 4525, 4527, 4528, 4538, 4540, 4548, 4551, 4554, 4574, 4575, 4577, 4587, 4590, 4598, 4599, 4602, 4603, 4605, 4608, 4609, 4610, 4611, 4613, 4616, 4630, 4634, 4640, 4644, 4647, 4650, 4652, 4656, 4671, 4676, 4677, 4679, 4680, 4682, 4686, 4690, 4693, 4695, 4704, 4711, 4714, 4716, 4717, 4723, 4733, 4736, 4743, 4748, 4753, 4758, 4759, 4762, 4763, 4768, 4769, 4771, 4772, 4773, 4775, 4779, 4780, 4782, 4784, 4786, 4787, 4793, 4794, 4799, 4801, 4803, 4804, 4805, 4806, 4822, 4829, 4841, 4842, 4844, 4845, 4851, 4855, 4857, 4860, 4864, 4917, 4930, 4933, 4944, 4966, 4970, 4982, 4987, 4989, 4999, 5000, 5010, 5012, 5015, 5020, 5039, 5040, 5044, 5045, 5047, 5055, 5058, 5063, 5072, 5084, 5092, 5110, 5125, 5131, 5133, 5137, 5139, 5141, 5145, 5147, 5148, 5153, 5157, 5159, 5160, 5163, 5166, 5169, 5170, 5173, 5176, 5179, 5181, 5182, 5186, 5193, 5213, 5217, 5223, 5226, 5227, 5234, 5237, 5241, 5242, 5243, 5246, 5249, 5251, 5255, 5258, 5271, 5273, 5274, 5290, 5291, 5293, 5303, 5309, 5317, 5318, 5320, 5322, 5323, 5326, 5328, 5331, 5343, 5345, 5348, 5366, 5372, 5375, 5376, 5379, 5391, 5397, 5402, 5404, 5407, 5416, 5423, 5426, 5427, 5533, 5539, 5551, 5553, 5559, 5561, 5564, 5567, 5570, 5580, 5582, 5589, 5596, 5602, 5605, 5606, 5607, 5613, 5620, 5621, 5622, 5623, 5625, 5626, 5629, 5630, 5633, 5634, 5636, 5645, 5647, 5652, 5655, 5659, 5661, 5662, 5663, 5665, 5666, 5667, 5668, 5670, 5689, 5697, 5715, 5720, 5722, 5725, 5727, 5728, 5729, 5730, 5731, 5737, 5741, 5743, 5744, 5747, 5748, 5752, 5760, 5767, 5771, 5773, 5775, 5779, 5784, 5786, 5795, 5801, 5804, 5808, 5810, 5812, 5814, 5815, 5833, 5835, 5841, 5842, 5843, 5846, 5849, 5850, 5851, 5857, 5872, 5873, 5875, 5878, 5880, 5881, 5883, 5889, 5890, 5892, 5896, 5909, 5910, 5921, 5927, 6040, 6042, 6060, 6061, 6078, 6082, 6090, 6097, 6098, 6101, 6105, 6108, 6110, 6111, 6112, 6113, 6118, 6121, 6123, 6124, 6125, 6127, 6133, 6137, 6143, 6144, 6147, 6152, 6158, 6163, 6164, 6169, 6183, 6189, 6194, 6196, 6197, 6198, 6201, 6203, 6206, 6207, 6210, 6211, 6213, 6214, 6215, 6222, 6226, 6227, 6229, 6231, 6236, 6242, 6245, 6249, 6252, 6259, 6260, 6262, 6264, 6276, 6294, 6296, 6300, 6302, 6304, 6308, 6310, 6313, 6322, 6323, 6327, 6328, 6330, 6331, 6335, 6337, 6339, 6340, 6342, 6347, 6350, 6354, 6359, 6368, 6373, 6376, 6379, 6385, 6386, 6387, 6388, 6391, 6393, 6395, 6396, 6400, 6403, 6405, 6408, 6411, 6412, 6413, 6416, 6417, 6424, 6430, 6431, 6434, 6446, 6452, 6453, 6455, 6456, 6457, 6464, 6470, 6480, 6486, 6497, 6501, 6506, 6645, 6646, 6650, 6656, 6658, 6663, 6673, 6676, 6683, 6688, 6704, 6709, 6712, 6714, 6724, 6726, 6742, 6746, 6754, 6758, 6760, 6762, 6763, 6767, 6768, 6771, 6779, 6780, 6795, 6805, 6807, 6808, 6810, 6817, 6818, 6820, 6821, 6823, 6844, 6848, 6853, 6863, 6872, 6877, 6879, 6882, 6892, 6895, 6897, 6908, 6912, 6919, 6920, 6923, 6926, 6934, 6936, 6940, 6942, 6943, 6944, 6948, 6950, 6953, 6955, 6958, 6964, 6966, 6967, 6974, 6980, 6989, 6997, 7008, 7012, 7013, 7014, 7016, 7019, 7023, 7024, 7027, 7028, 7033, 7034, 7037, 7038, 7040, 7044, 7046, 7051, 7052, 7057, 7060, 7066, 7069, 7073, 7074, 7076, 7077, 7079, 7080, 7084, 7093, 7094, 7099, 7102, 7103, 7104, 7108, 7111, 7119, 7124, 7128, 7132, 7136, 7137, 7142, 7144, 7148, 7152, 7156, 7159, 7167, 7172, 7182, 7184, 7186, 7189, 7194, 7195, 7196, 7306, 7307, 7309, 7312, 7320, 7321, 7322, 7333, 7335, 7336, 7339, 7340, 7342, 7348, 7351, 7353, 7355, 7362, 7363, 7372, 7374, 7378, 7382, 7393, 7399, 7401, 7403, 7406, 7408, 7414, 7422, 7423, 7425, 7426, 7428, 7429, 7431, 7433, 7440, 7441, 7444, 7446, 7451, 7456, 7458, 7461, 7465, 7468, 7473, 7479, 7482, 7485, 7489, 7491, 7492, 7493, 7501, 7507, 7510, 7511, 7522, 7526, 7528, 7530, 7536, 7540, 7548, 7550, 7558, 7566, 7567, 7569, 7570, 7571, 7573, 7576, 7579, 7581, 7582, 7586, 7588, 7589, 7590, 7592, 7597, 7603, 7613, 7614, 7617, 7618, 7619, 7622, 7624, 7625, 7629, 7630, 7631, 7632, 7637, 7640, 7643, 7645, 7646, 7651, 7652, 7654, 7656, 7662, 7665, 7670, 7673, 7675, 7685, 7689, 7691, 7692, 7693, 7700, 7704, 7707, 7721, 7732, 7733, 7834, 7846, 7855, 7860, 7861, 7862, 7865, 7866, 7869, 7882, 7885, 7888, 7891, 7895, 7897, 7901, 7905, 7909, 7911, 7915, 7916, 7917, 7928, 7935, 7937, 7940, 7942, 7944, 7946, 7953, 7954, 7956, 7966, 7970, 7971, 7972, 7973, 7977, 7979, 7984, 7991, 7995, 7996, 8006, 8008, 8009, 8015, 8020, 8021, 8022, 8026, 8027, 8028, 8034, 8059, 8061, 8065, 8070, 8072, 8073, 8074, 8076, 8078, 8080, 8081, 8100, 8103, 8106, 8123, 8125, 8127, 8130, 8138, 8142, 8147, 8150, 8154, 8155, 8157, 8159, 8161, 8163, 8167, 8169, 8170, 8175, 8177, 8180, 8185, 8190, 8192, 8196, 8201, 8202, 8205, 8208, 8210, 8235, 8251, 8256, 8259, 8328, 8335, 8337, 8343, 8348, 8354, 8358, 8360, 8362, 8363, 8367, 8368, 8369, 8374, 8378, 8380, 8381, 8388, 8392, 8393, 8399, 8403, 8405, 8406, 8407, 8425, 8428, 8431, 8437, 8450, 8454, 8456, 8466, 8468, 8469, 8470, 8472, 8478, 8481, 8483, 8490, 8495, 8497, 8504, 8511, 8518, 8522, 8529, 8535, 8537, 8545, 8549, 8553, 8559, 8563, 8565, 8570, 8572, 8574, 8575, 8578, 8584, 8586, 8592, 8596, 8598, 8599, 8610, 8611, 8612, 8617, 8623, 8625, 8634, 8650, 8651, 8654, 8659, 8667, 8671, 8672, 8681, 8683, 8684, 8689, 8692, 8694, 8696, 8701, 8704, 8718, 8734, 8737, 8741, 8744, 8749, 8753, 8755, 8756, 8758, 8766, 8768, 8809, 8848, 8851, 8854, 8872, 8875, 8876, 8878, 8884, 8885, 8889, 8895, 8898, 8909, 8912, 8913, 8918, 8919, 8920, 8930, 8937, 8944, 8945, 8946, 8947, 8952, 8957, 8961, 8966, 8968, 8972, 8974, 8975, 8979, 8989, 8993, 8998, 9001, 9002, 9003, 9011, 9015, 9020, 9021, 9028, 9032, 9040, 9048, 9050, 9058, 9061, 9063, 9064, 9067, 9068, 9070, 9079, 9085, 9093, 9096, 9098, 9108, 9109, 9110, 9117, 9127, 9128, 9130, 9139, 9141, 9143, 9145, 9156, 9158, 9165, 9166, 9169, 9173, 9179, 9188, 9189, 9197, 9205, 9209, 9215, 9221, 9224, 9227, 9232, 9234, 9245, 9262, 9265, 9270, 9272, 9273, 9279, 9282, 9283, 9285, 9286, 9287, 9289, 9292, 9294, 9305, 9310, 9313, 9315, 9316, 9319, 9321, 9322, 9326, 9328, 9329, 9333, 9346, 9349, 9354, 9355, 9358, 9366, 9368, 9371, 9372, 9373, 9374, 9375, 9386, 9388, 9394, 9396, 9397, 9398, 9402, 9403, 9405, 9409, 9411, 9412, 9419, 9421, 9423, 9428, 9435, 9436, 9439, 9440, 9442, 9449, 9453, 9454, 9456, 9458, 9461, 9464, 9465, 9473, 9478, 9479, 9480, 9485, 9487, 9490, 9493, 9496, 9505, 9507, 9516, 9520, 9522, 9527, 9529, 9531, 9532, 9533, 9534, 9539, 9546, 9561, 9583, 9592, 9596, 9608, 9615, 9616, 9621, 9622, 9631, 9647, 9651, 9656, 9660, 9661, 9667, 9676, 9677, 9680, 9683, 9686, 9687, 9691, 9693, 9694, 9698, 9703, 9711, 9712, 9714, 9720, 9721, 9723, 9729, 9730, 9732, 9736, 9739, 9740, 9754, 9756, 9757, 9764, 9774, 9775, 9780, 9785, 9792, 9796, 9805, 9806, 9807, 9809, 9810, 9814, 9820, 9824, 9828, 9835, 9837, 9843, 9846, 9848, 9852, 9860, 9861, 9864, 9867, 9868, 9887, 9889, 9890, 9894, 9895, 9900, 9905, 9908, 9909, 9910, 9913, 9914, 9915, 9917, 9918, 9919, 9921, 9923, 9925, 9930, 9939, 9940, 9950, 9988, 10007, 10026, 10035, 10038, 10040, 10043, 10048, 10066, 10082, 10084, 10086, 10093, 10094, 10097, 10099, 10103, 10105, 10107, 10108, 10115, 10116, 10120, 10122, 10123, 10126, 10133, 10139, 10146, 10147, 10152, 10155, 10158, 10174, 10188, 10191, 10192, 10193, 10196, 10201, 10203, 10205, 10206, 10217, 10222, 10246, 10253, 10256, 10258, 10262, 10264, 10266, 10275, 10276, 10286, 10287, 10288, 10293, 10295, 10298, 10300, 10310, 10317, 10334, 10335, 10338, 10340, 10343, 10347, 10353, 10356, 10357, 10359, 10361, 10363, 10366, 10371, 10379, 10387, 10405, 10409, 10410, 10411, 10412, 10414, 10416, 10422, 10423, 10424, 10427, 10428, 10430, 10431, 10435, 10439, 10446, 10452, 10457, 10458, 10460, 10461, 10462, 10463, 10465, 10466, 10474, 10475, 10476, 10477, 10478, 10488, 10491, 10501, 10504, 10506, 10514, 10518, 10521, 10523, 10527, 10533, 10535, 10538, 10539, 10541, 10548, 10549, 10550, 10552, 10553, 10560, 10561, 10566, 10567, 10568, 10569, 10571, 10578, 10583, 10588, 10590, 10593, 10600, 10601, 10602, 10604, 10607, 10609, 10610, 10612, 10613, 10615, 10616, 10617, 10621, 10631, 10632, 10634, 10641, 10642, 10644, 10648, 10650, 10652, 10655, 10659, 10663, 10665, 10670, 10672, 10678, 10681, 10688, 10689, 10690, 10691, 10703, 10716, 10723, 10725, 10727, 10740, 10742, 10743, 10744, 10746, 10748, 10754, 10758, 10759, 10761, 10766, 10767, 10768, 10769, 10770, 10771, 10773, 10780, 10783, 10791, 10799, 10802, 10803, 10808, 10810, 10812, 10819, 10822, 10824, 10825, 10829, 10844, 10848, 10849, 10853, 10856, 10864, 10871, 10884, 10886, 10887, 10889, 10890, 10892, 10894, 10895, 10897, 10898, 10899, 10900, 10904, 10907, 10909, 10916, 10917, 10924, 10927, 10928, 10931, 10939, 10941, 10948, 10951, 10953, 10954, 10955, 10957, 10958, 10960, 10961, 10962, 10975, 10985, 10986, 10992, 11008, 11025, 11029, 11036, 11039, 11059, 11083, 11084, 11085, 11090, 11096, 11098, 11100, 11107, 11117, 11130, 11133, 11137, 11149, 11156, 11164, 11166, 11177, 11180, 11182, 11199, 11202, 11210, 11212, 11221, 11222, 11223, 11230, 11237, 11240, 11241, 11243, 11245, 11249, 11250, 11259, 11260, 11266, 11267, 11268, 11269, 11270, 11272, 11278, 11280, 11282, 11291, 11296, 11298, 11300, 11302, 11303, 11313, 11317, 11319, 11326, 11328, 11331, 11337, 11338, 11339, 11340, 11341, 11346, 11347, 11351, 11354, 11355, 11359, 11360, 11365, 11370, 11381, 11388, 11389, 11392, 11399, 11405, 11417, 11420, 11424, 11428, 11429, 11430, 11431, 11439, 11444, 11446, 11449, 11457, 11460, 11470, 11473, 11477, 11479, 11481, 11482, 11485, 11489, 11490, 11499, 11501, 11503, 11507, 11512, 11519, 11523, 11527, 11530, 11535, 11536, 11538, 11545, 11546, 11566, 11655, 11661, 11664, 11672, 11676, 11684, 11686, 11688, 11689, 11691, 11692, 11697, 11701, 11703, 11709, 11711, 11715, 11720, 11725, 11729, 11730, 11739, 11740, 11743, 11750, 11751, 11758, 11759, 11766, 11768, 11769, 11771, 11775, 11776, 11785, 11786, 11789, 11792, 11794, 11797, 11807, 11811, 11817, 11818, 11819, 11824, 11826, 11828, 11829, 11834, 11838, 11839, 11855, 11856, 11859, 11860, 11861, 11873, 11878, 11882, 11884, 11886, 11888, 11889, 11891, 11893, 11894, 11905, 11908, 11912, 11916, 11921, 11925, 11930, 11937, 11940, 11961, 11962, 11964, 11973, 11983, 11984, 11989, 11992, 11994, 11995, 11996, 12000, 12001, 12003, 12004, 12006, 12007, 12008, 12014, 12015, 12017, 12019, 12024, 12025, 12028, 12029, 12033, 12037, 12043, 12044, 12046, 12050, 12055, 12062, 12063, 12070, 12071, 12072, 12075, 12080, 12081, 12087, 12088, 12090, 12093, 12094, 12095, 12105, 12106, 12109, 12110, 12120, 12124, 12126, 12128, 12140, 12147, 12148, 12149, 12151, 12152, 12154, 12155, 12158, 12159, 12160, 12161, 12163, 12164, 12175, 12182, 12188, 12193, 12197, 12198, 12200, 12201, 12206, 12208, 12209, 12217, 12218, 12219, 12222, 12223, 12224, 12228, 12231, 12233, 12234, 12239, 12244, 12248, 12249, 12250, 12252, 12257, 12259, 12266, 12267, 12269, 12276, 12284, 12285, 12287, 12290, 12292, 12301, 12310, 12312, 12315, 12318, 12321, 12322, 12324, 12326, 12327, 12331, 12333, 12340, 12348, 12349, 12350, 12352, 12354, 12360, 12361, 12362, 12369, 12371, 12379, 12381, 12383, 12384, 12386, 12389, 12391, 12396, 12398, 12402, 12404, 12405, 12406, 12407, 12409, 12411, 12412, 12415, 12425, 12428, 12437, 12460, 12466, 12468, 12475, 12476, 12479, 12485, 12488, 12489, 12492, 12497, 12504, 12506, 12507, 12529, 12531, 12533, 12536, 12548, 12563, 12565, 12578, 12579, 12580, 12591, 12594, 12595, 12598, 12601, 12602, 12612, 12617, 12618, 12621, 12623, 12625, 12627, 12636, 12642, 12643, 12644, 12647, 12652, 12654, 12657, 12659, 12662, 12664, 12665, 12668, 12675, 12679, 12680, 12684, 12686, 12687, 12693, 12702, 12703, 12706, 12710, 12713, 12714, 12715, 12718, 12722, 12725, 12726, 12727, 12736, 12738, 12740, 12742, 12744, 12746, 12748, 12750, 12756, 12758, 12759, 12764, 12766, 12769, 12772, 12773, 12778, 12779, 12780, 12783, 12786, 12791, 12799, 12800, 12805, 12807, 12808, 12817, 12821, 12823, 12825, 12828, 12830, 12833, 12839, 12841, 12842, 12846, 12849, 12850, 12861, 12863, 12864, 12865, 12866, 12868, 12869, 12870, 12872, 12873, 12874, 12876, 12877, 12880, 12882, 12884, 12886, 12892, 12895, 12898, 12900, 12903, 12904, 12908, 12909, 12910, 12912, 12914, 12916, 12918, 12923, 12925, 12927, 12929, 12939, 12943, 12944, 12945, 12946, 12952, 12954, 12955, 12964, 12968, 12973, 12982, 12983, 12988, 12990, 12991, 12992, 12994, 13000, 13001, 13002, 13003, 13005, 13007, 13010, 13011, 13012, 13014, 13021, 13023, 13035, 13037, 13045, 13048, 13049, 13052, 13063, 13065, 13067, 13068, 13069, 13074, 13076, 13080, 13086, 13087, 13090, 13092, 13093, 13097, 13102, 13104, 13105, 13108, 13111, 13115, 13116, 13117, 13121, 13123, 13124, 13134, 13137, 13147, 13149, 13150, 13151, 13152, 13153, 13154, 13158, 13161, 13162, 13164, 13168, 13169, 13170, 13175, 13181, 13184, 13185, 13187, 13189, 13190, 13193, 13194, 13197, 13207, 13208, 13209, 13212, 13215, 13218, 13219, 13220, 13231, 13232, 13238, 13242, 13245, 13246, 13247, 13252, 13253, 13255, 13259, 13267, 13268, 13269, 13270, 13274, 13290, 13292, 13297, 13305, 13307, 13311, 13315, 13320, 13322, 13324, 13326, 13328, 13333, 13335, 13337, 13341, 13346, 13347, 13350, 13353, 13355, 13372, 13373, 13375, 13377, 13380, 13383, 13384, 13385, 13386, 13387, 13390, 13391, 13395, 13397, 13399, 13401, 13402, 13404, 13405, 13420, 13422, 13426, 13427, 13435, 13437, 13438, 13441, 13442, 13444, 13446, 13447, 13448, 13449, 13458, 13461, 13463, 13471, 13473, 13476, 13480, 13481, 13483, 13487, 13488, 13494, 13496, 13497, 13501, 13508, 13510, 13805, 13818, 14262, 14301, 14305, 14312, 14314, 14317, 14318, 14321, 14322, 14323, 14334, 14335, 14339, 14341, 14343, 14350, 14354, 14359, 14361, 14363, 14369, 14372, 14378, 14381, 14388, 14395, 14397, 14399, 14401, 14402, 14403, 14408, 14411, 14413, 14420, 14421, 14423, 14430, 14432, 14436, 14437, 14438, 14441, 14443, 14444, 14446, 14448, 14449, 14453, 14454, 14458, 14459, 14464, 14470, 14471, 14477, 14479, 14484, 14490, 14491, 14492, 14496, 14497, 14499, 14500, 14503, 14505, 14507, 14511, 14514, 14515, 14519, 14524, 14525, 14526, 14530, 14533, 14534, 14537, 14539, 14546, 14548, 14553, 14558, 14561, 14562, 14564, 14565, 14567, 14568, 14573, 14576, 14583, 14584, 14587, 14591, 14594, 14595, 14596, 14597, 14598, 14600, 14603, 14606, 14607, 14609, 14610, 14612, 14614, 14616, 14617, 14618, 14620, 14622, 14623, 14627, 14631, 14636, 14638, 14641, 14642, 14644, 14645, 14650, 14651, 14655, 14660, 14663, 14667, 14671, 14672, 14680, 14687, 14692, 14693, 14694, 14699, 14700, 14701, 14706, 14709, 14710, 14712, 14717, 14719, 14722, 14729, 14730, 14734, 14736, 14737, 14742, 14752, 14753, 14755, 14756, 14757, 14758, 14768, 14773, 14777, 14780, 14783, 14785, 14786, 14789, 14790, 14792, 14799, 14802, 14809, 14810, 14819, 14821, 14822, 14823, 14825, 14830, 14831, 14838, 14843, 14845, 14847, 14857, 14864, 14865, 14869, 14872, 14875, 14876, 14878, 14879, 14881, 14882, 14885, 14888, 14893, 14894, 14899, 14901, 14903, 14905, 14910, 14921, 14924, 14927, 14928, 14930, 14931, 14933, 14935, 14936, 14941, 14944, 14949, 14950, 14951, 14952, 14954, 14957, 14959, 14970, 14971, 14972, 14979, 14981, 14988, 14992, 14993, 14996, 15002, 15005, 15010, 15011, 15014, 15022, 15027, 15029, 15031, 15032, 15034, 15036, 15041, 15045, 15047, 15051, 15052, 15054, 15057, 15060, 15064, 15069, 15075, 15084, 15885, 15886, 15887, 15890, 15892, 15901, 15902, 15903, 15906, 15915, 15916, 15926, 15928, 15930, 15931, 15933, 15935, 15936, 15938, 15939, 15942, 15946, 15947, 15951, 15952, 15953, 15957, 15960, 15971, 15973, 15976, 15985, 15990, 15991, 15992, 15994, 16014, 16015, 16018, 16024, 16028, 16030, 16036, 16038, 16039, 16042, 16048, 16054, 16062, 16065, 16067, 16070, 16079, 16091, 16094, 16099, 16107, 16108, 16111, 16116, 16118, 16119, 16120, 16122, 16126, 16129, 16134, 16135, 16137, 16140, 16146, 16147, 16154, 16155, 16160, 16164, 16165, 16166, 16173, 16174, 16176, 16178, 16180, 16183, 16188, 16191, 16193, 16194, 16203, 16204, 16211, 16213, 16216, 16220, 16222, 16236, 16237, 16238, 16239, 16241, 16247, 16249, 16250, 16251, 16252, 16255, 16257, 16259, 16263, 16265, 16268, 16271, 16280, 16284, 16285, 16286, 16288, 16289, 16296, 16299, 16303, 16308, 16309, 16310, 16311, 16314, 16315, 16316, 16319, 16322, 16323, 16325, 16326, 16328, 16332, 16333, 16343, 16353, 16355, 16356, 16364, 16366, 16372, 16377, 16378, 16396, 16398, 16405, 16408, 16413, 16417, 16419, 16426, 16428, 16430, 16433, 16445, 16448, 16451, 16454, 16463, 16469, 16473, 16474, 16476, 16479, 16482, 16487, 16494, 16495, 16496, 16497, 16504, 16506, 16509, 16519, 16520, 16523, 16527, 16531, 16532, 16534, 16538, 16540, 16548, 16549, 16551, 16555, 16716, 16719, 16723, 16725, 16726, 16727, 16732, 16734, 16735, 16736, 16740, 16741, 16742, 16743, 16744, 16751, 16754, 16759, 16760, 16765, 16766, 16767, 16768, 16769, 16782, 16786, 16787, 16789, 16792, 16794, 16797, 16798, 16800, 16805, 16809, 16810, 16811, 16815, 16818, 16827, 16828, 16832, 16833, 16836, 16837, 16841, 16842, 16845, 16847, 16848, 16852, 16858, 16860, 16861, 16864, 16865, 16866, 16873, 16878, 16881, 16884, 16890, 16893, 16894, 16898, 16902, 16912, 16913, 16916, 16926, 16927, 16931, 16933, 16936, 16942, 16945, 16947, 16948, 16950, 16952, 16954, 16960, 16961, 16966, 16970, 16971, 16972, 16973, 16974, 16976, 16981, 16982, 16985, 16988, 16991, 16992, 16998, 16999, 17000, 17006, 17007, 17009, 17012, 17013, 17014, 17017, 17018, 17023, 17025, 17026, 17027, 17029, 17034, 17037, 17038, 17041, 17043, 17046, 17054, 17055, 17061, 17062, 17064, 17067, 17070, 17071, 17078, 17084, 17086, 17087, 17091, 17092, 17093, 17094, 17100, 17109, 17112, 17113, 17115, 17116, 17120, 17127, 17130, 17133, 17136, 17149, 17151, 17167, 17173, 17178, 17180, 17186, 17190, 17194, 17197, 17198, 17199, 17200, 17205, 17210, 17211, 17217, 17220, 17231, 17232, 17233, 17237, 17239, 17242, 17248, 17257, 17263, 17266, 17268, 17269, 17270, 17275, 17277, 17278, 17279, 17290, 17291, 17293, 17299, 17301, 17302, 17304, 17314, 17315, 17318, 17319, 17324, 17327, 17331, 17334, 17335, 17336, 17345, 17350, 17354, 17355, 17357, 17363, 17364, 17366, 17370, 17371, 17375, 17378, 17379, 17390, 17391, 17393, 17395, 17400, 17401, 17402, 17407, 17408, 17412, 17414, 17415, 17418, 17419, 17421, 17422, 17425, 17437, 17438, 17439, 17447, 17449, 17450, 17454, 17456, 17459, 17460, 17461, 17464, 17469, 17470, 17471, 17473, 17475, 17477, 17481, 17482, 17485, 17486, 17489, 17490, 17492, 17495, 17496, 17498, 17499, 17501, 17504, 17505, 17508, 17509, 17511, 17513, 17514, 17516, 17518, 17520, 17521, 17528, 17530, 17531, 17532, 17533, 17535, 17536, 17540, 17543, 17544, 17547, 17548, 17552, 17553, 17718, 17724, 17747, 17750, 17751, 17773, 17777, 17778, 17787, 17788, 17800, 17801, 17807, 17813, 17821, 17839, 17840, 17856, 17883, 17894, 17895, 17906, 17909, 17912, 17918, 17919, 17922, 17926, 17927, 17931, 17937, 17939, 17943, 17944, 17946, 17950, 17954, 17958, 17962, 17963, 17968, 17970, 17976, 17979, 17980, 17984, 17994, 17995, 17998, 17999, 18000, 18005, 18007, 18029, 18036, 18044, 18050, 18054, 18058, 18062, 18068, 18071, 18073, 18081, 18084, 18089, 18090, 18094, 18101, 18110, 18115, 18117, 18123, 18126, 18132, 18144, 18145, 18151, 18155, 18156, 18163, 18195, 18199, 18214, 18219, 18222, 18228, 18230, 18239, 18252, 18255, 18267, 18341, 18346, 18354, 18366, 18375, 18387, 18394, 18403, 18405, 18408, 18411, 18412, 18414, 18421, 18431, 18435, 18439, 18443, 18446, 18448, 18450, 18452, 18458, 18460, 18464, 18467, 18471, 18474, 18481, 18485, 18486, 18487, 18488, 18491, 18492, 18495, 18504, 18505, 18506, 18511, 18513, 18528, 18530, 18545, 18547, 18548, 18550, 18554, 18556, 18558, 18559, 18560, 18562, 18568, 18572, 18573, 18574, 18577, 18582, 18584, 18597, 18601, 18608, 18614, 18615, 18616, 18621, 18622, 18629, 18633, 18636, 18638, 18639, 18640, 18645, 18648, 18654, 18657, 18658, 18659, 18671, 18677, 18689, 18798, 18807, 18824, 18825, 18831, 18837, 18840, 18846, 18852, 18853, 18856, 18859, 18863, 18865, 18873, 18875, 18880, 18882, 18885, 18886, 18898, 18909, 18916, 18917, 18920, 18922, 18926, 18928, 18934, 18936, 18939, 18944, 18945, 18947, 18950, 18953, 18954, 18956, 18960, 18962, 18966, 18968, 18969, 18974, 18975, 18977, 18978, 18979, 18983, 18985, 18988, 18989, 18995, 18996, 19001, 19013, 19014, 19015, 19018, 19019, 19023, 19025, 19032, 19034, 19040, 19044, 19046, 19047, 19048, 19051, 19052, 19054, 19059, 19060, 19063, 19068, 19073, 19076, 19078, 19081, 19085, 19086, 19088, 19095, 19098, 19102, 19104, 19108, 19114, 19116, 19119, 19121, 19122, 19130, 19138, 19142, 19144, 19146, 19151, 19152, 19161, 19164, 19170, 19172, 19176, 19178, 19179, 19184, 19186, 19187, 19188, 19191, 19193, 19194, 19198, 19202, 19203, 19207, 19209, 19213, 19214, 19216, 19220, 19225, 19233, 19236, 19241, 19242, 19245, 19251, 19252, 19253, 19254, 19256, 19258, 19259, 19272, 19281, 19287, 19289, 19291, 19292, 19298, 19299, 19304, 19312, 19327, 19463, 19474, 19483, 19489, 19493, 19494, 19512, 19526, 19538, 19541, 19545, 19552, 19553, 19555, 19565, 19574, 19583, 19587, 19589, 19590, 19593, 19597, 19606, 19616, 19618, 19622, 19640, 19645, 19653, 19666, 19668, 19677, 19678, 19679, 19683, 19684, 19687, 19688, 19689, 19691, 19692, 19696, 19698, 19704, 19705, 19714, 19716, 19719, 19723, 19726, 19732, 19741, 19748, 19750, 19755, 19756, 19762, 19767, 19774, 19777, 19782, 19786, 19790, 19794, 19797, 19801, 19803, 19804, 19809, 19817, 19823, 19832, 19835, 19840, 19844, 19851, 19863, 19867, 19873, 19875, 19878, 19898, 19901, 19903, 19908, 19910, 19911, 19917, 20080, 20085, 20097, 20099, 20102, 20120, 20127, 20132, 20134, 20136, 20140, 20142, 20143, 20151, 20157, 20158, 20166, 20172, 20173, 20177, 20182, 20184, 20185, 20186, 20187, 20188, 20193, 20194, 20196, 20199, 20200, 20203, 20205, 20206, 20207, 20210, 20213, 20214, 20215, 20217, 20218, 20220, 20226, 20232, 20236, 20241, 20242, 20243, 20250, 20258, 20263, 20264, 20266, 20267, 20269, 20277, 20278, 20279, 20281, 20290, 20291, 20292, 20295, 20300, 20302, 20303, 20307, 20312, 20314, 20316, 20321, 20323, 20328, 20331, 20340, 20342, 20343, 20348, 20358, 20361, 20364, 20369, 20370, 20372, 20373, 20376, 20379, 20383, 20387, 20388, 20393, 20394, 20397, 20399, 20401, 20405, 20406, 20413, 20414, 20421, 20422, 20423, 20425, 20427, 20432, 20435, 20436, 20437, 20441, 20442, 20443, 20444, 20448, 20450, 20453, 20457, 20461, 20467, 20469, 20470, 20471, 20474, 20479, 20482, 20486, 20491, 20493, 20494, 20501, 20502, 20503, 20504, 20505, 20506, 20510, 20518, 20522, 20529, 20530, 20538, 20542, 20543, 20546, 20548, 20550, 20555, 20557, 20560, 20565, 20570, 20576, 20578, 20586, 20587, 20588, 20589, 20590, 20595, 20596, 20600, 20603, 20604, 20610, 20616, 20620, 20624, 20628, 20631, 20636, 20638, 20639, 20850, 20919, 20972, 20998, 21198]\n",
      "Consistency checking done -- CPU time: 0.13129496574401855 seconds\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.372401\n",
       "Sentiment_Polarity        0.040811\n",
       "Sentiment_Subjectivity   -0.005926\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818172</td>\n",
       "      <td>0.855967</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>4282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.516755</td>\n",
       "      <td>4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "23       1.0            0.818172                0.855967       4\n",
       "27       1.0            0.955556                0.907407       5\n",
       "...      ...                 ...                     ...     ...\n",
       "20850    1.0            0.388889                0.000000    4281\n",
       "20919    1.0            0.962963                0.790123    4282\n",
       "20972    1.0            0.148148                0.516755    4283\n",
       "20998    1.0            0.388889                0.000000    4284\n",
       "21198    1.0            0.388889                0.000000    4285\n",
       "\n",
       "[4285 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.746\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0414\n",
      "Time:                        11:43:08   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16672   BIC:                         4.111e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3724      0.018     75.599      0.000       1.337       1.408\n",
      "Sentiment_Polarity         0.0408      0.029      1.429      0.153      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0059      0.019     -0.310      0.757      -0.043       0.032\n",
      "New_ID                  3.278e-06   1.33e-06      2.457      0.014    6.63e-07    5.89e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4396.236   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.242\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                     4.87e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.87e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7085140234413241\n",
      "Regression done -- CPU time: 0.039437055587768555 seconds\n",
      "End Pipeline CPU time: 0.17095685005187988 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> ED -> LOF -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Patterns:\n",
      "         col  num        pattern\n",
      "0        App    0  '^[A-Za-z]+$'\n",
      "1  Sentiment    0    '^[1-2]+$^'\n",
      "\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Indexes of rows to be removed: []\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "Indexes of rows to be removed: [0, 1, 3, 4, 5, 6, 39078, 8, 9, 39079, 11, 12, 13, 14, 17, 18, 19, 21, 22, 24, 25, 26, 31, 32, 34, 37, 38, 41, 43, 45, 48, 49, 51, 53, 54, 55, 56, 57, 59, 63, 65, 66, 67, 69, 71, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 97, 98, 99, 100, 105, 106, 108, 109, 110, 111, 32877, 113, 114, 116, 119, 120, 122, 124, 126, 127, 128, 130, 131, 132, 133, 134, 135, 138, 139, 141, 142, 143, 144, 32910, 146, 147, 148, 32914, 150, 151, 152, 32916, 154, 155, 39108, 157, 158, 159, 160, 165, 166, 168, 169, 170, 39111, 172, 173, 174, 175, 176, 39112, 180, 181, 182, 185, 186, 187, 39114, 189, 190, 191, 192, 193, 194, 32957, 39115, 197, 198, 199, 32968, 201, 39116, 203, 204, 206, 207, 39119, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 32987, 222, 223, 32991, 226, 229, 230, 231, 232, 233, 234, 235, 236, 237, 39124, 39125, 241, 243, 245, 247, 33015, 249, 33018, 251, 254, 39128, 256, 258, 259, 33028, 262, 263, 265, 266, 267, 39130, 269, 270, 271, 39131, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 33050, 284, 285, 286, 287, 288, 289, 33057, 291, 292, 294, 295, 296, 33062, 298, 299, 300, 302, 306, 307, 308, 33074, 310, 311, 312, 313, 315, 39140, 317, 318, 320, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 33099, 334, 39142, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 33112, 350, 353, 354, 356, 39148, 358, 359, 360, 361, 363, 364, 366, 367, 370, 371, 372, 373, 374, 375, 379, 381, 382, 383, 385, 388, 390, 391, 392, 394, 395, 397, 398, 400, 401, 402, 403, 404, 406, 410, 411, 413, 415, 39160, 417, 419, 420, 33187, 422, 423, 424, 39161, 428, 430, 431, 432, 433, 434, 33202, 436, 440, 441, 39165, 444, 446, 447, 448, 449, 450, 454, 455, 457, 458, 460, 461, 462, 463, 464, 33228, 466, 467, 468, 469, 470, 33230, 472, 473, 476, 477, 33244, 480, 482, 483, 484, 33252, 486, 487, 488, 33258, 493, 494, 497, 498, 499, 500, 33271, 504, 505, 506, 507, 33273, 510, 512, 514, 517, 520, 521, 522, 523, 524, 525, 33288, 527, 528, 529, 530, 531, 533, 534, 535, 33301, 537, 538, 540, 542, 543, 544, 545, 39185, 547, 39186, 549, 550, 553, 556, 557, 560, 561, 562, 563, 33328, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 39192, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 33362, 595, 39195, 597, 598, 599, 39196, 601, 604, 605, 39198, 33377, 610, 611, 612, 613, 33382, 616, 617, 618, 619, 620, 621, 622, 33386, 624, 39200, 626, 627, 39202, 629, 630, 631, 633, 634, 33403, 636, 39204, 640, 641, 642, 644, 645, 33416, 649, 650, 652, 654, 656, 657, 658, 660, 662, 663, 664, 39209, 666, 667, 668, 669, 670, 39210, 673, 674, 675, 33445, 678, 679, 680, 682, 684, 687, 688, 689, 690, 33456, 692, 693, 695, 697, 698, 699, 33465, 701, 33467, 706, 708, 709, 710, 33478, 712, 33483, 717, 33486, 720, 725, 726, 727, 730, 33502, 39228, 39230, 39231, 33550, 39233, 33562, 39235, 33564, 33565, 33567, 39236, 33570, 33571, 33572, 33573, 33576, 39238, 33578, 33579, 33580, 33581, 33583, 33584, 33585, 39240, 33588, 33590, 33592, 33593, 33595, 33596, 33597, 33599, 33600, 33601, 33602, 33603, 39243, 33606, 33607, 33608, 33609, 33610, 33612, 33613, 33614, 33615, 33616, 33617, 33618, 33620, 33621, 33622, 33624, 33625, 33627, 33628, 33630, 33633, 33634, 33635, 33638, 33639, 33641, 33642, 33644, 877, 33648, 33649, 33650, 33651, 33652, 33653, 33654, 33655, 888, 33657, 890, 33658, 33659, 33660, 894, 33662, 33663, 33664, 33665, 899, 33666, 33667, 33668, 33671, 33672, 905, 33673, 33674, 33675, 909, 33676, 33677, 33678, 33679, 33680, 33681, 33683, 33684, 33685, 33686, 33687, 33690, 923, 33692, 33693, 928, 33696, 33697, 33698, 33699, 33700, 33701, 33704, 33705, 33708, 942, 33710, 33711, 33712, 946, 33713, 948, 33718, 951, 33719, 33721, 954, 33724, 33727, 33728, 33730, 33731, 33732, 33733, 33736, 970, 33739, 972, 33743, 33744, 978, 979, 33748, 981, 982, 33750, 33751, 33752, 33753, 33754, 988, 33755, 33756, 33757, 33758, 993, 33759, 995, 33763, 33764, 33765, 33766, 33768, 33769, 33771, 33772, 33773, 33774, 33775, 1008, 33776, 33777, 33778, 33779, 1013, 33781, 1015, 33782, 33785, 33786, 33788, 33789, 33790, 1023, 33791, 33792, 33793, 33794, 33796, 33798, 33799, 1034, 33803, 33804, 1037, 1038, 1039, 33805, 1041, 33807, 33809, 1044, 33810, 1046, 33812, 33813, 33814, 33815, 33817, 33818, 33819, 33820, 33821, 33823, 1057, 33824, 33825, 1060, 33826, 33828, 1063, 33829, 33831, 1066, 33832, 33833, 33834, 33835, 33836, 33837, 33838, 33840, 33841, 33843, 1077, 33846, 33847, 1080, 33849, 33850, 33851, 33852, 33853, 33854, 33856, 1091, 33861, 33863, 33864, 33865, 33866, 33868, 33869, 33871, 1104, 33873, 33875, 1109, 33878, 33880, 33881, 1114, 39120, 33884, 33885, 33887, 33890, 33892, 33895, 33898, 1131, 33899, 33900, 33901, 33902, 33905, 33907, 33909, 33911, 33913, 33915, 33916, 33918, 33919, 33920, 33921, 1154, 1155, 33922, 1157, 33924, 33927, 1160, 33932, 33933, 33934, 1167, 33935, 33936, 33940, 33941, 33942, 1175, 33943, 1177, 33945, 33947, 33953, 1187, 1188, 33955, 33956, 33957, 33958, 1193, 33960, 33963, 33964, 1197, 33965, 1200, 33968, 33969, 33970, 1204, 33971, 33973, 33974, 1209, 33978, 1215, 33985, 33986, 1221, 33989, 33990, 33991, 1226, 33995, 1228, 33997, 34000, 1233, 1235, 1236, 34003, 34004, 34008, 34009, 34010, 1243, 1252, 1253, 34020, 1256, 1257, 34025, 34029, 1262, 34031, 1264, 1265, 34033, 34034, 34035, 34037, 34040, 1273, 34041, 1275, 34042, 34043, 34046, 34047, 34050, 1283, 34060, 34061, 34063, 34064, 1297, 34066, 34067, 34068, 34069, 34072, 34073, 34074, 34077, 1310, 34080, 1320, 34088, 34089, 1325, 1327, 1328, 34096, 34098, 1331, 1333, 1334, 1335, 34104, 1337, 34105, 1340, 1341, 34112, 1347, 1348, 1350, 34118, 1352, 1353, 34119, 1355, 1356, 1357, 1358, 34120, 1360, 34121, 1362, 34124, 1364, 1366, 1367, 1370, 1371, 1372, 1374, 1375, 1376, 1378, 1379, 1380, 1382, 1383, 1384, 1389, 1390, 1391, 1393, 1394, 1395, 1397, 1398, 1399, 1400, 1401, 1403, 1404, 1405, 1407, 1408, 1410, 1411, 1412, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1423, 1424, 1425, 1429, 1430, 1431, 1434, 1435, 1437, 1438, 1440, 1441, 1443, 1444, 1445, 1448, 1450, 1453, 1454, 1455, 1456, 1457, 1464, 1467, 1469, 1470, 1471, 1474, 1476, 1477, 1479, 1481, 1482, 1483, 1485, 1486, 1488, 1489, 1494, 1495, 1496, 1497, 1498, 1499, 34262, 34265, 1502, 1503, 34268, 1505, 34269, 1507, 1508, 1509, 1510, 1511, 1512, 34274, 1514, 34276, 1516, 1517, 34279, 34280, 1520, 34282, 1522, 34283, 1524, 34288, 34289, 1527, 34291, 1529, 1530, 1531, 34292, 34293, 1534, 1535, 34297, 34298, 1538, 34299, 1540, 34300, 34303, 34304, 1544, 34306, 1546, 34308, 1548, 34312, 1551, 1552, 1555, 1556, 1559, 1560, 1562, 1563, 1564, 1565, 1567, 1569, 1570, 1572, 1573, 1578, 1579, 1581, 1584, 1587, 1588, 1589, 34357, 34359, 1592, 1595, 1596, 1597, 1598, 34363, 1600, 34369, 1602, 1603, 34370, 1605, 34371, 34374, 34376, 1610, 1611, 34378, 1615, 1616, 34385, 1618, 1619, 1620, 34386, 1622, 1623, 1624, 1625, 34389, 34390, 1628, 34393, 1630, 1631, 1632, 1633, 1634, 34394, 34396, 1637, 1638, 1639, 1640, 34400, 1642, 34402, 1644, 1645, 1646, 34406, 1648, 1649, 34414, 1651, 34415, 1653, 34416, 34417, 1656, 34421, 34422, 1659, 34426, 1661, 1662, 1663, 1664, 34431, 34434, 1667, 1669, 1670, 1671, 34438, 1674, 1675, 34443, 1677, 1678, 1679, 1680, 34445, 34446, 34452, 1687, 34456, 34458, 1691, 1692, 1693, 34463, 1696, 1697, 1698, 1699, 1700, 1701, 34464, 34467, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 34471, 34472, 1714, 1715, 1716, 1717, 34477, 34480, 34483, 34486, 1722, 1723, 34488, 1725, 1726, 1727, 34489, 1729, 34490, 1731, 34491, 1733, 34495, 1735, 34499, 1737, 1738, 1739, 1740, 1741, 34505, 1743, 1744, 1745, 34506, 1747, 1748, 1749, 1750, 34510, 1752, 34512, 34514, 34515, 1756, 34516, 1758, 1759, 1760, 1761, 1762, 1763, 34523, 34525, 34526, 1767, 1768, 1769, 1770, 34531, 34533, 1773, 1774, 34534, 34539, 1777, 1778, 1779, 1780, 1781, 1782, 34543, 1784, 34546, 34552, 1787, 1788, 34554, 1790, 34555, 1792, 1793, 34556, 1795, 1796, 1797, 1798, 34558, 1800, 34561, 34562, 1803, 34565, 1805, 1806, 1807, 1808, 34569, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 34576, 1818, 1819, 1820, 34580, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 34590, 1832, 34592, 1834, 1835, 1836, 34596, 34598, 1839, 34599, 34601, 1842, 1843, 34603, 34605, 1846, 1847, 34608, 1849, 1850, 34610, 1852, 1853, 34614, 1855, 34615, 34616, 1858, 1859, 1860, 34620, 1862, 1863, 1864, 1865, 34626, 1867, 1868, 1869, 1870, 1871, 1872, 34632, 34635, 1875, 34636, 1877, 1878, 34639, 1880, 34641, 34643, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 34665, 34667, 1900, 34668, 34669, 34673, 34681, 34685, 34808, 2048, 2055, 2057, 2058, 2063, 34832, 34833, 2066, 34835, 34837, 34838, 2073, 34842, 2075, 34844, 34847, 34849, 34852, 2085, 34856, 2092, 34860, 2094, 34861, 34862, 2097, 2098, 34866, 34867, 34868, 34870, 34872, 34873, 34877, 34878, 34880, 34881, 34883, 34886, 34887, 34888, 34889, 34891, 2125, 34894, 2127, 34896, 2129, 2130, 34898, 34899, 34901, 2134, 34902, 2137, 34906, 2139, 34907, 34909, 34911, 2145, 34914, 34915, 2149, 34917, 2151, 34919, 34921, 2154, 34925, 2158, 34928, 2161, 2162, 34929, 34930, 2166, 34934, 2168, 2169, 34936, 34937, 34939, 34940, 34943, 34944, 34947, 2180, 2181, 2182, 34948, 34952, 34954, 34956, 2189, 34960, 34961, 2194, 34962, 2196, 34963, 2198, 34964, 34965, 34967, 2202, 34968, 34974, 2207, 34975, 2210, 2211, 2213, 2217, 2218, 2220, 2226, 2228, 2233, 2237, 2240, 2246, 35016, 2249, 2251, 2252, 2253, 35020, 2256, 35025, 35026, 2259, 35028, 35031, 35032, 35034, 35035, 35036, 35037, 35039, 35040, 2275, 2276, 2277, 35043, 35046, 35047, 35048, 2282, 35050, 35053, 35054, 35055, 35056, 35057, 2290, 2291, 35058, 2293, 2294, 35059, 35060, 2297, 2298, 2299, 35061, 2301, 35062, 35064, 2304, 2305, 35065, 35066, 2308, 2309, 2310, 35070, 35071, 2313, 2314, 2315, 2316, 2317, 35077, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 35089, 2331, 2332, 35092, 35093, 2335, 2336, 35096, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 35107, 2349, 2350, 35114, 35116, 35118, 2354, 2355, 2356, 35120, 35122, 35124, 2360, 2361, 2362, 35125, 35126, 2365, 35129, 35131, 35132, 35134, 2370, 35138, 2372, 35139, 2374, 2375, 35140, 35144, 35145, 35146, 2380, 2381, 2382, 35149, 2384, 35150, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 35152, 35154, 35155, 2396, 35156, 2398, 35158, 35159, 2401, 2402, 2403, 35163, 2405, 2406, 2407, 2408, 2409, 2410, 35170, 2412, 35173, 35174, 2415, 2416, 2417, 2418, 2419, 35182, 2421, 35183, 2423, 2424, 2425, 2426, 2427, 2428, 35188, 35189, 2431, 35192, 2433, 35196, 35197, 35198, 2437, 2438, 35199, 35201, 2441, 35202, 2443, 35203, 2445, 2446, 2447, 2448, 35208, 2450, 35210, 35211, 2453, 2454, 2455, 2456, 35216, 2458, 2459, 2460, 2461, 2462, 2463, 35224, 35225, 2466, 2467, 35227, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 35238, 35239, 2481, 2482, 2483, 35244, 2485, 2486, 2487, 2488, 2489, 2490, 35250, 35251, 2493, 2494, 2495, 2496, 2497, 35257, 2499, 2500, 2501, 2502, 2503, 35265, 35268, 2506, 35274, 2508, 2509, 2510, 35275, 2512, 35279, 35280, 35281, 2517, 35286, 2519, 2520, 2522, 2523, 2524, 35290, 35291, 2527, 2528, 2529, 2530, 35292, 2532, 35293, 2534, 2535, 35295, 2537, 2538, 2539, 2540, 2541, 35305, 2543, 2544, 2545, 35306, 2547, 2548, 35308, 2550, 35311, 2552, 2553, 2554, 2555, 35315, 35317, 2558, 35319, 2560, 35322, 35326, 2563, 2564, 2565, 35327, 35329, 35331, 35332, 2570, 2571, 35334, 35335, 35340, 35341, 2576, 2577, 35343, 35345, 2581, 2583, 2584, 2585, 35356, 35357, 2592, 2593, 2594, 35362, 2596, 2597, 35366, 2599, 35368, 35369, 2603, 2604, 2605, 35371, 2607, 35374, 2609, 35376, 2614, 2615, 2616, 2617, 35384, 2619, 35387, 2621, 2623, 2625, 2627, 2628, 2629, 2631, 2633, 2636, 2638, 2640, 2644, 2646, 2647, 2649, 2650, 2651, 2652, 2653, 2654, 39181, 2657, 2658, 2660, 2661, 2668, 2670, 2672, 2676, 2679, 2690, 2693, 2694, 33104, 35543, 35554, 35558, 35563, 35566, 35567, 35568, 35569, 35571, 35576, 2810, 35578, 35580, 35581, 35582, 2815, 2816, 2817, 35583, 35584, 35585, 35586, 35589, 35590, 35592, 35593, 35594, 35595, 35596, 35599, 35601, 35602, 35603, 35604, 35605, 35608, 35611, 35612, 35614, 35616, 35618, 35619, 35620, 35621, 35622, 35623, 35624, 2858, 35626, 35627, 35630, 35631, 40401, 35633, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 35636, 2874, 35638, 2876, 2877, 2878, 35639, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 35646, 2888, 2889, 2890, 2891, 35651, 2893, 2894, 35654, 2896, 35656, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 35666, 2908, 2909, 35669, 2911, 2912, 35672, 35673, 2915, 2916, 35676, 35677, 2919, 35680, 2921, 2922, 35682, 35685, 35686, 2926, 35687, 2928, 35690, 2930, 2931, 35691, 2933, 2934, 2935, 2936, 2937, 35699, 2939, 35701, 35703, 35705, 35707, 2944, 2945, 2946, 35709, 2948, 35710, 35712, 2951, 2952, 2953, 2954, 35714, 2956, 2957, 2958, 35718, 2960, 2961, 2962, 2963, 2964, 2965, 35726, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 35735, 2976, 2977, 2978, 35738, 35740, 2981, 2982, 2983, 35745, 2985, 35748, 35749, 35750, 2989, 2990, 2991, 35754, 35755, 35756, 35757, 35759, 2997, 2998, 2999, 3000, 35760, 3002, 35763, 3004, 35764, 35765, 3007, 35767, 3009, 3010, 3011, 35774, 3013, 3014, 3015, 35776, 3017, 3018, 35779, 3020, 3021, 35781, 35782, 3024, 3025, 3026, 3027, 3028, 35789, 35791, 3031, 3032, 35792, 3034, 3035, 35795, 35796, 3038, 35798, 3040, 35800, 3042, 3043, 3044, 3045, 35805, 35806, 35807, 3049, 35812, 3051, 3052, 35815, 35816, 35818, 3056, 35819, 35820, 35821, 3060, 35823, 3062, 35827, 35831, 3065, 3066, 35832, 35833, 35834, 35835, 35836, 3072, 35837, 35839, 35840, 3076, 3077, 3078, 3079, 3080, 3081, 35842, 3083, 3084, 35845, 3086, 3087, 3088, 35848, 3090, 3091, 35851, 3093, 35854, 3095, 3096, 3097, 35857, 35860, 35863, 35864, 35867, 35868, 35869, 35872, 35873, 35874, 35875, 35877, 35878, 35879, 35881, 35882, 35883, 35884, 35885, 35886, 35888, 35889, 35891, 35893, 35894, 35896, 35897, 35898, 35899, 35900, 35901, 35902, 35903, 35904, 35905, 35906, 35907, 35908, 35909, 35910, 35911, 35914, 35916, 35918, 35919, 35921, 35922, 35923, 35924, 35925, 35926, 35928, 35929, 35930, 35931, 35932, 35934, 35936, 35937, 35938, 35939, 35944, 3179, 35948, 3181, 3182, 3183, 35949, 35954, 3187, 35955, 35956, 3190, 3191, 35957, 3193, 35958, 3195, 3196, 35961, 3198, 3199, 3200, 35962, 35964, 35966, 3204, 3205, 35967, 35969, 3208, 35970, 3210, 35971, 35973, 3213, 35975, 35976, 35978, 35980, 35983, 3219, 35984, 35985, 35986, 35988, 35989, 35990, 35991, 35992, 35995, 35996, 35997, 35999, 3232, 36001, 36003, 36004, 36005, 36006, 36007, 36008, 36009, 36011, 36012, 36013, 36014, 36016, 36017, 36018, 36019, 36021, 36024, 36025, 36028, 36029, 36030, 36031, 36032, 36034, 36035, 36036, 36037, 36038, 36039, 36040, 36041, 36043, 36044, 36046, 36049, 36051, 36052, 36053, 36054, 36057, 36058, 36060, 36061, 36062, 36063, 36064, 36067, 36068, 36069, 36070, 36071, 36072, 36073, 36075, 36078, 36079, 36080, 36081, 36082, 36084, 36086, 36089, 36092, 36094, 36098, 36101, 3335, 36105, 3338, 36109, 36110, 36111, 3344, 36112, 36113, 3347, 36116, 36118, 36119, 36120, 36121, 3354, 36122, 36123, 36125, 3358, 3359, 36126, 3361, 3362, 36127, 36128, 36130, 3366, 3367, 36131, 36133, 36134, 36135, 36140, 3373, 36141, 3375, 36142, 36143, 36144, 3379, 36146, 36148, 36150, 36153, 3386, 3387, 3388, 36154, 36155, 3391, 3392, 36156, 3394, 3395, 36157, 36158, 3398, 36159, 36160, 36161, 36163, 3403, 36164, 36165, 3406, 36167, 36168, 3409, 36171, 36173, 36174, 3413, 3414, 3415, 3416, 3417, 36177, 36179, 3420, 36180, 3422, 3423, 36183, 3425, 36185, 3427, 36188, 3429, 36192, 3431, 36197, 3433, 3434, 36200, 3436, 3437, 3438, 3439, 36201, 36203, 36205, 3443, 36209, 3445, 36213, 3447, 36215, 3452, 3453, 36221, 3455, 36224, 3461, 3465, 3466, 3467, 3468, 3470, 3474, 3477, 3484, 3485, 3487, 3498, 3499, 3504, 3506, 3507, 3509, 3512, 3513, 3515, 3517, 3519, 3521, 3525, 3528, 3529, 3530, 3533, 3534, 3536, 3538, 3540, 3541, 3544, 3545, 3547, 3548, 3549, 3551, 3553, 3554, 3555, 3556, 3557, 3559, 3562, 3563, 3567, 3569, 3570, 3573, 3575, 3577, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3589, 3590, 3591, 3593, 3594, 3595, 3597, 3601, 3602, 3603, 3605, 3606, 3609, 3611, 3612, 3614, 3616, 3618, 3619, 3620, 3621, 3622, 3627, 3630, 3633, 3636, 3637, 3638, 3639, 3640, 3642, 3643, 3645, 3646, 3651, 3655, 3656, 3661, 3662, 3663, 3666, 3667, 3668, 3669, 3671, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3686, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3699, 3700, 3701, 3702, 3703, 3705, 3706, 3707, 3708, 3709, 3712, 3713, 3714, 3716, 3720, 3723, 3726, 3729, 3732, 3737, 3738, 3739, 3740, 3741, 3743, 3746, 3750, 3751, 3753, 3756, 3758, 3759, 3762, 3763, 3765, 3768, 3770, 3773, 3774, 3777, 3780, 3782, 3783, 3784, 36550, 3786, 36556, 3794, 3795, 3796, 3798, 3801, 3802, 3803, 3807, 3808, 3809, 3810, 3811, 3816, 3817, 3819, 3821, 3822, 3842, 36686, 3939, 3949, 3950, 3951, 3953, 3955, 3958, 3961, 3966, 3968, 3970, 3971, 3973, 3976, 3978, 3979, 3982, 3985, 3986, 3987, 3989, 3991, 3994, 3996, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4009, 4011, 4012, 4013, 4017, 4020, 4021, 4022, 4023, 4024, 4027, 4029, 4033, 4036, 4037, 4038, 4039, 36810, 4044, 4045, 4046, 4047, 4049, 4050, 4051, 4052, 4053, 4054, 4057, 4060, 4061, 4062, 4065, 4067, 4069, 4070, 4072, 4075, 4077, 4078, 4079, 4080, 4081, 36849, 4084, 36853, 4086, 4089, 4093, 4094, 4095, 4098, 4099, 4101, 4102, 4104, 4107, 4110, 4111, 4112, 4113, 4115, 4118, 4120, 4121, 4122, 4123, 4124, 4125, 4128, 4130, 4131, 4132, 4133, 4134, 4135, 4137, 4139, 4140, 4142, 4144, 4145, 4146, 4148, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4160, 4161, 4162, 4165, 4166, 4167, 4168, 4170, 4171, 4172, 4174, 4175, 4177, 4178, 4179, 4180, 4181, 4183, 4185, 4186, 36955, 4188, 4192, 4197, 4198, 4201, 4202, 4204, 4210, 4211, 4212, 4213, 4215, 4218, 4219, 4220, 4221, 4223, 4226, 4228, 4229, 4230, 4231, 4234, 4236, 4237, 4240, 4241, 4243, 4245, 4246, 4248, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4258, 4259, 4261, 4263, 4264, 4266, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 37043, 4278, 4279, 4280, 4281, 37044, 37048, 4284, 37050, 4286, 4287, 37051, 37055, 37056, 4291, 4292, 37057, 37062, 4295, 4296, 4297, 4298, 37064, 37065, 4301, 37067, 4303, 37068, 37069, 37071, 37073, 37074, 37078, 37081, 4314, 4316, 4317, 37084, 4319, 37085, 4321, 4322, 37087, 37089, 37090, 4326, 37091, 37095, 37097, 4331, 37100, 4333, 37101, 4335, 37102, 37104, 37105, 37108, 37110, 37114, 4347, 4348, 37115, 4351, 37119, 4353, 37120, 37122, 4356, 4357, 37124, 37125, 37126, 4361, 4362, 4363, 37127, 37130, 4366, 37131, 37133, 37135, 4370, 4371, 37136, 37139, 37140, 37142, 37144, 37145, 4378, 37147, 37149, 37150, 37151, 37152, 37155, 37157, 37159, 37160, 37161, 37163, 37164, 37166, 37167, 37169, 37170, 37171, 37172, 37173, 37178, 37179, 37180, 37181, 37182, 37184, 37185, 37186, 37191, 37192, 37193, 37194, 37195, 37196, 37197, 37198, 37199, 37200, 37202, 37203, 37204, 37207, 37209, 37211, 37212, 37213, 37214, 37221, 37223, 37224, 37225, 37226, 37227, 37229, 37230, 37231, 37232, 37233, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 39254, 4491, 4499, 4502, 4503, 4516, 4517, 4518, 4522, 4523, 4526, 4529, 4530, 4535, 4537, 4539, 4542, 4543, 4544, 4547, 37315, 4549, 37316, 37318, 37319, 4553, 37321, 37322, 4556, 4557, 37323, 37325, 37327, 4561, 4562, 37328, 37329, 37330, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 37333, 37334, 37336, 4576, 37338, 37341, 4579, 37343, 37344, 37346, 4583, 4584, 4585, 4586, 37349, 37351, 4589, 37352, 4591, 4592, 4593, 4594, 37354, 37357, 37358, 37360, 37363, 4600, 4601, 37364, 37365, 37367, 37370, 37371, 37373, 37374, 37376, 37377, 37378, 4612, 37379, 37380, 4615, 37381, 37382, 4618, 4619, 37383, 4621, 37384, 4623, 37387, 4625, 4626, 4627, 37388, 37389, 37392, 37394, 37396, 4633, 37401, 4635, 37402, 37404, 37405, 4639, 37406, 4641, 4642, 37407, 37408, 4645, 4646, 37409, 37410, 4649, 37413, 37414, 37415, 37417, 4654, 37419, 37420, 4657, 4658, 4659, 4660, 4661, 37423, 4663, 4664, 4665, 4666, 4667, 4668, 4669, 4670, 37430, 4672, 37432, 37433, 37435, 37436, 37438, 4678, 37440, 37443, 4681, 37445, 4683, 4684, 4685, 37449, 4687, 37452, 4689, 37455, 4691, 37457, 37459, 37462, 37463, 4696, 4697, 4698, 37464, 4700, 37465, 4702, 37466, 37469, 4705, 37470, 37471, 4708, 37472, 4710, 37473, 4712, 4713, 37474, 4715, 37475, 37480, 4718, 4719, 4720, 37485, 4722, 37486, 4724, 37488, 37490, 4727, 4728, 37491, 37492, 37493, 4732, 37494, 4734, 4735, 37496, 37497, 4738, 4739, 4740, 4741, 4742, 37502, 37503, 4745, 4746, 4747, 37507, 4749, 4750, 4751, 4752, 37512, 37513, 4755, 4756, 4757, 37517, 37520, 4760, 4761, 37521, 37522, 4764, 4765, 37525, 4767, 37528, 37529, 4770, 37530, 37531, 37532, 4774, 37534, 4776, 4777, 4778, 37539, 37540, 4781, 37541, 4783, 37543, 37548, 37549, 37551, 4788, 37552, 4790, 37553, 4792, 37555, 37556, 37557, 37558, 37562, 37563, 37564, 4800, 37567, 37568, 37570, 37574, 4807, 37575, 37576, 4810, 4811, 4812, 37577, 37578, 37579, 37580, 4817, 4818, 4819, 37581, 4821, 37583, 37584, 37586, 37587, 4826, 37588, 37591, 37592, 37594, 4831, 37595, 37597, 37598, 37600, 37601, 37604, 37605, 37608, 37610, 37612, 37614, 37616, 37618, 37621, 37622, 37625, 37626, 37627, 37628, 37629, 37632, 37634, 37635, 37636, 37640, 4873, 37641, 37642, 37643, 37644, 37645, 37646, 37647, 4881, 37649, 4883, 37650, 37652, 37655, 37656, 37657, 37660, 37661, 37662, 4895, 37663, 37664, 37665, 4899, 37666, 37669, 37670, 37672, 37674, 37675, 37676, 37677, 37678, 37679, 37680, 37681, 37682, 4916, 37684, 37687, 37688, 37689, 37691, 4926, 37694, 37695, 37697, 37699, 37701, 37702, 37703, 37704, 4937, 37705, 37706, 4940, 4941, 4942, 37707, 37708, 37709, 37711, 37713, 37714, 4949, 37715, 37716, 37717, 37718, 37719, 4955, 4956, 37720, 37721, 37723, 37724, 4961, 37725, 37726, 37728, 37729, 37730, 4967, 4968, 4969, 37731, 37732, 37733, 37734, 37735, 37736, 37738, 37739, 37740, 37741, 37742, 37743, 37745, 37747, 37748, 37749, 37750, 37752, 37754, 37755, 37756, 37757, 37758, 37759, 37761, 37763, 37764, 37765, 37767, 37771, 37773, 37774, 37775, 37776, 37777, 37778, 37780, 37781, 37783, 37785, 37786, 37788, 37789, 37791, 37792, 37798, 37801, 37803, 37805, 37806, 37808, 37809, 37810, 37812, 37813, 37854, 37855, 37856, 37858, 37859, 37860, 5094, 37862, 37863, 5097, 5098, 5099, 37864, 5101, 37868, 5103, 37869, 5105, 5106, 37871, 5108, 37873, 37874, 5111, 37875, 5113, 37876, 5115, 37877, 37878, 37881, 5119, 5120, 37882, 37883, 5123, 5124, 37885, 5126, 5128, 5132, 5134, 5135, 5136, 5138, 5140, 5142, 5143, 5144, 5146, 5149, 5150, 5151, 5152, 5154, 5156, 5158, 5161, 5162, 5164, 5165, 5167, 5168, 5171, 5212, 5214, 5215, 5216, 5218, 5219, 5220, 5221, 5222, 5224, 5225, 5228, 5229, 5230, 5231, 5232, 5233, 5235, 5236, 5239, 5240, 5244, 5245, 5247, 5248, 5250, 5252, 5253, 5254, 5256, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5272, 5275, 5276, 5277, 5278, 5279, 5280, 5282, 5284, 5285, 5286, 5287, 5289, 5292, 5294, 5295, 5296, 5297, 5298, 5299, 5301, 5302, 5304, 5305, 5306, 5307, 5308, 5310, 5311, 5312, 5314, 5315, 5316, 5321, 5325, 5330, 5332, 5333, 5336, 5338, 5341, 5342, 5344, 5346, 5347, 5349, 5350, 5351, 5352, 5356, 5358, 5359, 5360, 5361, 5363, 5364, 5365, 5367, 5368, 5369, 5370, 5371, 5373, 5374, 5378, 5380, 5382, 5385, 5386, 5387, 5394, 5396, 5399, 5400, 5401, 5403, 5405, 5406, 5409, 5410, 5411, 5412, 5414, 5415, 5417, 5418, 5421, 5422, 5424, 5425, 5429, 5434, 5527, 5528, 5529, 5530, 5531, 5532, 5538, 5540, 5541, 5542, 5544, 5547, 5550, 5556, 5558, 5560, 5563, 5565, 5568, 5569, 5571, 5572, 5573, 5574, 5577, 5578, 5579, 5581, 5584, 5586, 5588, 5590, 5591, 5592, 5593, 5595, 5597, 5599, 5600, 5601, 5603, 5604, 5608, 5610, 5611, 5612, 5615, 5617, 5618, 5624, 5627, 5628, 5631, 5632, 5635, 5637, 5638, 5639, 5640, 5642, 5643, 5644, 5646, 5648, 5649, 5650, 5651, 5653, 5656, 5657, 5658, 5660, 5669, 5672, 5673, 5675, 5676, 5677, 5678, 5679, 5683, 5685, 5688, 5690, 5691, 5692, 5693, 5695, 5696, 5699, 5700, 5701, 5702, 5704, 5705, 5707, 5708, 5709, 5711, 5714, 5716, 5717, 5718, 5719, 5721, 5723, 5724, 5726, 5732, 5733, 5735, 5736, 5739, 5740, 5742, 5745, 5746, 5749, 5751, 5753, 5754, 5756, 5757, 5758, 5759, 5763, 5765, 5768, 5769, 5770, 5772, 5774, 5777, 5780, 5781, 5782, 5785, 5788, 5789, 5791, 5792, 5793, 5794, 5796, 5797, 5799, 5800, 5802, 5805, 5806, 5807, 5809, 5811, 5813, 5816, 5818, 5819, 5820, 5821, 5823, 5824, 5825, 5827, 5828, 5830, 5834, 5836, 5837, 5838, 5839, 5840, 5844, 5845, 5847, 5848, 5852, 5858, 5859, 5860, 5862, 5863, 5864, 5865, 5866, 5867, 5868, 5869, 5870, 5871, 5874, 5876, 5877, 5879, 5882, 5884, 5885, 5886, 5887, 5888, 5893, 5894, 5895, 5898, 5899, 5901, 5902, 5904, 5908, 5911, 5912, 5915, 5916, 5918, 38688, 38689, 38690, 38691, 5924, 38692, 38694, 38695, 38696, 38697, 38698, 5931, 5932, 38700, 38702, 40257, 38705, 38706, 38707, 38709, 38712, 38713, 38714, 38715, 38718, 38720, 38721, 38723, 38725, 38729, 38733, 38734, 40263, 38736, 40264, 38741, 38742, 38743, 38744, 38747, 38749, 38750, 38751, 38752, 38753, 38754, 38755, 38756, 38757, 38758, 38759, 38761, 38763, 38766, 38767, 38768, 38769, 38770, 38771, 38774, 38775, 38776, 38778, 38780, 38782, 38783, 38785, 38786, 38789, 38790, 38791, 38792, 38794, 38795, 38797, 38799, 38800, 38801, 38802, 38803, 38804, 38805, 38809, 38810, 38811, 38813, 38814, 38816, 38817, 38818, 38819, 6052, 38820, 38823, 38824, 38826, 38827, 38828, 38829, 6062, 38830, 6064, 38834, 6068, 38836, 6070, 38838, 38839, 6073, 6074, 38842, 6076, 6077, 38843, 38844, 6080, 6081, 38845, 6083, 38846, 6085, 6086, 38847, 38848, 38849, 38850, 38852, 6092, 6093, 6094, 38854, 6096, 38859, 38861, 38863, 38864, 38865, 6102, 38866, 38868, 38870, 6106, 6107, 38871, 6109, 38872, 38873, 38874, 38875, 6114, 6115, 6116, 6117, 38877, 6119, 6120, 38881, 6122, 38882, 38884, 38885, 6126, 38886, 6128, 6129, 6130, 6131, 6132, 38894, 6134, 6135, 6136, 38898, 38899, 6139, 6140, 6141, 6142, 38903, 38904, 6145, 6146, 38908, 6148, 38910, 6150, 6151, 38911, 6153, 6154, 6155, 6156, 6157, 38917, 6159, 38919, 6161, 6162, 38924, 38927, 6165, 6166, 38932, 6168, 38933, 6170, 38935, 38937, 6173, 6174, 6175, 6176, 38938, 6178, 6179, 38940, 38941, 6182, 38942, 6184, 6185, 6186, 6187, 6188, 38948, 6190, 6191, 6192, 6193, 38953, 6195, 38955, 38956, 38957, 6199, 38961, 38963, 6202, 38964, 38965, 6205, 38966, 38968, 6208, 6209, 38970, 38971, 6212, 38972, 38973, 38975, 6216, 6217, 6218, 6219, 6220, 6221, 38981, 6223, 6224, 6225, 38985, 38986, 6228, 38988, 6230, 38991, 6232, 6233, 6234, 6235, 38995, 38996, 6238, 6239, 6240, 6241, 39001, 6243, 6244, 39004, 6246, 6247, 6248, 39008, 39010, 6251, 39011, 6253, 39014, 6255, 6256, 6257, 39017, 39018, 39019, 6261, 39021, 6263, 39024, 6265, 6266, 6267, 39028, 6269, 6270, 6271, 39031, 6273, 6274, 6275, 39035, 6277, 6278, 6279, 6280, 39040, 39041, 6283, 6284, 6285, 6286, 39046, 6288, 6289, 6290, 6291, 6292, 6293, 39055, 6295, 39056, 6297, 6298, 6299, 39059, 39062, 39063, 39066, 39068, 6305, 6306, 6307, 39070, 6309, 39071, 6311, 6312, 39072, 39073, 6315, 6316, 6317, 39077, 6319, 6320, 6321, 39084, 39086, 6324, 6325, 6326, 39087, 39088, 6329, 39090, 39091, 39094, 6333, 6334, 39095, 6336, 39098, 6338, 39100, 39101, 6341, 39105, 6343, 6344, 6345, 6346, 39106, 6348, 6349, 39109, 6351, 6352, 6353, 39113, 6355, 6356, 6357, 39117, 39118, 6360, 6361, 6362, 39123, 6364, 6365, 6366, 39126, 39127, 6369, 39129, 6371, 6372, 39134, 6374, 6375, 39138, 6377, 6378, 39139, 6380, 6381, 39141, 6383, 6384, 39144, 39145, 39146, 39147, 6389, 6390, 39152, 39154, 39156, 6394, 39157, 39158, 6397, 6398, 6399, 39159, 6401, 6402, 39162, 39163, 39164, 6406, 6407, 39167, 39168, 6410, 39172, 39173, 39174, 6414, 6415, 39175, 39178, 6418, 6419, 6420, 6421, 6422, 6423, 39184, 6425, 6426, 6427, 6428, 6429, 39189, 39190, 6432, 6433, 39194, 6435, 6436, 6437, 6438, 6439, 6440, 6441, 6442, 6443, 6444, 6445, 39207, 6447, 39208, 6449, 6450, 6451, 39212, 39213, 6454, 39215, 39218, 39220, 6458, 39221, 39222, 39225, 6462, 6463, 39226, 6465, 6466, 6467, 6468, 6469, 39229, 6471, 6472, 39232, 6474, 39234, 6476, 6477, 6478, 6479, 39239, 6481, 39241, 6483, 6484, 6485, 39247, 39249, 6488, 6489, 39250, 39252, 6492, 6493, 39253, 6495, 39256, 39257, 39258, 6499, 6500, 39261, 39262, 6503, 39269, 39270, 39271, 6507, 39272, 6509, 39273, 39275, 39278, 39280, 6516, 39284, 39285, 39286, 39287, 39289, 39291, 39292, 40374, 6526, 39294, 39295, 39296, 39298, 39299, 39300, 39301, 39302, 39303, 39304, 39307, 39310, 39312, 39313, 39316, 39317, 39318, 39320, 39321, 40380, 40382, 40385, 40386, 40387, 39367, 39369, 39370, 39374, 39375, 39376, 39381, 39386, 39387, 39389, 39391, 39392, 39393, 39396, 6630, 39398, 39399, 39400, 39401, 39402, 39407, 39408, 6641, 6642, 6643, 39409, 39411, 39412, 39413, 39414, 6649, 39415, 39416, 39418, 39419, 39420, 6655, 39421, 6657, 39423, 6659, 6660, 39426, 39427, 39428, 6664, 6665, 39429, 6667, 6668, 39430, 39432, 39433, 39434, 39435, 39438, 39440, 39444, 6679, 39448, 39451, 39453, 6689, 6690, 6691, 39457, 6695, 6696, 6699, 39467, 6701, 39470, 6705, 6710, 6711, 6715, 6716, 6718, 40414, 6729, 6730, 6733, 6735, 6736, 6739, 6743, 6744, 40418, 6747, 6748, 6751, 40420, 6757, 6773, 6783, 6785, 6786, 6788, 6791, 6793, 6796, 40428, 6798, 6799, 6806, 6811, 6815, 6816, 6824, 6827, 6828, 6829, 6830, 6831, 6833, 6837, 6838, 40437, 6843, 6846, 6847, 40438, 6849, 6850, 6851, 6852, 6854, 6855, 6856, 6860, 6861, 6862, 40441, 6865, 6867, 6868, 6869, 6870, 6871, 40443, 6873, 6874, 6875, 6876, 6878, 6880, 6881, 6883, 6884, 6885, 6886, 6887, 6888, 6889, 6890, 6891, 40446, 6893, 6894, 6898, 6899, 6900, 6901, 6902, 6903, 6904, 6905, 6906, 6907, 6909, 6911, 6913, 6914, 6915, 6917, 6918, 6922, 6925, 6927, 6928, 6929, 6930, 6931, 6972, 6973, 6976, 6977, 6978, 6979, 6981, 6982, 6983, 6984, 6985, 6986, 6987, 6988, 6991, 6992, 6993, 6994, 6995, 6996, 6998, 6999, 7000, 7003, 7004, 7005, 7006, 7007, 7009, 7010, 7011, 7053, 7054, 7055, 7056, 7058, 7059, 7061, 7062, 7063, 7064, 7065, 7067, 7068, 7070, 7071, 7072, 7075, 7078, 7081, 7082, 7083, 7085, 7087, 7089, 7090, 7091, 7092, 7095, 7096, 7097, 7100, 7101, 7105, 7106, 7107, 7109, 7110, 7112, 7114, 7116, 7118, 7122, 7125, 7127, 7129, 7131, 7133, 7134, 7135, 7138, 7139, 7140, 7141, 7145, 7146, 7147, 7151, 7153, 7154, 7160, 7161, 7162, 7164, 7165, 7171, 7173, 7175, 7181, 7187, 7190, 7193, 7313, 7314, 7317, 7323, 7327, 7328, 7329, 7330, 7332, 7337, 7338, 7343, 7344, 7345, 7346, 7347, 7350, 7352, 7356, 7357, 7358, 7359, 7360, 7361, 7364, 7365, 7366, 7368, 7369, 7370, 7371, 7373, 7375, 7376, 7380, 7381, 7383, 7384, 7385, 7386, 7387, 7388, 7389, 7390, 7391, 7392, 7395, 7396, 7397, 7398, 7400, 7402, 7404, 7405, 7407, 7409, 7410, 7411, 7412, 7415, 7416, 7420, 7421, 7424, 7427, 7430, 7435, 7437, 7438, 7439, 7442, 7443, 7445, 7447, 7448, 7449, 7450, 7452, 7453, 7454, 7455, 7460, 7462, 7463, 7464, 7469, 7470, 7471, 7472, 40237, 7474, 40238, 7476, 7477, 7478, 40239, 40240, 40241, 40242, 40243, 40244, 40248, 7486, 7487, 7488, 40249, 7490, 40250, 40251, 40253, 7494, 7495, 7496, 7497, 7498, 7499, 7500, 40262, 7502, 7503, 7504, 7505, 40265, 40268, 40270, 7509, 40271, 40272, 7512, 7513, 40273, 40274, 40280, 7517, 7518, 7519, 40281, 7521, 40283, 7523, 7524, 40284, 7527, 7529, 7531, 7532, 7535, 7538, 7541, 7542, 7543, 7544, 7545, 7546, 7547, 7549, 7551, 7552, 7553, 7554, 7555, 7556, 40325, 40326, 7560, 7561, 7562, 7563, 7564, 7565, 40328, 40329, 7568, 40330, 40331, 40333, 40334, 40336, 40340, 7575, 40342, 40343, 7578, 40344, 40345, 40346, 40347, 7583, 7584, 7585, 40348, 7587, 40349, 40351, 40352, 7591, 40354, 40355, 40357, 40358, 7596, 40359, 7598, 40361, 40364, 7601, 7602, 40366, 7604, 7605, 7606, 7607, 7608, 40368, 7610, 7611, 40371, 40372, 40373, 7615, 7616, 40377, 40378, 40379, 7620, 7621, 40381, 7623, 40383, 40384, 7626, 7627, 7628, 40388, 40389, 40390, 40393, 7633, 7634, 7635, 7636, 40396, 7638, 7639, 40399, 7641, 7642, 40404, 7644, 40405, 40409, 7647, 7648, 7649, 7650, 40411, 40412, 7653, 40413, 7655, 40416, 7657, 7658, 7659, 7660, 7661, 40423, 40425, 7664, 40426, 7666, 7667, 7668, 7669, 40429, 40431, 7672, 40434, 7674, 40435, 40436, 7677, 7678, 7679, 40439, 7681, 7682, 7683, 7684, 40445, 7686, 7687, 40449, 40450, 7690, 40451, 40452, 40453, 40455, 40459, 40460, 40463, 40467, 40468, 40469, 7702, 40472, 7706, 7708, 7709, 40478, 7711, 40480, 40482, 7715, 40483, 40484, 40486, 7719, 40487, 40488, 7723, 7725, 40496, 40497, 40498, 40499, 40500, 40501, 40502, 7735, 40503, 40504, 40506, 7739, 7740, 40507, 40508, 7743, 40509, 40513, 40514, 40515, 40516, 40517, 40521, 40522, 40524, 40525, 40526, 40531, 40532, 40536, 40538, 40540, 40541, 40542, 40545, 40547, 40549, 40550, 40551, 40552, 40553, 40555, 40557, 40558, 40559, 40560, 40561, 40562, 40563, 40564, 40565, 40566, 40567, 40569, 40570, 40573, 40574, 40575, 40576, 40577, 40578, 40579, 40580, 40581, 40582, 40585, 40586, 40587, 40588, 40589, 40590, 40591, 40594, 40595, 40596, 40597, 40598, 40599, 40600, 40601, 40602, 7835, 40604, 7837, 40606, 40608, 7841, 40610, 40611, 40614, 7850, 40618, 40619, 7853, 40620, 40621, 40622, 40625, 40638, 7859, 40628, 40629, 7863, 7864, 40632, 40634, 7867, 7868, 40635, 7870, 7871, 7872, 7873, 7874, 7875, 40636, 7877, 7878, 7879, 7880, 40640, 40641, 7883, 7884, 40643, 7886, 7887, 40644, 7889, 7890, 40650, 40651, 40655, 7894, 40656, 7896, 40657, 7898, 7899, 7900, 40647, 7902, 7903, 7904, 40667, 7906, 7907, 40649, 40668, 7910, 40670, 40671, 7913, 40674, 40675, 40676, 40679, 7918, 40682, 7920, 40683, 7922, 40685, 40686, 40687, 7926, 40690, 40691, 7929, 7930, 40692, 7932, 40694, 40695, 40697, 7936, 40698, 7938, 7939, 40699, 40700, 40701, 7943, 40704, 7945, 40706, 7947, 7948, 7949, 7950, 40713, 40714, 40715, 40718, 40719, 40720, 40721, 7958, 40659, 7960, 40723, 7962, 40660, 7964, 40726, 40727, 7967, 40661, 40729, 40731, 40732, 40733, 40662, 40735, 40738, 40739, 40740, 7978, 40663, 7980, 7981, 40741, 7983, 40743, 40744, 7986, 40746, 40747, 7989, 7990, 40750, 7992, 7993, 40754, 40755, 40756, 7997, 7998, 7999, 8000, 8001, 8002, 8003, 40763, 8005, 40765, 8007, 40669, 40768, 8010, 8011, 8012, 40772, 40773, 40774, 8016, 8017, 8018, 8019, 40780, 40781, 40784, 8023, 8024, 8025, 40672, 40787, 40790, 40791, 8030, 8031, 8032, 8033, 40794, 8035, 8036, 8037, 8038, 8039, 8040, 8041, 40801, 40802, 40805, 8045, 8046, 40806, 40807, 8049, 40809, 8051, 40813, 40815, 8054, 40817, 8056, 8057, 8058, 40818, 8060, 40820, 8062, 40822, 8064, 40824, 40826, 8067, 8068, 8069, 40829, 8071, 40831, 40832, 40833, 8075, 40836, 8077, 40837, 8079, 40839, 40840, 8082, 8083, 40843, 8085, 8086, 40846, 40847, 40849, 8090, 40850, 40853, 40854, 8094, 8095, 40859, 8097, 8098, 8099, 40860, 8101, 8102, 40862, 8104, 8105, 40871, 8107, 8108, 40872, 8110, 8111, 8112, 8113, 8114, 8115, 8116, 8117, 8118, 40878, 40879, 8121, 8122, 40883, 8124, 40884, 8126, 40886, 8128, 8129, 40890, 8131, 8132, 8133, 8134, 8135, 8136, 8137, 40897, 8139, 8140, 8141, 40902, 8143, 8144, 8145, 8146, 8149, 8152, 8153, 8156, 8158, 8160, 8162, 8164, 8165, 8168, 8171, 8172, 8173, 8174, 40702, 8176, 40945, 40946, 8181, 8182, 40949, 8184, 40950, 8186, 40951, 8188, 40952, 40955, 8191, 40956, 8193, 8194, 8195, 40961, 8197, 8199, 40707, 40970, 40708, 40976, 8209, 40709, 8211, 8212, 40978, 8214, 40981, 40982, 40984, 40986, 40987, 40988, 40990, 40991, 40994, 40995, 8228, 8229, 8230, 8231, 40997, 40999, 8241, 8243, 8254, 8264, 8339, 8340, 8344, 8345, 8349, 8350, 8352, 8353, 8356, 8365, 8372, 8375, 8376, 8382, 8383, 8385, 8387, 8389, 8390, 8396, 8402, 8404, 41175, 41176, 41177, 8410, 41178, 8412, 41179, 41181, 8415, 8416, 41183, 41184, 41185, 8420, 8421, 8422, 40751, 41186, 41188, 41189, 41190, 41191, 41193, 41194, 41195, 41196, 8433, 8434, 8435, 8436, 41197, 41198, 8439, 8440, 8441, 41201, 8443, 41203, 8445, 8446, 8447, 41207, 8449, 41211, 8451, 40757, 8453, 41214, 8455, 40758, 41216, 41218, 41219, 8460, 8461, 8462, 40759, 8464, 41226, 40760, 41229, 41230, 41231, 41232, 40761, 41233, 8473, 8474, 8475, 8476, 8477, 40762, 41238, 41240, 41241, 8482, 41245, 8484, 8485, 8486, 40764, 41247, 8489, 41249, 41250, 41252, 41254, 41255, 41256, 41257, 41258, 41259, 8499, 41260, 41262, 41263, 41264, 41265, 8505, 8506, 8507, 41270, 41273, 8510, 41274, 40769, 41276, 8514, 41278, 8516, 8517, 40770, 41279, 41281, 8521, 40771, 41282, 41284, 41285, 41287, 8527, 41288, 41289, 41291, 41298, 41300, 8534, 41302, 8536, 8538, 8539, 8540, 8541, 8542, 41307, 8544, 41310, 8546, 8547, 40776, 41316, 8550, 41318, 8552, 41321, 8554, 8555, 8556, 40778, 8558, 41327, 8560, 8561, 8562, 41328, 8564, 41331, 8566, 8567, 41332, 8569, 41334, 8571, 41335, 8573, 41336, 41337, 8576, 8577, 41338, 8579, 8580, 8581, 8582, 8583, 34270, 8585, 41345, 8587, 8588, 8589, 41351, 8591, 41354, 8593, 41356, 8595, 41357, 8597, 41358, 41362, 41366, 8601, 8602, 8603, 8604, 8605, 8606, 8607, 41367, 8609, 41370, 41371, 41372, 8613, 41374, 8615, 8616, 41378, 41380, 8619, 8620, 8621, 8622, 41383, 8624, 41385, 8626, 8627, 41387, 8629, 8630, 8631, 8632, 41392, 41394, 8635, 8636, 8637, 8638, 8639, 41399, 41400, 41402, 8643, 8644, 8645, 8646, 8647, 8648, 41410, 41412, 41413, 8652, 8653, 41415, 41418, 8656, 8657, 8658, 40798, 8660, 8661, 8662, 40799, 41423, 8665, 41427, 41428, 8668, 8669, 40800, 41430, 41431, 8673, 8674, 8675, 8676, 8677, 8678, 41438, 8680, 41441, 41444, 41446, 41448, 41449, 41450, 41451, 41452, 41453, 8690, 41454, 41458, 8693, 41459, 8695, 41461, 8697, 41462, 8699, 41464, 41465, 8702, 8703, 41466, 8705, 41467, 8707, 8708, 40808, 41469, 8711, 41471, 8713, 41474, 41476, 41477, 8717, 41479, 41480, 41481, 8721, 8722, 8723, 8724, 41485, 41486, 41487, 8728, 8729, 8730, 8731, 41491, 41495, 41496, 41497, 41502, 41503, 41505, 41507, 8740, 41508, 41509, 8743, 41510, 8745, 41511, 41512, 8748, 41514, 41516, 41517, 41518, 41519, 41520, 41521, 41522, 41524, 8760, 41528, 41529, 40819, 41530, 41533, 41534, 41538, 8771, 41539, 40821, 41546, 8779, 40823, 41553, 8788, 41557, 41558, 41560, 41561, 41562, 41563, 41565, 41566, 8800, 41568, 41573, 41574, 41578, 41585, 41593, 40834, 8852, 8859, 8862, 8867, 8873, 8874, 8879, 8880, 40842, 8886, 8888, 40844, 8891, 8893, 8896, 8899, 8900, 8901, 8902, 8903, 8904, 8905, 8906, 8907, 8910, 8911, 8914, 8915, 8916, 8917, 8921, 8922, 8923, 8924, 8925, 8927, 8928, 8931, 8932, 8933, 8935, 8939, 8949, 8950, 8953, 8954, 8955, 8956, 41723, 8958, 41724, 8960, 41727, 8962, 8963, 8964, 8965, 41728, 41729, 41732, 8969, 8970, 41733, 41735, 8973, 40861, 41739, 41742, 41745, 8980, 8981, 41748, 41750, 40863, 8985, 8986, 8987, 41751, 41752, 8990, 41754, 41757, 41759, 8994, 8995, 8996, 41762, 41763, 8999, 9000, 9004, 9005, 41772, 9007, 9008, 41773, 9010, 41774, 9012, 41775, 41779, 41780, 41781, 9017, 9018, 9019, 41782, 41783, 9022, 41785, 9024, 41787, 9026, 9027, 41794, 41795, 9030, 41796, 41798, 41799, 9034, 9035, 9036, 9037, 9038, 9039, 40873, 9041, 40874, 9043, 9044, 9045, 9046, 9047, 40875, 9049, 41809, 9051, 9052, 9053, 9054, 9055, 9056, 9057, 40877, 9059, 9060, 41821, 9062, 41822, 41825, 9065, 9066, 41826, 41827, 9069, 41829, 9071, 9072, 9073, 9074, 9075, 9076, 9077, 9078, 40881, 9080, 9081, 9082, 9083, 9084, 41844, 9086, 9087, 9088, 9089, 9090, 9091, 9092, 41853, 9094, 9095, 40885, 9097, 41857, 9099, 9100, 9101, 9102, 9103, 9104, 9105, 9106, 9107, 41867, 41869, 41870, 9111, 9112, 9113, 9114, 9115, 9116, 41876, 9118, 9119, 9120, 9121, 9122, 41882, 9125, 40892, 9131, 9132, 9133, 9134, 9135, 9136, 9137, 9138, 40893, 9140, 9144, 40895, 9146, 9147, 9148, 9149, 9150, 9151, 9152, 9153, 9154, 40896, 9157, 41927, 9160, 9161, 41928, 41930, 41931, 41933, 40899, 9167, 41934, 41935, 9170, 41937, 9172, 41938, 9174, 9175, 9176, 9177, 41939, 41940, 41941, 41944, 9182, 9183, 9184, 9185, 40903, 41946, 41948, 41949, 41950, 40904, 41951, 41952, 41953, 41954, 41955, 41959, 9198, 41961, 41963, 9201, 9206, 9212, 9214, 9218, 9223, 34398, 9229, 9230, 9231, 34399, 9233, 9237, 9238, 42005, 42006, 34401, 42007, 42008, 42009, 42010, 42011, 9247, 42012, 9249, 42014, 9251, 9252, 34403, 9254, 42016, 34404, 42017, 9258, 42019, 9260, 34405, 42022, 42023, 42024, 42026, 42027, 42029, 9268, 42032, 42033, 34407, 42035, 42037, 42038, 42039, 9276, 9277, 42040, 42041, 9280, 9281, 42043, 42045, 42046, 42047, 42048, 42049, 9288, 42050, 9290, 9291, 42051, 9293, 42054, 42056, 9296, 9297, 42057, 9299, 42059, 9301, 42061, 9303, 9304, 42064, 42065, 9307, 42067, 42069, 42071, 9311, 42072, 42073, 9314, 42074, 42077, 9317, 9318, 42078, 42079, 42081, 42082, 9323, 42083, 9325, 42086, 42088, 42089, 42092, 9330, 9331, 42093, 42094, 9334, 42096, 9336, 9337, 9338, 42098, 42099, 9341, 9342, 42102, 42103, 42104, 42105, 9347, 9348, 42108, 9350, 42110, 42111, 9353, 42113, 42114, 9356, 9357, 42117, 9359, 9360, 9361, 42121, 9363, 9364, 9365, 42126, 9367, 42127, 42128, 42129, 42131, 42132, 42133, 42134, 42136, 9376, 9377, 9378, 9379, 9380, 9381, 9382, 9383, 9384, 9385, 42146, 9387, 42147, 9389, 42149, 9391, 9392, 42152, 42153, 9395, 42157, 42158, 42159, 42162, 42163, 9401, 42164, 42165, 9404, 42166, 9406, 9407, 42167, 42168, 9410, 42170, 42174, 9413, 9414, 9415, 42176, 9417, 42177, 42179, 42180, 42182, 9422, 42183, 42184, 9425, 9426, 9427, 42188, 9429, 9430, 42190, 9432, 42193, 9434, 42194, 42196, 42197, 42198, 42200, 42202, 9441, 42206, 9443, 9444, 9445, 9446, 9447, 42210, 42211, 9450, 9451, 9452, 42213, 42215, 9455, 42216, 9457, 42217, 9459, 9460, 42220, 9462, 42223, 42226, 42230, 42233, 9467, 9468, 42234, 42235, 9471, 9472, 42237, 9474, 9475, 9476, 9477, 9481, 9482, 9483, 9484, 9486, 9488, 9489, 9491, 9492, 9494, 9495, 9497, 9498, 9499, 9500, 9501, 9502, 9503, 9504, 9506, 9509, 9510, 9511, 9513, 9514, 9515, 9517, 9518, 9519, 9521, 9523, 9525, 9526, 9528, 9536, 9537, 9540, 9542, 9544, 9545, 9547, 42318, 42320, 42322, 42324, 42325, 42326, 9560, 42328, 42331, 42332, 42333, 42334, 9567, 42335, 42336, 9570, 42337, 9572, 42339, 42340, 42341, 42342, 9577, 42343, 42344, 42345, 42346, 42347, 42348, 42349, 9585, 42350, 42351, 34470, 42353, 42356, 9591, 42357, 42360, 42361, 42362, 42363, 42364, 42365, 42366, 9600, 34473, 42371, 42373, 42375, 42376, 42378, 9611, 9612, 42379, 9614, 9618, 34476, 42387, 42390, 9623, 9624, 9625, 42395, 42398, 42400, 42402, 42404, 42405, 42406, 9640, 42408, 9642, 9643, 42412, 42413, 9646, 9648, 42417, 42418, 9652, 42420, 42422, 42423, 42424, 42425, 42426, 42427, 42428, 42429, 9662, 42432, 9665, 42436, 9669, 9670, 42438, 9672, 9673, 9674, 9675, 42439, 42440, 9678, 9679, 42442, 9681, 9682, 42443, 9684, 9685, 42449, 42451, 9688, 9689, 9690, 42452, 9692, 42454, 42455, 42456, 9696, 9697, 34492, 9699, 42459, 9701, 9702, 42462, 9704, 9705, 9706, 9707, 42469, 9709, 9710, 42474, 42475, 9715, 9717, 9718, 9722, 9724, 9726, 9727, 9728, 9731, 9733, 9735, 9737, 9738, 34500, 9741, 9742, 9743, 9744, 9745, 9747, 9748, 9749, 9751, 9752, 9753, 9755, 9758, 9759, 9760, 9761, 9762, 9763, 9765, 9766, 9767, 9768, 9769, 9770, 9771, 9772, 9777, 9778, 9779, 9781, 9782, 9783, 9784, 9786, 9787, 9788, 9789, 9790, 9791, 9793, 9794, 9795, 34511, 9797, 9798, 9799, 9800, 9801, 9802, 9803, 9804, 9808, 34518, 34519, 34520, 34521, 34528, 42650, 42652, 34529, 42653, 42655, 42659, 42664, 42667, 42670, 42672, 9912, 9916, 42687, 9920, 42689, 9922, 42691, 9924, 9926, 9927, 9928, 9929, 42695, 42702, 9935, 42704, 9943, 42714, 9948, 42718, 9951, 42720, 9953, 9954, 42721, 42724, 42727, 42734, 42735, 42743, 42745, 42746, 42747, 42749, 42751, 42752, 42756, 42758, 42759, 42766, 42768, 10001, 42770, 10003, 42772, 10005, 42773, 42774, 42776, 10009, 42779, 42781, 10015, 10017, 42785, 10019, 10021, 10022, 42789, 42791, 10025, 34557, 42795, 10028, 42797, 10031, 10032, 10034, 42803, 10036, 10037, 42804, 10041, 10042, 10046, 42816, 10049, 42817, 10051, 10052, 42820, 42823, 10056, 10057, 10059, 10060, 42829, 10062, 42830, 42831, 10065, 42833, 10067, 42834, 10069, 42835, 10071, 42837, 10077, 10079, 10080, 10087, 10089, 10095, 10096, 10098, 10100, 10101, 34572, 10104, 10111, 34574, 10114, 10117, 10119, 10125, 34577, 10127, 10128, 10129, 10130, 10132, 10134, 10136, 34579, 10138, 10142, 10143, 34581, 10148, 10150, 10162, 10163, 34585, 10168, 10171, 34586, 10180, 10184, 34589, 10189, 10194, 10195, 10197, 10198, 10200, 10202, 10204, 34593, 10208, 10211, 10212, 42979, 42980, 10215, 42982, 34595, 42983, 42984, 42985, 42987, 42988, 42989, 42990, 42991, 10226, 10227, 10228, 10229, 10230, 42994, 42996, 10233, 42997, 42998, 10236, 43000, 10238, 43001, 43002, 43004, 10242, 10243, 10244, 10245, 43006, 10247, 43009, 10249, 10250, 43014, 10252, 34602, 10254, 43017, 43020, 43021, 43025, 10259, 10260, 10261, 43026, 43027, 43028, 10265, 43030, 10267, 10268, 10269, 10270, 43031, 10272, 10273, 10274, 43038, 43043, 10277, 43045, 10279, 43046, 10281, 10282, 10283, 10284, 10285, 43050, 43054, 43056, 10289, 43057, 10291, 10292, 43059, 10294, 43061, 43062, 10297, 34611, 10299, 43064, 10301, 10302, 10303, 10304, 10305, 43065, 10307, 43070, 10309, 43072, 10311, 10312, 10313, 43075, 43076, 10318, 10319, 10321, 10323, 10325, 10326, 10327, 10328, 10329, 10330, 10332, 10333, 34618, 10337, 10339, 10342, 10345, 10346, 10348, 10350, 10351, 10352, 34622, 10354, 10355, 34623, 10358, 10360, 34624, 10364, 10367, 10368, 10370, 10372, 10373, 10374, 10375, 10376, 10377, 10378, 34627, 10380, 10382, 34628, 10384, 10385, 10388, 10389, 10390, 10391, 34629, 10396, 10397, 10398, 10399, 10400, 10401, 10402, 10403, 10404, 34631, 10406, 10407, 10408, 10413, 10415, 10417, 10418, 10419, 10420, 10421, 10425, 10426, 10429, 10432, 10433, 10434, 10436, 10437, 10438, 10440, 10441, 10442, 10443, 10444, 10445, 10447, 10448, 10449, 10450, 10451, 10453, 10454, 10455, 10456, 10459, 10464, 10467, 10468, 10469, 10470, 10472, 10473, 10479, 10480, 10481, 10483, 10484, 10485, 10486, 10487, 10489, 10490, 10492, 10493, 10495, 10496, 10497, 10498, 10499, 10500, 34651, 10502, 10503, 10505, 10507, 10508, 10509, 10510, 10512, 10513, 10515, 10516, 10517, 10519, 10520, 10524, 10525, 10526, 10528, 10529, 10530, 10531, 10532, 10536, 10537, 10540, 10542, 10543, 10544, 10545, 10546, 10547, 10554, 10555, 10556, 10557, 10558, 10559, 10563, 10564, 10565, 10570, 10572, 10573, 10575, 10576, 10577, 10579, 10580, 10581, 10582, 10584, 10585, 10586, 10587, 10589, 10591, 10592, 10594, 10595, 10596, 10597, 10598, 10599, 10603, 10606, 10608, 10611, 10614, 10618, 10619, 10620, 10622, 10623, 10624, 10626, 10627, 10628, 10629, 10630, 10635, 10636, 10637, 10638, 10639, 10640, 10643, 10645, 10646, 10647, 10649, 10651, 10653, 10654, 10656, 10657, 10658, 10660, 10662, 10664, 10666, 10669, 10671, 10673, 10674, 10676, 10677, 10680, 41200, 10682, 10683, 10684, 10685, 10686, 10692, 10693, 10694, 10695, 10696, 10697, 10700, 10701, 10702, 10704, 10705, 10706, 10707, 10708, 10709, 41206, 10713, 10714, 10715, 10718, 10719, 10720, 10721, 10722, 10724, 10726, 10728, 10729, 10730, 10731, 10732, 10733, 10734, 10736, 10737, 10738, 10739, 10741, 10745, 10747, 10749, 10751, 10753, 10755, 10756, 10760, 10762, 10763, 10764, 10765, 10772, 10774, 10776, 10777, 10778, 10779, 10781, 10782, 10784, 10785, 10786, 10787, 10788, 10789, 41221, 10793, 10794, 10795, 10796, 41223, 10798, 10800, 10801, 10804, 10805, 10806, 10807, 10809, 10811, 10813, 10814, 10816, 10817, 10818, 10820, 10821, 10823, 10826, 10827, 10828, 10831, 10833, 10834, 10835, 10836, 10838, 10839, 10840, 10841, 10842, 10843, 10845, 10847, 10850, 10851, 10852, 10854, 10855, 41235, 10857, 10858, 10859, 10860, 10861, 10862, 10863, 10865, 10866, 10867, 10868, 10869, 10870, 10872, 10873, 10874, 10875, 10876, 10877, 10878, 10879, 10880, 10881, 10882, 10883, 10885, 10888, 10891, 10893, 10896, 10901, 10902, 10903, 10905, 10906, 10908, 10910, 10911, 10912, 10913, 10914, 10915, 10918, 10919, 10920, 10921, 10922, 10923, 41248, 10925, 10926, 10929, 10930, 10932, 10933, 10934, 10935, 10936, 10937, 10938, 10940, 10942, 10943, 10944, 10945, 10946, 10947, 10949, 10950, 10952, 10956, 10959, 10963, 10969, 10971, 10980, 10988, 10989, 10994, 10996, 10997, 11000, 11001, 11006, 11007, 11011, 41266, 11020, 11022, 11027, 11030, 11032, 11041, 11042, 11044, 11046, 11057, 11058, 11069, 11070, 11072, 11073, 11075, 11091, 11093, 11094, 11095, 11097, 11099, 11101, 11105, 11116, 11120, 11125, 11129, 11135, 11139, 11145, 11146, 11150, 11151, 11154, 11159, 11161, 11168, 11171, 11186, 11191, 11192, 11195, 11198, 11214, 11216, 11217, 11219, 11220, 11224, 11225, 11226, 11227, 11228, 11229, 11231, 11232, 11233, 11234, 11235, 11236, 11238, 11239, 11242, 11244, 11246, 11247, 11248, 11251, 11252, 11253, 11254, 11255, 11256, 11257, 11261, 11262, 11263, 11264, 11265, 11271, 11273, 11274, 11275, 11276, 11277, 11279, 11281, 11283, 11284, 11285, 11286, 11287, 11288, 11289, 11290, 11292, 11294, 11295, 11299, 11304, 11305, 11306, 11307, 11309, 11310, 11311, 11312, 11314, 11315, 11316, 11318, 11320, 11321, 11322, 11323, 11324, 11325, 11329, 11330, 11332, 11333, 11334, 11335, 11336, 11342, 11348, 11349, 11350, 11352, 11353, 11356, 11357, 11358, 11361, 11362, 11363, 11364, 11366, 11368, 11369, 11371, 11372, 11373, 11374, 11375, 11376, 11377, 11378, 11379, 41339, 11382, 11383, 11384, 11386, 11390, 11391, 11394, 11396, 11397, 11402, 11404, 41344, 11406, 11407, 11408, 11409, 11410, 11413, 11419, 11421, 11423, 11425, 11427, 11432, 11434, 11436, 11437, 11442, 11443, 11445, 11447, 11448, 11451, 11454, 11458, 11461, 11466, 11468, 11469, 11471, 11472, 11474, 11475, 11476, 11478, 11480, 11484, 11486, 11487, 11488, 11491, 11492, 11493, 11494, 11495, 11497, 11498, 11500, 11502, 11504, 11505, 11506, 11508, 11509, 11510, 11511, 11514, 11516, 11517, 11518, 11520, 11521, 11524, 11525, 11526, 41368, 11528, 11529, 11532, 11533, 11534, 11537, 11539, 11540, 11541, 11542, 11543, 11544, 11547, 11560, 41375, 41386, 41388, 41389, 11656, 11657, 11658, 11659, 11660, 11666, 11667, 41396, 11669, 11670, 11673, 11674, 11679, 11680, 11681, 11682, 11683, 11685, 11687, 11690, 11693, 11694, 11695, 11696, 11698, 11700, 41403, 11702, 11704, 11705, 11706, 11708, 11712, 11713, 11714, 11716, 11717, 11718, 11719, 41406, 11721, 11722, 11723, 11724, 41407, 11726, 11727, 11728, 11731, 11732, 11733, 11736, 11741, 11742, 11745, 11746, 11747, 11748, 11749, 39169, 11755, 11756, 11757, 11760, 11762, 11764, 11765, 11767, 11770, 11772, 11773, 11774, 11777, 11779, 11781, 11787, 41420, 11790, 11793, 11796, 41422, 11798, 11799, 11800, 11802, 11806, 11808, 11809, 11810, 11812, 11813, 11814, 11815, 11821, 11823, 11825, 11827, 11830, 11831, 11832, 11833, 41429, 11836, 11837, 11840, 11841, 11842, 11844, 11845, 11848, 11849, 11850, 11851, 11852, 11853, 41433, 11857, 11858, 41434, 11863, 11865, 11866, 11869, 11871, 11872, 11874, 11875, 11880, 11881, 11885, 11887, 11890, 11895, 11897, 11899, 11900, 11902, 11903, 11904, 11906, 11907, 11909, 11910, 11911, 11914, 11915, 11917, 11918, 11922, 11923, 11924, 11926, 11927, 11929, 11931, 11932, 11933, 11934, 11935, 11938, 11939, 11941, 11944, 11946, 11948, 11949, 11950, 11951, 11952, 11953, 11955, 11956, 11957, 11958, 11959, 11963, 11966, 11967, 11968, 11969, 11970, 11971, 11972, 11974, 11975, 11976, 11977, 11978, 11979, 11980, 11981, 11982, 11985, 11986, 11987, 11988, 11990, 11991, 11993, 11997, 11998, 11999, 12002, 12005, 12009, 12010, 12011, 12012, 12013, 12016, 12018, 12020, 12021, 12022, 12023, 12026, 12027, 12030, 12031, 12032, 12034, 12035, 12036, 12038, 12039, 12040, 12041, 12042, 41470, 12045, 12047, 12048, 12049, 12051, 12052, 12053, 12054, 12056, 12057, 12058, 12059, 12060, 12061, 12064, 12065, 12066, 12067, 12068, 12069, 12073, 12074, 12076, 12077, 12078, 12079, 12082, 12083, 12084, 12085, 12086, 12089, 12092, 12098, 12099, 12100, 12101, 12102, 12103, 41483, 12108, 12111, 12112, 12115, 12116, 12117, 12118, 12119, 12121, 12122, 12123, 12127, 12129, 12130, 12131, 12132, 12133, 12134, 12135, 12136, 12137, 12138, 12139, 12141, 12142, 12143, 12144, 12145, 12146, 12150, 12153, 12156, 12157, 12162, 12165, 12166, 12167, 12168, 12169, 12170, 12171, 12172, 12173, 12174, 12176, 12177, 12178, 12179, 12180, 12181, 12183, 12184, 12185, 12186, 12187, 12189, 12190, 12191, 12192, 12194, 12195, 12196, 12199, 12202, 12203, 12204, 12205, 12207, 12210, 12211, 12212, 12213, 12214, 12215, 12216, 12220, 12221, 12225, 12226, 12227, 12229, 12230, 12232, 12235, 12236, 12237, 12238, 12240, 12241, 12242, 12243, 12245, 12246, 12247, 12251, 12253, 12254, 12255, 12256, 12258, 12260, 12261, 12262, 12263, 12264, 12265, 12268, 12270, 12271, 12272, 12273, 12274, 12275, 12277, 12278, 12279, 12280, 12281, 12282, 12283, 12286, 12288, 12289, 12291, 12293, 12294, 12295, 12296, 12297, 12298, 12299, 12300, 12302, 12303, 12304, 12305, 12306, 12307, 12308, 12309, 12311, 12313, 12314, 12316, 12317, 12319, 12320, 12323, 12325, 12328, 12329, 12330, 12332, 12335, 12336, 12337, 12338, 12339, 12341, 12342, 12343, 12344, 12345, 12346, 12347, 12351, 12353, 12355, 12356, 12357, 12359, 12363, 12364, 12365, 12366, 12408, 12410, 12413, 12414, 12416, 12417, 12418, 12419, 12420, 12421, 12422, 12423, 12424, 12426, 12427, 12429, 12430, 12431, 12432, 12433, 12434, 12439, 12440, 12446, 12447, 12448, 12450, 12452, 12455, 12456, 12457, 12463, 12465, 12469, 12471, 12472, 12473, 12478, 12480, 12484, 12487, 12490, 12493, 12494, 12495, 12496, 12498, 12499, 12502, 12503, 12511, 12514, 12515, 12516, 12518, 12520, 12523, 12525, 12526, 12527, 12528, 12532, 12537, 12538, 12542, 12543, 12547, 12555, 12560, 12566, 12567, 12569, 12584, 35067, 12593, 12596, 35068, 12599, 12600, 12603, 12604, 12605, 12607, 12608, 12609, 12610, 12611, 12614, 12615, 12616, 12619, 12620, 12624, 12626, 35074, 12629, 12630, 12632, 12633, 12634, 35075, 12638, 12639, 12640, 12649, 12650, 12651, 35079, 12653, 12655, 12656, 12658, 12660, 12661, 35081, 12663, 12666, 12667, 12670, 12671, 12672, 12673, 12674, 12676, 12677, 12678, 35084, 12681, 12682, 12683, 12685, 12689, 12690, 12691, 12692, 35087, 12694, 12695, 12696, 12697, 12698, 12699, 12700, 12701, 35088, 12704, 12705, 12707, 12708, 12709, 35090, 12711, 12712, 12716, 12717, 12719, 12720, 12721, 12723, 12724, 35094, 12728, 12729, 12730, 12731, 12732, 12733, 12734, 12735, 12737, 12739, 12741, 12743, 12745, 12747, 35098, 12749, 12751, 12752, 12753, 12754, 12755, 35099, 12757, 12760, 12761, 12762, 12763, 12765, 12767, 12768, 35102, 12770, 12771, 12774, 12775, 12776, 12777, 35104, 12781, 12782, 35105, 12784, 12785, 12788, 12789, 12790, 35106, 12793, 12794, 12795, 12796, 12797, 12798, 12801, 12802, 12803, 12804, 35109, 12809, 12810, 12811, 12812, 12813, 12814, 12815, 12816, 12818, 12819, 12820, 12822, 12824, 12826, 12827, 12829, 12831, 12832, 12834, 12835, 12836, 12837, 12838, 12840, 12843, 12844, 12845, 12847, 12848, 12851, 12852, 12853, 12854, 12855, 12856, 12857, 12858, 12859, 12860, 12862, 12867, 12871, 12875, 12878, 12879, 12881, 12883, 12885, 12887, 12889, 12890, 12891, 12893, 12896, 12897, 12899, 12901, 12902, 12905, 12906, 12913, 12915, 12917, 12919, 12920, 12921, 12922, 12926, 12928, 12930, 12931, 12932, 12934, 12935, 12936, 12937, 12938, 12947, 12948, 12949, 12950, 12951, 12953, 12956, 12957, 12958, 12959, 12960, 12961, 12962, 12963, 12965, 12966, 12967, 12969, 12970, 12972, 12976, 12977, 12979, 12980, 12981, 12984, 12985, 12986, 12987, 12989, 12993, 12995, 12996, 12997, 12998, 13004, 13006, 13009, 13013, 13015, 13016, 13017, 13018, 13020, 13022, 13024, 13026, 13027, 13028, 13029, 13030, 13031, 13032, 13033, 13034, 13036, 13038, 13039, 13040, 13041, 13042, 13043, 13044, 35157, 13046, 13047, 13050, 13051, 13053, 13054, 13055, 13056, 13057, 13058, 13059, 13060, 13061, 13062, 35160, 13064, 35161, 13066, 13072, 13073, 13075, 13077, 13078, 13082, 13083, 35165, 13085, 13088, 13089, 13094, 13095, 13096, 35167, 13098, 13099, 13100, 13101, 13103, 13106, 13107, 13109, 13110, 13113, 13114, 35171, 13118, 13119, 13120, 13122, 13126, 13127, 13128, 13130, 13131, 13132, 13133, 13135, 13136, 35175, 13138, 13139, 13140, 13141, 13143, 13145, 13146, 13148, 13155, 13156, 13157, 13159, 13160, 13163, 13165, 13166, 13167, 13171, 13172, 13173, 13174, 13176, 13177, 13178, 13179, 13180, 13182, 13183, 13186, 13188, 13191, 13192, 13195, 13196, 13198, 13199, 13200, 13201, 13202, 13203, 13204, 13205, 13210, 13211, 13213, 13214, 13216, 13217, 13221, 13222, 13223, 13224, 13225, 13226, 13227, 13228, 13229, 13230, 13233, 13234, 13235, 13236, 13237, 13240, 13241, 13243, 13244, 13248, 13249, 13250, 13251, 13254, 13256, 13257, 13258, 13260, 13261, 13262, 13263, 13264, 13265, 13266, 13271, 13272, 13273, 13275, 13277, 13278, 13279, 13280, 13282, 13283, 13284, 13285, 13286, 13287, 13288, 13289, 35205, 13291, 35206, 13293, 13294, 13295, 13296, 13299, 13300, 13301, 13302, 13303, 13306, 35209, 13309, 13310, 13312, 13313, 13314, 13316, 13317, 13318, 13321, 35212, 13323, 13325, 13327, 13329, 13330, 13331, 13332, 13334, 13336, 13338, 13339, 13340, 13342, 13343, 13344, 13345, 13348, 13349, 35218, 13352, 13354, 13356, 13357, 13358, 13359, 13360, 13361, 35220, 13363, 13364, 13366, 13367, 13368, 13370, 13371, 13374, 13376, 13378, 13379, 13381, 13382, 13388, 13389, 35226, 13392, 13393, 13394, 13396, 13398, 13400, 13403, 13406, 13407, 13408, 13409, 13410, 13411, 13412, 13413, 13414, 13415, 13416, 13417, 13418, 13419, 35231, 13421, 13423, 13424, 13425, 35233, 13428, 13429, 13430, 13431, 13432, 13433, 35234, 13436, 35235, 13439, 13440, 13445, 13450, 13451, 13452, 13453, 13454, 13455, 13456, 13457, 13459, 13462, 13464, 13465, 13466, 13467, 13468, 13469, 13470, 13472, 35242, 13475, 13477, 13478, 13479, 13482, 13484, 13485, 13486, 35245, 13489, 13490, 13491, 13492, 13493, 13495, 13498, 13499, 35248, 13504, 13505, 13506, 13507, 35249, 13509, 35252, 35255, 35260, 41800, 41801, 41802, 41804, 41806, 13733, 41807, 41808, 35297, 41810, 41812, 35300, 41813, 41814, 41816, 41817, 41819, 35313, 35314, 13843, 41830, 41833, 13874, 41835, 41836, 41839, 41840, 41841, 41842, 41843, 41845, 41849, 41851, 41854, 41855, 41856, 41858, 41861, 41865, 41866, 41871, 41875, 14080, 41877, 41878, 14095, 41879, 14100, 41880, 41881, 14170, 14296, 14297, 14298, 14299, 14302, 14303, 14304, 14306, 14308, 14310, 14311, 14313, 14315, 14316, 14320, 14324, 14325, 14327, 14328, 14329, 14330, 14331, 14332, 14333, 14336, 14337, 14338, 14340, 14342, 14345, 14346, 14347, 14348, 14349, 14351, 14352, 14353, 14355, 14356, 14357, 14358, 14360, 14362, 14364, 14365, 14366, 14367, 14368, 14370, 14371, 14373, 14374, 14375, 14376, 14377, 14379, 14380, 14382, 14383, 14384, 14385, 14386, 14387, 14389, 14390, 14391, 14392, 14393, 14394, 14396, 14398, 14400, 14404, 14405, 14406, 14409, 14410, 14412, 14414, 14415, 14416, 14417, 14418, 14419, 14422, 14425, 14426, 14427, 14428, 14429, 14431, 14433, 14434, 14435, 14439, 14442, 14445, 14447, 14450, 14451, 14452, 14455, 14456, 14457, 14460, 14461, 14462, 14463, 14465, 14466, 14469, 14472, 14474, 14475, 14476, 14478, 14480, 14481, 14482, 14483, 14485, 14486, 14527, 14528, 14529, 14531, 14535, 14536, 14538, 14540, 14541, 14542, 14543, 14544, 14545, 14547, 14549, 14550, 14552, 14554, 14555, 14556, 14557, 14559, 14560, 14563, 14566, 14569, 14570, 14571, 14572, 14574, 14575, 14577, 14578, 14579, 14580, 14581, 14582, 14585, 14586, 14588, 14589, 14590, 14592, 14593, 14599, 14601, 14602, 14604, 14605, 14707, 14711, 14713, 14714, 14715, 14716, 14720, 14723, 14726, 14727, 14728, 14731, 14732, 14733, 14735, 14738, 14739, 14740, 14741, 14743, 14744, 14745, 14746, 14747, 14748, 14749, 14750, 14751, 14754, 14759, 14760, 14761, 14762, 14763, 14764, 14765, 14766, 14767, 14769, 14770, 14771, 14772, 14774, 14775, 14776, 14778, 14779, 14781, 14782, 14784, 14787, 14788, 14791, 14793, 14794, 14795, 14796, 14797, 14798, 14800, 14801, 14803, 14804, 14805, 14806, 14807, 14808, 42020, 14811, 14812, 14813, 14814, 14815, 14816, 14817, 14818, 14820, 14824, 14826, 14827, 14828, 14829, 14832, 14833, 14834, 14835, 14836, 14837, 14839, 14840, 14841, 14842, 14844, 14846, 14848, 14849, 14850, 14851, 14853, 14854, 14855, 14856, 14858, 14859, 14860, 14861, 14862, 14863, 14866, 14867, 14868, 14870, 14871, 14873, 14874, 14877, 14880, 14883, 14884, 14886, 14887, 14889, 14890, 14891, 14892, 14895, 14896, 14897, 14898, 14900, 14902, 14904, 14906, 14907, 14908, 14909, 14911, 14912, 14914, 14915, 14916, 14917, 14918, 14919, 14920, 14922, 14923, 14925, 14926, 14929, 14932, 14934, 14937, 14938, 14939, 14940, 14942, 14943, 14945, 14946, 14947, 14948, 14953, 14955, 14956, 14958, 14960, 14961, 14962, 14963, 14964, 14965, 14966, 14967, 14968, 14969, 42052, 14973, 14974, 14975, 14976, 14978, 14980, 14982, 14983, 14984, 14985, 14986, 14987, 14989, 14990, 14991, 14994, 14995, 14997, 14998, 15001, 15003, 15004, 15006, 15007, 15008, 15009, 15013, 15015, 15016, 15017, 15018, 15019, 15020, 15021, 42062, 15023, 15024, 15025, 15026, 42063, 15028, 15030, 15033, 15035, 15037, 15038, 15039, 15040, 42066, 15042, 15043, 15044, 15046, 15049, 15053, 15055, 15056, 15058, 15059, 15061, 15063, 15065, 15066, 15067, 15068, 15070, 15071, 15072, 15073, 15074, 15076, 15077, 15078, 15079, 15080, 15081, 15082, 15083, 15085, 15086, 15087, 15088, 15104, 15106, 15107, 15108, 15110, 15112, 42100, 42101, 42107, 42109, 42112, 42115, 42116, 42118, 42120, 42122, 42123, 42124, 42138, 42139, 42140, 42142, 42143, 42144, 42150, 42151, 35641, 42154, 35643, 35644, 35645, 35649, 42169, 35657, 35658, 35659, 35660, 35661, 35662, 35663, 35664, 35665, 35667, 35668, 35670, 35671, 42185, 35674, 35675, 42189, 35678, 42191, 35681, 35692, 35694, 42218, 42219, 42221, 35715, 35716, 35717, 35719, 35720, 35721, 15883, 15884, 35722, 15888, 15889, 15891, 35723, 15893, 15894, 15895, 15896, 15897, 15898, 15899, 15900, 35724, 15904, 15907, 15908, 15909, 15910, 15911, 35727, 15913, 15914, 15917, 15918, 15919, 15920, 15921, 15922, 15923, 15924, 15925, 35729, 15927, 35730, 15929, 15932, 15934, 15937, 35732, 15940, 15941, 35733, 15943, 15944, 15949, 15950, 15954, 15955, 15956, 15958, 15959, 15962, 15963, 15964, 15965, 35737, 15967, 15968, 15969, 15970, 15972, 15974, 15975, 15977, 15978, 15979, 15980, 15981, 15982, 15983, 15984, 15986, 15987, 15988, 15989, 15993, 15995, 15997, 15998, 16000, 16001, 16002, 16003, 16004, 16005, 16006, 16007, 16008, 16009, 16010, 16011, 16013, 16016, 16017, 16019, 16020, 16021, 16022, 16023, 16025, 16026, 16027, 16029, 16031, 16032, 16033, 16034, 16035, 16037, 16040, 16041, 16043, 16044, 16046, 16047, 16049, 16050, 16051, 16052, 16053, 16055, 16056, 16057, 16058, 16059, 16060, 16064, 16066, 16068, 16069, 16071, 16074, 16075, 16076, 16077, 16078, 16080, 16081, 16082, 16083, 16084, 16085, 16086, 16087, 16088, 16089, 16090, 35761, 16092, 16093, 16095, 16096, 16097, 16098, 16100, 16102, 16104, 16105, 16106, 16109, 16110, 16114, 16115, 16117, 35768, 16121, 16123, 16124, 16125, 35769, 16127, 35770, 16130, 16131, 16132, 16133, 16136, 16138, 16139, 16142, 16144, 16145, 16148, 16149, 16151, 16152, 16153, 16156, 16157, 16158, 16159, 16161, 16162, 16163, 35777, 35783, 35784, 35785, 16207, 16208, 16209, 16210, 35786, 16212, 16214, 16215, 35787, 16217, 16218, 16219, 16221, 16223, 16224, 16225, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233, 16234, 16235, 16240, 16242, 16244, 16245, 16246, 35793, 16248, 35794, 16253, 16254, 16256, 16258, 16260, 16261, 16262, 16264, 16267, 16269, 16270, 16272, 16273, 16274, 16275, 16276, 16277, 16278, 16279, 35799, 16281, 16282, 16283, 16287, 35802, 16290, 16291, 16292, 16293, 16294, 35803, 16297, 16298, 16300, 16301, 16302, 16304, 16305, 16306, 16307, 16312, 16313, 16317, 16318, 16320, 16321, 35808, 16324, 16327, 16329, 16330, 16331, 16334, 16335, 16336, 16337, 16338, 16339, 16340, 16341, 16342, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351, 16352, 16354, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16365, 16367, 16368, 16369, 16370, 16371, 16373, 16374, 16375, 16376, 16379, 16380, 16381, 16382, 16383, 16384, 16385, 16386, 16387, 16388, 16389, 16390, 16391, 16392, 16393, 16394, 16395, 16397, 16399, 16400, 16401, 16402, 16403, 16404, 16406, 16407, 16409, 16410, 16411, 16412, 16414, 16415, 16416, 16418, 16420, 16421, 16422, 16423, 16424, 16425, 16427, 16429, 16431, 16432, 16434, 16435, 16436, 16437, 16438, 16439, 16440, 16441, 16442, 16443, 16444, 16446, 16447, 16449, 16450, 16452, 16453, 16455, 16456, 16457, 16458, 16459, 16460, 16461, 16462, 16464, 16465, 16466, 16467, 16468, 16470, 16471, 16472, 16475, 16477, 16478, 16480, 16481, 16483, 16484, 16485, 16486, 16488, 16489, 16490, 16491, 16492, 16493, 35843, 16498, 16499, 16501, 16502, 16503, 16507, 16508, 16510, 35846, 16512, 16513, 16515, 16516, 16517, 16518, 35847, 16521, 16522, 16524, 16525, 16526, 35849, 35850, 35852, 35855, 35856, 16715, 16718, 16720, 16721, 16722, 16724, 16728, 16729, 16730, 16731, 16733, 16737, 16738, 16739, 16745, 16746, 16747, 16748, 16749, 16750, 16752, 16753, 16756, 16757, 16758, 16761, 16762, 16763, 16764, 16770, 16771, 16772, 16773, 16774, 16775, 16776, 16777, 16778, 16779, 16780, 16781, 16783, 16784, 16785, 16788, 16790, 16791, 16793, 16795, 16796, 16799, 16801, 16802, 16803, 16804, 16806, 16807, 16808, 16812, 16813, 16814, 16816, 16817, 16819, 16820, 16821, 16822, 16823, 16824, 16825, 16826, 16829, 16830, 16831, 16834, 16835, 16838, 16839, 16840, 16843, 16844, 16846, 16849, 16850, 16851, 16853, 16854, 16855, 16856, 16857, 16859, 16862, 16863, 16867, 16868, 16869, 16870, 16871, 16872, 16874, 16875, 16876, 16877, 16879, 16880, 16882, 16883, 16885, 16886, 42458, 42466, 17328, 17329, 17330, 17332, 17333, 17337, 17338, 17339, 17340, 17341, 17342, 17343, 17344, 17346, 17347, 17348, 17349, 17351, 17352, 17353, 17356, 17358, 17359, 17360, 17361, 17362, 17365, 17367, 17368, 17369, 17372, 17373, 17374, 17376, 17377, 17380, 17381, 17383, 17384, 17385, 17386, 17387, 17388, 17389, 17392, 17394, 17396, 17398, 17399, 17403, 17404, 17405, 17406, 17409, 17410, 17411, 17413, 17416, 17417, 17420, 17423, 17424, 17426, 17427, 17428, 17429, 17430, 17431, 17432, 17433, 17434, 17435, 17436, 17440, 17441, 17442, 17443, 17444, 17445, 17446, 17487, 17488, 17491, 17493, 17494, 17497, 17500, 17502, 17503, 17506, 17507, 17510, 17512, 17515, 17517, 17519, 17522, 17523, 17524, 17525, 17526, 17527, 17529, 17534, 17537, 17538, 17539, 17541, 17542, 17545, 17546, 17549, 17550, 17551, 17719, 17720, 17721, 17727, 17733, 17734, 17737, 17741, 17742, 17743, 17746, 17748, 17754, 17759, 17762, 17765, 17848, 17849, 17854, 17855, 17858, 17861, 17867, 17869, 17875, 17876, 17877, 17881, 17882, 17885, 17887, 17888, 17889, 17892, 17897, 17900, 17904, 17916, 17917, 17920, 17921, 17923, 17924, 17928, 17929, 17930, 17932, 17934, 17935, 17938, 17940, 17941, 17942, 17948, 17951, 17952, 17953, 17955, 17956, 17957, 17959, 17960, 17961, 17965, 17966, 17967, 17969, 17971, 17972, 17973, 17975, 17977, 17978, 17981, 17982, 17983, 17985, 17986, 17987, 17988, 17990, 17991, 17997, 18002, 18003, 18004, 18006, 18008, 18010, 18011, 18012, 18013, 18014, 18017, 18018, 18019, 18020, 18021, 18022, 18023, 18024, 18025, 18026, 18027, 18028, 18030, 18031, 18032, 18033, 18035, 18037, 18038, 18040, 18041, 18042, 18043, 18046, 18047, 18048, 18049, 18052, 18055, 18057, 18060, 18067, 18070, 18072, 18074, 18075, 18076, 18077, 18078, 18079, 18083, 18086, 18087, 18091, 18098, 18100, 18102, 18105, 18106, 18107, 18111, 18112, 18114, 18116, 18118, 18119, 18121, 18122, 18124, 18125, 18128, 18129, 18131, 18133, 18134, 18135, 18136, 18138, 18146, 18147, 18148, 18149, 18154, 18162, 18166, 18167, 18168, 18169, 36175, 36176, 18178, 18182, 18184, 18188, 18189, 18190, 18196, 36181, 18198, 18200, 18201, 36182, 18209, 18210, 36184, 18212, 18215, 18218, 18224, 18225, 18229, 18237, 18246, 18247, 18256, 18271, 18272, 18274, 18326, 18330, 18333, 18337, 18343, 18347, 18352, 18361, 18371, 18377, 18381, 18386, 18388, 18390, 18391, 18392, 18393, 18406, 18407, 18410, 18413, 18415, 18419, 18420, 18422, 18424, 18425, 18427, 18428, 18429, 18432, 18433, 18437, 18438, 18440, 18442, 18445, 18449, 18453, 18454, 18455, 18456, 18459, 18461, 18462, 18463, 18465, 18468, 18470, 18475, 18476, 18477, 18479, 18480, 18483, 18484, 18489, 18490, 18493, 18494, 18496, 18497, 18498, 18499, 18500, 18501, 18502, 18503, 18507, 18512, 18514, 18515, 18516, 18518, 18519, 18520, 18523, 18524, 18525, 18526, 18527, 18529, 18531, 18532, 18533, 18534, 18535, 18536, 18537, 18539, 18540, 18541, 18542, 18543, 18544, 18546, 18549, 18551, 18552, 18553, 18557, 18563, 18564, 18566, 18567, 18569, 18570, 18575, 18578, 18579, 18581, 18583, 18585, 18587, 18588, 18589, 18590, 18591, 18592, 18593, 18594, 18595, 18596, 18598, 18599, 18600, 18602, 18603, 18604, 18605, 18606, 18607, 18611, 18613, 18617, 18618, 18620, 18623, 18624, 18626, 18627, 18628, 18630, 18632, 18634, 18641, 18643, 18644, 18646, 18650, 18652, 18653, 18656, 18660, 18661, 18662, 18663, 18664, 18665, 18670, 18672, 18675, 18676, 18680, 18681, 18682, 18684, 18686, 18687, 18699, 18706, 18713, 18718, 18795, 18802, 18810, 18811, 18812, 18815, 18816, 18820, 18823, 18826, 18828, 18830, 18833, 18835, 18838, 18839, 18841, 18842, 18843, 18844, 18847, 18849, 18850, 18851, 18854, 18855, 18858, 18867, 18869, 18871, 18872, 18874, 18878, 18879, 18881, 18883, 18887, 18888, 18889, 18890, 18892, 18893, 18894, 18895, 18899, 18900, 18901, 18902, 18903, 18904, 18905, 18906, 18907, 18908, 18910, 18911, 18912, 18913, 18914, 18918, 18919, 18921, 18923, 18924, 18925, 18927, 18929, 18930, 18931, 18933, 18935, 18938, 18940, 18942, 18943, 18946, 18948, 18949, 18951, 18952, 18955, 18957, 18958, 18961, 18963, 18964, 18965, 18967, 18970, 18971, 18973, 18976, 18980, 18982, 18986, 18987, 18990, 18991, 18992, 18993, 18994, 18997, 18998, 19000, 19002, 19003, 19004, 19005, 19007, 19008, 19009, 19011, 19016, 19017, 19020, 19022, 19024, 19026, 19027, 19028, 19029, 19030, 19033, 19036, 19037, 19038, 19039, 19042, 19043, 19045, 19049, 19050, 19053, 19055, 19056, 19057, 19058, 19061, 19062, 19065, 19066, 19069, 19070, 19072, 19074, 19075, 19079, 19080, 19082, 19084, 19087, 19089, 19090, 19091, 19092, 19093, 19094, 19096, 19099, 19100, 19101, 19105, 19106, 19107, 19109, 19110, 19111, 19112, 19113, 19115, 19117, 19120, 19123, 19125, 19126, 19128, 19129, 19131, 19133, 19134, 19136, 19137, 19139, 19141, 19143, 19145, 19147, 19148, 19149, 19150, 19153, 19154, 19155, 19156, 19157, 19158, 19159, 19160, 19162, 19163, 19165, 19166, 19208, 19210, 19211, 19215, 19217, 19218, 19219, 19221, 19222, 19223, 19224, 19226, 19227, 19228, 19230, 19231, 19232, 19234, 19235, 19237, 19238, 19239, 19240, 19243, 19244, 19246, 19247, 19248, 19249, 19250, 19255, 19257, 19260, 19261, 19262, 19263, 19265, 19266, 19267, 19270, 19273, 19274, 19275, 19277, 19278, 19279, 19280, 19283, 19284, 19285, 19286, 19290, 19293, 19294, 19295, 19296, 19297, 19300, 19301, 19302, 19303, 19305, 19306, 19311, 19329, 19468, 19470, 19475, 19478, 19480, 19487, 19490, 19497, 19499, 19502, 19503, 19506, 19507, 19508, 19509, 19521, 19524, 19528, 19529, 19531, 19532, 19534, 19539, 19546, 19548, 19549, 19554, 19556, 19558, 19561, 19562, 19563, 19572, 19573, 19575, 19576, 19581, 19582, 19584, 19586, 19592, 19598, 19600, 19604, 19609, 19614, 19615, 19619, 19620, 19624, 19627, 19629, 19630, 19632, 19633, 19642, 19644, 19646, 19648, 19649, 19656, 19657, 19661, 19663, 19669, 19670, 19672, 19673, 19675, 19676, 19681, 19682, 19685, 19686, 19693, 19695, 19697, 19699, 19700, 19701, 19702, 19703, 19706, 19707, 19708, 19709, 19710, 19712, 19713, 19717, 19718, 19720, 19721, 19722, 19724, 19725, 19729, 19730, 19733, 19734, 19735, 19736, 19737, 19739, 19740, 19742, 19744, 19747, 19749, 19752, 19753, 19754, 19758, 19759, 19760, 19761, 19764, 19765, 19766, 19769, 19771, 19772, 19773, 19775, 19778, 19779, 19780, 19781, 19783, 19784, 19785, 19787, 19788, 19792, 19793, 19795, 19796, 19798, 19799, 19800, 19802, 19807, 19808, 19810, 19812, 19813, 19814, 19815, 19816, 19818, 19821, 19824, 19825, 19826, 19827, 19828, 19830, 19838, 19839, 19846, 19854, 19856, 19857, 19858, 19859, 19860, 19861, 19862, 19865, 19866, 19868, 19870, 19872, 19876, 19879, 19880, 19882, 19883, 19884, 19887, 19890, 19891, 19892, 19893, 19894, 19899, 19900, 19912, 19913, 19918, 19919, 19924, 19926, 19927, 19928, 19930, 19935, 19951, 19952, 20061, 20062, 20064, 20065, 43066, 20072, 20074, 20075, 20076, 20078, 20084, 20089, 20091, 20094, 20098, 20104, 20105, 20106, 20107, 20108, 20110, 20111, 20112, 20113, 20114, 20115, 20116, 20117, 20118, 20119, 20122, 20123, 20124, 20126, 20128, 20129, 20130, 20133, 20137, 20138, 20139, 20144, 20147, 20149, 20150, 20152, 20153, 20154, 20159, 20160, 20162, 20163, 20164, 20165, 20167, 20169, 20170, 20171, 20174, 20175, 20176, 20178, 20179, 20180, 20181, 20189, 20190, 20192, 20195, 20197, 20198, 20201, 20202, 20204, 20208, 20209, 20211, 20212, 20219, 20222, 20223, 20224, 20225, 20227, 20228, 20229, 20230, 20231, 20233, 20234, 20235, 20237, 20238, 20239, 20240, 20245, 20246, 20247, 20248, 20249, 20251, 20252, 20253, 20254, 20255, 20257, 20259, 20260, 20262, 20265, 20268, 20270, 20272, 20273, 20274, 20276, 20283, 20284, 20285, 20286, 20287, 20288, 20289, 20293, 20294, 20296, 20297, 20299, 20301, 20304, 20305, 20306, 20309, 20311, 20313, 20315, 20317, 20318, 20319, 20320, 20322, 20324, 20325, 20326, 20329, 20330, 20333, 20334, 20335, 20336, 20337, 20338, 20339, 20341, 20344, 20345, 20346, 20347, 20349, 20350, 20351, 20352, 20353, 20354, 20355, 20356, 20357, 20359, 20360, 20362, 20363, 20365, 20366, 20367, 20368, 20371, 20374, 20375, 20377, 20378, 20380, 20381, 20382, 20384, 20385, 20386, 20389, 20390, 20392, 20395, 20396, 20400, 20402, 20403, 20404, 20407, 20408, 20409, 20410, 20411, 20412, 20415, 20417, 20419, 20420, 20424, 20426, 20428, 20429, 20430, 20431, 20434, 20438, 20439, 20440, 20445, 20447, 20449, 20451, 20452, 20458, 20459, 20460, 20462, 20463, 20464, 20465, 20466, 20472, 20473, 20475, 20476, 20477, 20478, 20480, 20481, 20483, 20484, 20485, 20487, 20488, 20489, 20490, 20492, 20496, 20497, 20498, 20499, 20500, 20507, 20508, 20509, 20511, 20512, 20513, 20514, 20515, 20516, 20517, 20519, 20520, 20521, 20523, 20524, 20525, 20526, 20527, 20528, 20532, 20533, 20534, 20536, 20537, 20539, 20540, 20544, 20545, 20547, 20549, 20551, 20552, 20554, 20556, 20558, 20559, 20561, 20562, 20563, 20564, 20566, 20567, 20568, 20569, 20571, 20572, 20573, 20574, 20575, 20577, 20579, 20581, 20582, 20583, 20584, 20585, 20591, 20592, 20593, 20597, 20598, 20599, 20601, 20602, 20605, 20606, 20607, 20608, 20609, 20613, 20614, 20621, 20625, 20627, 20630, 20632, 20633, 20634, 20635, 20637, 20640, 20642, 20645, 20649, 20805, 20814, 20816, 20827, 20888, 20893, 20937, 20994, 21039, 21086, 21108, 21127, 21140, 21157, 21227, 21238, 21279, 21351, 21368, 21388, 21409, 21434, 21451, 21452, 21456, 21459, 21460, 21461, 21462, 21463, 21464, 21465, 21466, 21468, 21469, 21471, 21472, 21475, 21477, 21482, 21484, 21486, 21487, 21488, 21490, 21491, 21492, 21494, 21495, 21497, 21500, 21501, 21502, 21503, 21504, 21506, 21507, 21508, 21509, 21510, 21512, 21513, 21514, 21515, 21516, 21517, 21519, 21520, 21522, 21525, 21526, 21528, 21529, 21530, 21532, 21538, 21539, 21540, 21541, 21542, 21543, 21544, 21545, 21546, 21547, 21548, 21550, 21554, 21555, 21561, 21562, 21563, 21564, 21566, 21568, 21569, 21570, 21571, 21572, 21573, 21574, 21577, 21578, 21579, 21580, 21583, 21584, 21585, 21586, 21587, 21588, 21590, 21591, 21594, 21597, 21598, 21599, 21600, 21601, 21602, 21603, 21608, 21609, 21610, 21611, 21612, 21613, 21614, 21616, 21617, 21618, 21620, 21621, 21624, 21625, 21626, 21629, 21630, 21631, 21634, 21637, 21639, 21640, 21641, 21642, 21643, 21644, 21647, 21648, 21651, 21653, 21654, 21655, 21658, 21659, 21660, 21661, 21663, 21664, 21667, 21668, 21669, 21670, 21671, 21672, 21674, 21677, 21678, 21679, 21680, 21681, 21682, 21683, 21684, 21686, 21687, 21688, 21690, 21693, 21694, 21696, 21697, 21698, 21700, 21702, 21703, 21704, 21706, 21707, 21709, 21710, 21711, 21713, 21716, 21718, 21720, 21725, 21726, 21727, 21729, 21730, 21735, 21737, 21738, 21739, 21740, 21742, 21743, 21744, 21745, 21747, 21748, 21750, 21752, 21754, 21755, 21757, 21758, 21759, 21760, 21761, 21762, 21763, 21765, 21766, 21767, 21769, 21771, 21773, 21774, 21775, 21776, 21779, 21781, 21782, 21784, 21785, 21786, 21787, 21788, 21789, 21790, 21791, 21793, 21794, 21797, 21799, 21800, 21802, 21803, 21804, 21805, 21806, 21807, 21808, 21813, 21814, 21818, 21819, 21820, 21822, 21823, 21825, 21829, 21831, 21832, 21834, 21835, 21836, 21837, 21838, 21839, 21842, 21846, 21851, 21853, 21854, 21855, 21856, 21858, 21860, 21861, 21862, 21863, 21864, 21865, 21866, 21869, 21870, 21871, 21872, 21873, 21874, 21875, 21876, 21877, 21879, 21881, 21883, 21884, 21885, 21887, 21889, 21890, 21891, 21892, 21893, 21896, 21898, 21900, 21903, 21904, 21905, 21906, 21908, 21911, 21914, 21915, 21916, 21917, 21918, 21919, 21920, 21921, 21922, 21923, 21925, 21926, 21929, 21930, 21932, 21934, 21935, 21936, 21937, 21938, 21939, 21940, 21942, 21943, 21944, 21945, 21946, 21947, 21948, 21949, 21950, 21951, 21953, 21955, 21957, 21958, 21959, 21962, 21963, 21965, 21967, 21971, 21972, 21975, 21978, 21980, 21981, 21983, 21985, 21986, 21988, 21989, 21990, 21991, 21993, 21995, 21996, 21997, 22000, 22001, 22002, 22003, 22004, 22006, 22008, 22009, 22011, 22012, 22016, 22019, 22020, 22021, 22022, 22023, 22024, 22025, 22026, 22027, 22028, 22030, 22031, 22032, 22034, 22035, 22038, 22039, 22042, 22043, 22045, 22048, 22050, 22052, 22054, 22057, 22058, 22060, 22061, 22062, 22063, 22064, 22066, 22067, 22068, 22069, 22070, 22071, 22072, 22074, 22077, 22078, 22081, 22082, 22084, 22085, 22086, 22088, 22089, 22090, 22093, 22094, 22095, 22097, 22098, 22099, 22104, 22105, 22108, 22109, 22110, 22111, 22113, 22117, 22118, 22120, 22121, 22125, 22126, 22127, 22128, 22129, 22130, 22134, 22135, 22137, 22138, 22139, 22140, 22142, 22143, 22147, 22149, 22150, 22151, 22154, 22155, 22156, 22158, 22160, 22163, 22164, 22168, 22171, 22172, 22173, 22174, 22176, 22180, 22181, 22182, 22183, 22184, 22186, 22187, 22189, 22191, 22193, 22195, 22196, 22197, 22198, 22199, 22200, 22201, 22202, 22203, 22205, 22206, 22208, 22209, 22210, 22211, 22212, 22214, 22216, 22217, 22218, 22220, 22222, 22223, 22224, 22225, 22227, 22228, 22229, 22230, 22231, 22232, 22233, 22235, 22236, 22237, 22239, 22243, 22244, 22245, 22246, 22248, 22249, 22251, 22253, 22254, 22255, 22256, 22258, 22260, 22261, 22262, 22263, 22266, 22267, 22269, 22271, 22272, 22273, 22275, 22280, 22281, 22284, 22285, 22286, 22287, 22289, 22290, 22291, 22292, 22293, 22295, 22296, 22297, 22304, 23109, 23110, 23111, 23112, 23113, 23114, 23115, 23118, 23120, 23121, 23123, 23124, 23127, 23129, 23132, 23133, 23135, 23137, 23139, 23142, 23143, 23146, 23147, 23148, 23149, 23150, 23151, 23152, 23153, 23155, 23156, 23157, 23158, 23160, 23162, 23163, 23164, 23167, 23170, 23172, 23173, 23174, 23176, 23178, 23179, 23180, 23182, 23184, 23185, 23187, 23188, 23189, 23190, 23192, 23193, 23194, 23195, 23196, 23197, 23198, 23199, 23200, 23201, 23202, 23203, 23205, 23209, 23210, 23211, 23212, 23215, 23216, 23217, 23219, 23220, 23221, 23222, 23223, 23224, 23226, 23227, 23229, 23230, 23231, 23234, 23235, 23236, 23237, 23238, 23240, 23241, 23244, 23247, 23250, 23253, 23254, 23255, 23256, 23257, 23258, 23259, 23261, 23262, 23265, 23266, 23267, 23268, 23269, 23270, 23272, 23273, 23274, 23276, 23277, 23278, 23279, 23281, 23282, 23283, 23285, 23290, 23291, 23293, 23294, 23297, 23299, 23300, 23301, 23302, 23303, 23304, 23305, 23306, 23307, 23308, 23309, 23310, 23312, 23314, 23315, 23316, 23317, 23318, 23319, 23322, 23323, 23324, 23325, 23326, 23327, 23328, 23330, 23332, 23333, 23336, 23337, 23338, 23340, 23341, 23343, 23344, 23345, 23346, 23349, 23351, 23352, 23354, 23355, 23359, 23360, 23361, 23362, 23363, 23364, 23366, 23368, 23369, 23370, 23373, 23374, 23375, 23377, 23378, 23379, 23380, 23381, 23384, 23386, 23387, 23388, 23389, 23390, 23391, 23396, 23397, 23398, 23399, 23400, 23401, 23402, 23406, 23407, 23408, 23409, 23412, 23414, 23415, 23416, 23418, 23419, 23420, 23421, 23422, 23423, 23424, 23425, 23426, 23427, 23428, 23429, 23430, 23431, 23433, 23436, 23438, 23439, 23440, 23442, 23443, 23445, 23447, 23448, 23449, 23450, 23452, 23453, 23454, 23455, 23456, 23457, 23459, 23460, 23461, 23462, 23463, 23465, 23467, 23468, 23470, 23474, 23475, 23478, 23479, 23480, 23481, 23482, 23483, 23484, 23485, 23487, 23488, 23489, 23493, 23494, 23495, 23496, 23497, 23498, 23499, 23502, 23503, 23504, 23505, 23507, 23508, 23509, 23511, 23514, 23516, 23517, 23518, 23519, 23521, 23523, 23525, 23527, 23528, 23529, 23530, 23531, 23532, 23533, 23534, 23535, 23536, 23537, 23538, 23539, 23540, 23541, 23543, 23546, 23547, 23548, 23549, 23551, 23553, 23554, 23555, 23556, 23557, 23558, 23559, 23560, 23561, 23563, 23564, 23566, 23568, 23569, 23570, 23571, 23573, 23574, 23575, 23576, 23577, 23579, 23580, 23583, 23584, 23586, 23587, 23589, 23591, 23592, 23596, 23598, 23602, 23603, 23604, 23605, 23606, 23610, 23615, 23616, 23618, 23619, 23620, 23621, 23622, 23623, 23624, 23626, 23629, 23631, 23632, 23633, 23634, 23638, 23639, 23640, 23641, 23644, 23645, 23648, 23649, 23650, 23651, 23652, 23654, 23656, 23657, 23658, 23660, 23664, 23665, 23666, 23667, 23671, 23672, 23673, 23674, 23675, 23678, 23679, 23681, 23684, 23685, 23686, 23687, 23688, 23689, 23692, 23693, 23694, 23696, 23697, 23698, 23701, 23703, 23704, 23705, 23706, 23707, 23709, 23712, 23713, 23714, 23715, 23716, 23719, 23720, 23721, 23722, 23723, 23725, 23727, 23728, 23733, 23734, 23737, 23738, 23742, 23743, 23745, 23748, 23749, 23750, 23751, 23753, 23754, 23755, 23760, 23763, 23768, 23769, 23770, 23777, 23778, 23780, 23783, 23789, 23790, 23791, 23792, 23793, 23794, 23795, 23798, 23799, 23802, 23804, 23805, 23806, 23809, 23810, 23811, 23814, 23816, 23821, 23823, 23825, 23827, 23828, 23831, 23832, 23835, 23836, 23837, 23838, 23839, 23840, 23842, 23844, 23845, 23846, 23847, 23848, 23851, 23852, 23853, 23854, 23855, 23856, 23857, 23859, 23860, 23861, 23862, 23863, 23864, 23865, 23867, 23868, 23869, 23870, 23871, 23872, 23873, 23874, 23875, 23877, 23879, 23884, 23885, 23886, 23887, 23888, 23892, 23894, 23895, 23898, 23899, 23900, 23901, 23902, 23903, 23904, 23905, 23907, 23908, 23909, 23911, 23912, 23913, 23915, 23916, 23917, 23921, 23922, 23923, 23924, 23926, 23927, 23929, 23930, 23933, 23934, 23935, 23936, 23937, 23939, 23941, 23943, 23945, 23946, 23952, 23955, 23957, 23958, 23959, 23960, 23962, 23964, 23969, 23970, 23972, 23974, 23976, 23978, 23980, 23981, 37331, 23983, 23984, 23987, 23989, 23992, 23995, 23996, 23998, 24000, 24001, 24002, 24003, 24005, 24006, 24007, 24008, 24010, 24012, 24013, 24014, 24017, 24020, 24021, 37424, 37428, 37431, 37498, 24823, 24824, 24825, 24826, 37499, 24830, 24831, 37500, 24834, 24836, 24837, 37501, 24844, 24846, 24847, 24848, 24850, 24851, 24852, 24853, 24854, 24855, 24856, 24857, 24858, 24859, 24863, 24866, 24867, 24869, 24871, 24872, 24873, 24876, 24878, 24879, 24880, 24881, 24882, 24883, 24884, 24885, 24886, 37509, 37510, 37511, 24892, 24893, 24894, 24896, 24898, 24900, 24901, 24902, 37514, 24904, 24909, 24912, 24915, 24916, 24918, 24919, 24921, 24922, 24923, 24927, 24928, 24930, 24932, 24933, 24934, 24935, 24936, 24937, 24938, 24941, 24943, 24944, 24945, 24946, 24947, 24948, 37523, 24950, 24951, 24952, 24953, 37524, 24956, 24959, 24960, 24961, 24962, 24965, 24967, 24968, 24969, 24970, 24972, 24973, 24974, 24975, 24976, 24977, 37533, 37535, 37536, 25019, 25020, 25021, 25022, 25023, 25024, 25025, 25026, 25028, 25029, 25030, 25031, 25032, 25037, 25038, 25039, 25040, 25041, 25042, 25045, 25046, 25048, 25049, 25051, 25052, 25053, 25054, 25055, 25058, 25059, 25060, 25062, 25063, 25064, 25067, 25068, 25069, 25070, 25073, 25074, 25075, 25076, 25077, 25080, 25081, 25082, 25084, 25087, 25089, 25090, 25091, 25092, 25094, 25095, 25096, 25097, 25098, 25100, 25101, 25103, 25105, 25108, 25109, 25110, 25111, 25114, 25115, 25116, 25117, 25120, 25121, 25122, 25123, 25124, 25128, 25130, 25132, 25134, 25135, 25140, 25143, 25144, 25146, 25147, 25151, 25152, 25153, 25154, 25156, 25157, 25160, 25162, 25163, 25165, 25166, 25167, 25168, 25169, 25170, 25172, 25173, 25174, 25175, 25177, 25178, 25179, 25180, 25182, 25184, 25187, 25188, 25189, 25192, 25193, 25195, 25196, 25198, 25199, 25200, 25201, 25202, 25203, 25204, 25205, 25209, 25212, 25214, 25215, 25218, 25219, 25222, 25224, 25225, 25226, 25227, 25229, 25230, 25233, 25234, 25236, 25237, 25239, 25241, 25242, 25243, 25244, 25246, 25247, 25248, 25249, 25250, 25251, 25253, 25254, 25256, 25257, 25259, 25260, 25263, 25264, 25265, 25266, 25270, 25271, 25272, 25273, 25274, 25275, 25276, 25277, 25279, 25281, 25282, 25285, 25287, 25291, 25293, 25295, 25297, 25300, 25301, 25302, 25304, 25305, 25309, 25310, 25313, 25314, 25315, 25316, 25317, 25318, 25320, 25322, 25325, 25327, 25328, 25329, 25330, 25331, 25333, 25334, 25335, 25337, 25338, 25340, 25342, 25343, 25344, 25345, 25346, 25348, 25349, 25350, 25351, 25353, 25354, 25355, 25358, 25361, 25362, 25364, 25366, 25367, 25368, 25369, 25371, 25372, 25375, 25376, 25378, 25379, 25381, 25382, 25383, 25384, 25385, 25386, 25387, 25388, 25390, 25391, 25392, 25395, 25397, 25398, 25399, 25402, 25403, 25408, 25409, 25411, 25413, 25414, 25415, 25416, 25418, 25420, 25421, 25422, 25424, 25425, 25426, 25427, 25429, 25430, 25431, 25433, 25435, 25436, 25437, 25438, 25439, 25440, 25441, 25443, 25447, 25448, 25450, 25454, 25455, 25459, 25460, 25461, 25464, 25465, 25466, 25467, 25470, 25472, 25473, 25479, 25489, 25496, 25498, 26288, 26289, 26290, 26291, 26293, 26294, 26295, 26296, 26298, 26299, 26301, 26303, 26304, 26306, 26308, 26309, 26311, 26313, 26314, 26315, 26317, 26319, 26320, 26321, 26322, 26325, 26326, 26327, 26328, 26329, 26330, 26331, 26332, 26333, 26335, 26337, 26338, 26341, 26343, 26344, 26345, 26349, 26350, 26351, 26354, 26357, 26358, 26359, 26361, 26362, 26363, 26365, 26367, 26368, 26369, 26370, 26371, 26373, 26375, 26376, 26377, 26378, 26381, 26382, 26383, 26384, 26385, 26387, 26389, 26390, 26391, 26392, 26393, 26394, 26395, 26396, 26397, 26399, 26402, 26403, 26405, 26406, 26407, 26410, 26411, 26413, 26414, 26415, 26416, 26417, 26418, 26420, 26423, 26426, 26427, 26428, 26429, 26433, 26436, 26438, 26444, 26445, 26446, 26449, 26450, 26451, 26452, 26453, 26454, 26457, 26458, 26459, 26460, 26461, 26464, 26465, 26467, 26468, 26469, 26473, 26474, 26475, 26478, 26479, 26480, 26482, 26483, 26487, 26488, 26489, 26490, 26494, 26496, 26497, 26499, 26501, 26502, 26503, 26504, 26505, 26506, 26508, 26509, 26511, 26512, 26513, 26514, 26515, 26516, 26517, 26518, 26519, 26522, 26523, 26524, 26526, 26528, 26529, 26530, 26531, 26532, 26533, 26535, 26536, 26539, 26540, 26541, 26542, 26543, 26545, 26546, 26548, 26549, 26550, 26553, 26554, 26555, 26556, 26557, 26559, 26561, 26563, 26564, 26565, 26567, 26572, 26573, 26574, 26575, 26576, 26580, 26581, 26584, 26585, 26588, 26589, 26591, 26595, 26600, 26601, 26602, 26603, 26606, 26607, 26608, 26609, 26610, 26611, 26612, 26613, 26614, 26616, 26618, 26619, 26620, 26625, 26626, 26627, 26628, 26630, 26633, 26635, 26636, 26637, 26638, 26639, 26640, 26644, 26645, 26646, 26649, 26651, 26652, 26653, 26656, 26657, 26658, 26659, 26660, 26661, 26664, 26665, 26666, 26667, 26670, 26672, 26673, 26676, 26677, 26678, 26679, 26680, 26681, 26682, 26683, 26684, 26685, 26688, 26689, 26690, 26691, 26692, 26694, 26695, 26698, 26699, 26701, 26703, 26704, 26705, 26706, 26707, 26708, 26709, 26710, 26711, 26712, 26713, 26714, 26715, 26716, 26717, 26722, 26723, 26724, 26725, 26727, 26728, 26729, 26730, 26731, 26732, 26733, 26734, 26735, 26738, 26739, 26740, 26741, 26742, 26743, 26744, 26746, 26747, 26748, 26749, 26750, 26752, 26754, 26756, 26757, 26758, 26759, 26760, 26762, 26765, 26766, 26767, 26769, 26770, 26771, 26772, 26774, 26776, 26819, 26820, 26823, 26830, 26833, 26835, 26836, 26837, 26841, 26843, 26844, 26845, 26846, 26847, 26848, 26849, 26850, 26852, 26853, 26854, 26855, 26856, 26858, 26859, 26860, 26861, 26865, 26871, 26872, 26873, 26877, 26879, 26880, 26881, 26882, 26883, 26886, 26887, 26888, 26889, 26890, 26893, 26894, 26895, 26896, 26897, 26898, 26899, 26900, 26903, 26904, 26905, 26906, 26907, 26908, 26910, 26911, 26912, 26913, 26915, 26916, 26917, 26919, 26920, 26922, 26923, 26924, 26925, 26929, 26930, 26932, 26935, 26936, 26937, 26938, 26939, 26940, 26941, 26942, 26944, 26946, 26948, 26949, 26950, 26951, 26952, 26953, 26954, 26955, 26956, 26958, 26963, 26966, 26967, 26969, 26971, 26972, 26974, 26975, 26978, 26979, 26980, 26981, 26983, 26985, 26986, 26987, 26989, 26990, 26993, 26994, 26996, 26997, 26998, 26999, 27001, 27003, 27004, 27010, 27011, 27012, 27013, 27017, 27018, 27019, 27020, 27021, 27022, 27023, 27024, 27025, 27027, 27028, 27029, 27030, 27031, 27826, 27827, 27828, 27832, 27833, 27834, 27837, 27838, 27841, 27842, 27845, 27846, 27847, 27849, 27851, 27853, 27854, 27855, 27856, 27857, 27858, 27859, 27861, 27865, 27868, 27869, 27870, 27873, 27874, 27878, 27879, 27880, 27882, 27883, 27885, 27887, 27888, 27889, 27890, 27891, 27893, 27894, 27895, 27900, 27901, 27904, 27905, 27910, 27911, 27912, 27913, 27915, 27916, 27918, 27920, 27923, 27924, 27926, 27927, 27928, 27929, 27930, 27931, 27933, 27934, 27935, 27936, 27937, 27939, 27940, 27941, 27942, 27943, 27944, 27945, 27946, 27948, 27950, 27951, 27953, 27954, 27956, 27957, 27959, 27960, 27961, 27962, 27965, 27967, 27968, 27970, 27972, 27973, 27975, 27976, 27978, 27979, 27980, 27981, 27983, 27984, 27988, 27989, 27990, 27993, 27994, 27995, 27996, 27997, 27999, 28000, 28001, 28002, 28004, 28006, 28012, 28013, 28014, 28015, 28016, 28018, 28019, 28024, 28025, 28026, 28027, 28029, 28030, 28031, 28032, 28033, 28034, 28036, 28038, 28039, 28040, 28041, 28042, 28043, 28044, 28045, 28046, 28048, 28049, 28050, 28052, 28053, 28054, 28056, 28057, 28058, 28062, 28065, 28067, 28068, 28073, 28075, 28080, 28082, 28084, 28085, 28086, 28095, 28096, 28097, 28098, 28100, 28101, 28102, 28106, 28108, 28110, 28112, 28114, 28115, 28117, 28119, 28121, 28122, 28123, 28124, 28126, 28127, 28128, 28129, 28133, 28134, 28136, 28138, 28141, 28143, 28145, 28146, 28147, 28148, 28149, 28150, 28151, 28152, 28155, 28156, 28158, 28160, 28162, 28165, 28169, 28172, 28173, 28176, 28177, 28178, 28179, 28180, 28181, 28183, 28185, 28190, 28192, 28193, 28194, 28195, 28198, 28203, 28204, 28205, 28206, 28208, 28209, 28210, 28211, 28212, 28215, 28216, 28218, 28220, 28221, 28222, 28223, 28224, 28227, 28229, 28232, 28233, 28234, 28235, 28236, 28237, 28238, 28240, 28242, 28243, 28247, 28248, 28249, 28252, 28253, 28254, 28257, 28260, 28263, 28265, 28267, 28268, 28269, 28271, 28272, 28273, 28274, 28275, 28276, 28280, 28281, 28282, 28283, 28289, 28291, 28293, 28294, 28296, 28301, 28302, 28303, 28305, 28307, 28308, 28309, 28312, 28317, 28319, 28321, 28322, 28324, 28325, 28327, 28328, 28329, 28333, 28334, 28338, 28344, 28345, 28347, 28348, 28349, 28350, 28351, 28352, 28354, 28357, 28359, 28360, 28361, 28364, 28365, 28366, 28367, 28369, 28373, 28374, 28375, 28377, 28379, 28380, 28381, 28384, 28387, 28388, 28389, 28394, 28395, 28397, 28398, 28399, 28402, 28403, 28405, 28406, 28408, 28409, 28410, 28412, 28414, 28415, 28417, 28420, 28422, 28423, 28427, 28428, 28429, 28432, 28433, 28435, 28436, 28437, 28438, 28439, 28440, 28441, 28444, 28445, 28447, 28448, 28449, 28450, 28451, 28452, 28455, 28456, 28457, 28458, 28460, 28461, 28462, 28464, 28466, 28467, 28470, 28471, 28472, 28473, 28475, 28476, 28477, 28478, 28479, 28482, 28484, 28485, 28486, 28488, 28490, 28492, 28495, 28496, 28497, 28498, 28500, 28503, 28504, 28505, 28507, 28508, 28510, 28512, 28513, 28514, 28515, 28516, 28518, 28519, 28520, 28523, 28524, 28525, 28526, 28527, 28528, 28529, 28530, 28531, 28532, 28533, 28534, 28536, 28537, 28538, 28539, 28542, 28543, 28545, 28546, 28547, 28549, 28551, 28557, 28558, 28563, 28564, 28565, 28570, 28572, 28573, 28575, 28576, 28577, 28578, 28581, 28584, 28587, 28590, 28592, 28593, 28594, 28597, 28599, 28600, 28601, 28602, 28603, 28604, 28605, 28606, 28607, 28608, 28609, 28611, 28614, 28615, 28618, 28619, 28620, 28622, 28623, 28624, 28626, 28627, 28628, 28629, 28630, 28631, 28632, 28633, 28635, 28640, 28642, 28643, 28644, 28645, 28646, 28647, 28648, 28649, 28650, 28653, 28654, 28655, 28656, 28657, 28658, 28659, 28660, 28661, 28662, 28667, 28669, 28670, 28672, 28673, 28675, 28676, 28677, 28678, 28679, 28683, 28689, 28693, 28694, 28878, 28880, 28881, 28883, 28884, 28885, 28886, 28888, 28889, 28890, 28891, 28892, 28893, 28894, 28895, 28896, 28897, 28899, 28901, 28902, 28903, 28904, 28985, 28986, 28987, 28988, 28990, 28992, 28993, 28995, 28996, 28997, 28999, 29000, 29002, 29004, 29005, 29006, 29007, 29008, 29009, 29011, 29013, 29014, 29015, 29016, 29017, 29019, 29020, 29021, 29022, 29023, 29025, 29028, 29029, 29030, 29032, 29033, 29034, 29038, 29039, 29040, 29043, 29044, 29045, 29046, 29047, 29048, 29049, 29051, 29052, 29053, 29057, 29058, 29062, 29063, 29065, 29066, 29067, 29069, 29070, 29072, 29074, 29075, 29076, 29077, 29079, 29080, 29081, 29083, 29084, 29086, 29087, 29088, 29091, 29092, 29093, 29095, 29096, 29098, 29101, 29102, 29103, 29104, 29107, 29109, 29110, 29111, 29112, 29114, 29115, 29118, 29119, 29120, 29121, 29122, 29123, 29125, 29132, 29133, 29134, 29135, 29136, 29139, 29140, 29142, 29143, 29144, 29145, 29148, 29150, 29152, 29153, 29155, 29157, 29158, 29159, 29160, 29161, 29162, 29164, 29165, 29167, 29168, 29169, 29170, 29171, 29172, 29174, 29175, 29176, 29177, 29178, 29179, 29182, 29185, 29188, 29189, 29190, 29191, 29192, 29196, 29199, 29201, 29202, 29203, 29205, 29206, 29207, 29208, 29213, 29215, 29217, 29218, 29219, 29220, 29222, 29224, 29225, 29226, 29230, 29233, 29234, 29235, 29239, 29241, 29245, 29246, 29247, 29251, 29252, 29253, 29255, 29257, 29258, 29259, 29260, 29261, 29263, 29264, 29265, 29268, 29271, 29274, 29277, 29278, 29281, 29283, 29284, 29286, 29289, 29292, 29293, 29295, 29297, 29300, 29301, 29302, 29303, 29305, 29309, 29310, 29311, 29312, 29313, 29314, 29315, 29316, 29319, 29320, 29323, 29324, 29325, 29327, 29328, 29329, 29330, 29331, 29333, 29335, 29338, 29339, 29340, 29341, 29343, 29347, 29348, 29349, 29350, 29351, 29353, 29354, 29356, 29357, 29358, 29360, 29361, 29362, 29363, 29407, 29408, 29409, 29411, 29412, 29413, 29414, 29416, 29421, 29423, 29424, 29427, 29430, 29431, 29437, 29438, 29439, 29440, 29441, 29442, 29443, 29444, 29445, 29446, 29448, 29449, 29450, 29453, 29454, 29456, 29457, 29458, 29461, 29462, 29464, 29466, 29467, 29469, 29470, 29471, 29472, 29473, 29475, 29476, 29478, 29482, 29483, 29485, 29487, 29489, 29491, 29493, 29495, 29496, 29497, 29498, 29499, 29500, 29501, 29502, 29506, 29508, 29509, 29511, 29514, 29515, 29516, 29518, 29519, 29520, 29525, 29526, 29527, 29528, 29531, 29532, 29533, 29534, 29535, 29537, 29539, 29542, 29543, 29544, 29546, 29547, 29548, 29550, 29552, 29556, 29557, 29558, 29560, 29561, 29562, 29563, 29564, 29565, 29568, 29570, 29572, 29573, 29574, 29576, 29579, 29581, 29585, 29586, 29587, 29590, 29594, 29596, 29597, 29598, 29599, 29601, 29605, 29606, 29607, 29608, 29609, 29613, 29615, 29617, 29619, 29620, 29622, 29623, 29624, 29626, 29628, 29632, 29633, 29634, 29635, 29637, 29638, 29639, 29640, 29641, 29643, 29644, 29646, 29647, 29648, 29650, 29651, 29652, 29653, 29654, 29656, 29657, 29658, 29663, 29665, 29666, 29669, 29670, 29671, 29672, 29673, 29674, 29675, 29676, 29678, 29679, 29681, 29683, 29686, 29688, 29689, 29690, 29692, 29694, 29695, 29696, 29697, 29699, 29701, 29702, 29704, 29706, 29724, 30511, 30512, 30515, 30518, 30519, 30520, 30521, 30523, 30524, 30525, 30527, 30529, 30530, 30531, 30532, 30533, 30536, 30537, 30540, 30542, 30543, 30544, 30546, 30548, 30549, 30550, 30551, 30553, 30554, 30557, 30558, 30565, 30566, 30567, 30568, 30570, 30572, 30573, 30575, 30576, 30577, 30578, 30579, 30580, 30581, 30583, 30584, 30586, 30587, 30589, 30591, 30593, 30595, 30596, 30597, 30599, 30601, 30604, 30606, 30607, 30610, 30611, 30612, 30613, 30614, 30615, 30616, 30618, 30619, 30623, 30625, 30626, 30628, 30629, 30631, 30632, 30633, 30635, 30636, 30637, 30642, 30645, 30646, 30648, 30649, 30650, 30651, 30653, 30654, 30655, 30657, 30658, 30659, 30660, 30661, 30662, 30663, 30664, 30665, 30666, 30668, 30669, 30670, 30671, 30672, 30673, 30674, 30675, 30676, 30677, 30678, 30679, 30681, 30682, 30683, 30685, 30686, 30687, 30688, 30690, 30691, 30692, 30693, 30695, 30696, 30697, 30699, 30700, 30701, 30702, 30703, 30705, 30706, 30707, 30708, 30709, 30714, 30715, 30716, 30717, 30721, 30722, 30723, 30724, 30725, 30726, 30727, 30728, 30730, 30731, 30732, 30733, 30735, 30737, 30739, 30740, 30741, 30744, 30745, 30746, 30747, 30749, 30751, 30752, 30754, 30755, 30757, 30758, 30760, 30762, 30764, 30767, 30768, 30769, 30770, 30771, 30774, 30775, 30776, 30777, 30778, 30780, 30782, 30783, 30784, 30785, 30787, 30789, 30790, 30791, 30792, 30793, 30795, 30796, 30797, 30800, 30801, 30802, 30803, 30805, 30806, 30807, 30808, 30810, 30814, 30818, 30819, 30820, 30822, 30824, 30825, 30830, 30831, 30833, 30836, 30837, 30838, 30840, 30841, 30843, 30845, 30846, 30847, 30848, 30849, 30850, 30851, 30853, 30854, 30855, 30856, 30857, 30858, 30859, 30860, 30863, 30866, 30868, 30869, 30873, 30874, 30875, 30877, 30878, 30879, 30880, 30883, 30885, 30886, 30887, 30889, 30890, 30891, 30893, 30894, 30895, 30897, 30899, 30902, 30903, 30905, 30906, 30907, 30913, 30918, 30919, 30920, 30921, 30922, 30923, 30924, 30925, 30926, 30927, 30928, 30929, 30930, 30931, 30932, 30935, 30936, 30937, 30938, 30939, 30940, 30941, 30943, 30944, 30945, 30948, 30949, 30950, 30952, 30953, 30954, 30956, 30958, 30959, 30961, 30962, 30965, 30966, 30968, 30971, 30972, 30973, 30975, 30976, 30980, 30981, 30983, 30984, 30985, 30986, 30987, 30989, 30990, 30992, 30993, 30994, 30995, 30996, 30997, 30998, 30999, 31001, 31002, 31004, 31005, 31007, 31009, 31011, 31013, 31014, 31015, 31016, 31017, 31018, 31019, 31020, 31021, 31022, 31023, 31024, 31025, 31026, 31027, 31028, 31029, 31030, 31033, 31034, 31035, 31037, 31038, 31040, 31041, 31043, 31045, 31046, 31047, 31048, 31049, 31053, 31055, 31056, 31057, 31058, 31061, 31062, 31063, 31066, 31068, 31069, 31070, 31071, 31072, 31074, 31077, 31078, 31080, 31081, 31082, 31083, 31087, 31090, 31093, 31095, 31098, 31099, 31100, 31101, 31103, 31104, 31105, 31106, 31108, 31109, 31110, 31111, 31113, 31114, 31115, 31117, 31118, 31119, 31120, 31121, 31123, 31126, 31127, 31128, 31130, 31134, 31136, 31139, 31141, 31144, 31145, 31147, 31148, 31151, 31152, 31153, 31157, 31159, 31163, 31165, 31166, 31168, 31169, 31172, 31174, 31177, 31178, 31179, 31181, 31185, 31186, 31187, 31189, 31190, 31192, 31194, 31196, 31198, 31200, 31203, 31204, 31205, 31206, 31208, 31209, 31210, 31211, 31214, 31215, 31217, 31218, 31219, 31221, 31223, 31224, 31225, 31226, 31227, 31228, 31232, 31233, 31234, 31235, 31236, 31237, 31238, 31239, 31242, 31244, 31245, 31246, 31248, 31249, 31250, 31252, 31388, 31390, 31393, 31394, 31395, 31396, 31397, 31398, 31399, 31401, 31404, 31405, 31407, 31412, 31414, 31421, 31423, 31426, 31427, 31428, 31431, 31436, 31437, 31438, 31439, 31440, 31447, 31448, 31449, 31451, 31452, 31454, 31455, 31456, 31457, 31458, 31459, 31461, 31462, 31466, 31469, 31470, 31475, 31476, 31478, 31484, 31485, 31488, 31489, 31491, 31493, 31495, 31497, 31499, 31506, 31508, 31516, 31519, 31522, 31523, 31529, 31531, 31533, 31536, 31539, 31540, 31541, 31548, 31550, 31553, 31554, 31558, 31561, 31562, 31564, 31566, 31570, 31574, 31578, 31580, 31582, 31584, 31585, 31586, 31587, 31588, 31589, 31590, 31592, 31593, 31594, 31595, 31596, 31597, 31599, 31600, 31603, 31606, 31609, 31611, 31612, 31613, 31615, 31616, 31617, 31618, 31619, 31620, 31622, 31624, 31627, 31629, 31631, 31632, 31633, 31634, 31635, 31637, 31638, 38853, 31645, 31646, 31647, 31650, 38855, 31652, 31654, 31656, 31658, 31659, 31660, 31661, 31664, 31665, 31667, 31669, 31671, 31672, 31673, 31674, 31675, 31676, 31678, 31680, 31681, 31684, 31685, 31688, 31689, 31693, 31698, 31699, 31700, 31701, 31703, 31705, 31708, 31711, 31715, 31717, 31718, 31719, 31720, 31724, 31726, 31727, 31728, 31731, 31732, 31733, 31736, 31739, 31740, 31741, 31744, 31745, 31746, 31747, 31748, 31750, 31751, 31752, 31753, 31754, 38876, 31756, 31758, 31759, 31762, 31765, 31767, 31769, 38879, 31772, 31774, 31775, 31776, 31777, 31778, 31779, 31781, 31782, 31785, 31786, 31792, 31794, 31796, 31797, 31798, 31802, 31803, 31804, 31806, 31807, 31808, 31809, 31811, 31813, 31815, 31816, 31817, 31818, 31820, 31823, 31824, 31825, 38890, 31827, 31831, 31832, 38891, 31834, 31837, 31839, 31842, 31848, 31851, 38895, 31853, 31854, 31859, 31860, 31867, 31868, 38900, 31877, 31878, 31879, 31881, 38901, 31883, 31884, 31887, 31891, 31897, 38905, 31902, 31905, 31908, 31910, 31912, 31913, 31915, 31916, 31922, 31925, 31930, 31932, 38912, 31939, 38913, 31944, 31947, 38915, 38918, 38920, 38921, 32081, 32082, 32083, 32086, 32087, 32089, 32091, 38943, 32096, 38944, 32100, 32101, 32103, 32104, 32105, 38946, 32109, 32111, 32116, 32119, 32120, 38949, 32124, 32125, 32127, 32128, 38950, 32130, 32131, 32132, 32136, 38952, 32139, 32143, 32144, 32145, 32147, 32148, 38954, 32150, 32153, 32154, 32155, 32156, 32158, 32159, 32160, 32161, 32162, 32164, 32165, 32167, 32168, 32169, 32171, 32172, 32174, 32177, 32178, 32179, 32180, 32184, 32185, 32186, 32188, 32191, 32192, 32193, 32194, 32195, 32196, 32197, 32200, 32201, 32203, 32205, 32206, 32209, 32211, 32212, 32213, 32214, 32216, 32219, 32220, 32221, 32222, 32223, 32224, 32225, 32228, 32230, 32232, 32233, 32234, 32235, 32236, 32237, 32238, 32241, 32242, 32246, 32247, 32248, 32250, 32251, 32252, 32253, 32255, 32256, 32257, 32258, 38976, 32260, 32263, 32264, 38977, 32266, 32267, 32268, 32269, 32270, 38978, 32272, 32275, 32277, 32279, 32287, 32288, 32289, 32290, 32292, 32293, 32294, 32295, 32298, 32299, 32300, 32301, 38984, 32304, 32305, 32306, 32307, 32308, 32309, 32310, 32312, 32313, 38987, 32321, 38989, 32326, 32328, 32329, 32333, 32335, 32336, 32337, 32338, 32339, 38992, 32341, 32342, 32343, 38993, 32345, 32348, 32349, 32350, 32351, 32352, 32353, 32354, 32355, 38994, 32357, 32358, 32359, 32360, 32361, 32362, 32364, 32366, 32369, 32370, 32371, 32372, 32373, 32374, 32375, 32376, 32377, 38999, 32379, 32380, 39000, 32382, 32384, 32385, 32390, 32391, 32393, 32399, 32400, 32401, 32403, 32404, 32405, 32408, 32409, 32410, 32411, 32412, 32413, 39006, 39007, 32418, 32420, 32421, 32422, 32423, 32424, 32427, 32428, 32429, 32431, 32432, 32433, 32434, 32435, 32437, 32439, 39012, 32441, 32442, 32444, 32445, 32447, 32450, 32451, 32452, 32454, 32456, 32457, 32459, 32460, 32463, 32465, 32467, 32469, 32470, 32471, 32472, 32473, 32474, 32477, 32481, 32483, 32484, 40367, 32491, 32492, 32493, 32494, 32496, 32498, 32500, 32501, 32502, 32503, 32505, 32506, 32507, 39025, 32510, 32511, 39026, 32513, 32520, 32522, 32523, 32524, 32525, 32526, 32527, 39029, 32530, 39030, 32532, 32534, 32535, 32536, 32537, 32538, 32539, 32540, 39032, 32542, 32544, 32545, 32546, 39033, 32549, 32550, 39034, 32553, 32556, 32557, 32559, 32560, 39036, 32562, 32563, 32564, 39037, 32569, 39038, 32571, 32572, 32573, 32574, 32575, 39039, 32577, 32578, 32579, 32580, 32583, 32584, 32585, 32586, 32589, 32590, 32591, 39042, 32593, 32594, 32595, 32596, 32598, 32600, 32601, 32602, 32603, 32605, 32606, 32607, 32608, 39045, 32611, 32612, 32614, 32615, 32616, 39047, 32619, 32620, 32621, 32622, 32623, 39048, 32626, 39049, 32628, 32629, 32630, 39050, 32632, 32634, 32635, 32636, 39051, 32641, 32642, 39052, 32644, 32645, 32649, 32650, 32651, 32654, 32655, 32656, 32658, 32659, 32660, 32662, 32663, 32665, 39057, 32669, 32670, 32671, 32673, 32674, 32675, 32676, 32678, 32680, 32681, 32683, 32685, 32686, 32687, 32688, 32690, 32692, 32693, 32694, 32695, 32697, 32698, 32699, 32705, 32707, 32712, 32716, 32722, 39074, 39075, 39076]\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Patterns:\n",
      "         col  num        pattern\n",
      "0        App    0  '^[A-Za-z]+$'\n",
      "1  Sentiment    0    '^[1-2]+$^'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Indexes of rows to be removed: []\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "Indexes of rows to be removed: [8192, 8196, 8201, 10, 8202, 16396, 8205, 16398, 16, 8208, 8210, 20, 16405, 23, 16408, 27, 28, 29, 30, 16413, 33, 16417, 35, 36, 16419, 39, 40, 42, 8235, 44, 16426, 46, 47, 16428, 16430, 50, 16433, 52, 58, 8251, 60, 61, 62, 16445, 64, 8256, 16448, 8259, 68, 16451, 70, 16454, 74, 76, 16463, 80, 84, 16469, 16473, 16474, 92, 16476, 95, 96, 16479, 16482, 101, 103, 104, 16487, 16494, 16495, 112, 16496, 16497, 117, 118, 16504, 121, 16506, 123, 125, 16509, 129, 16519, 136, 137, 8328, 16520, 140, 16523, 8335, 145, 8337, 149, 8343, 153, 156, 8348, 161, 162, 163, 164, 8354, 8358, 167, 8360, 8362, 171, 8363, 8367, 8368, 177, 178, 179, 8369, 8374, 183, 184, 8378, 188, 8380, 8381, 195, 196, 8388, 200, 8392, 202, 8393, 205, 8399, 208, 209, 210, 8403, 8405, 8406, 8407, 221, 224, 225, 227, 228, 8425, 8428, 238, 239, 240, 8431, 242, 244, 8437, 246, 248, 250, 252, 253, 255, 257, 8450, 260, 261, 8454, 264, 8456, 272, 8466, 8468, 8469, 8470, 8472, 283, 8478, 8481, 290, 8483, 293, 297, 8490, 301, 303, 304, 305, 8495, 8497, 309, 8504, 314, 316, 319, 8511, 321, 324, 8518, 8522, 16716, 333, 335, 16719, 8529, 16723, 16725, 16726, 8535, 16727, 8537, 346, 347, 348, 349, 16732, 351, 352, 8545, 16734, 355, 16735, 357, 8549, 16736, 16740, 8553, 16741, 16742, 16743, 365, 16744, 8559, 16751, 369, 16754, 8563, 8565, 16759, 376, 377, 378, 8570, 380, 8572, 8574, 8575, 384, 16760, 386, 387, 8578, 389, 16765, 16766, 8584, 393, 8586, 396, 16782, 399, 8592, 16786, 16787, 8596, 16789, 8598, 8599, 408, 16792, 16794, 412, 16797, 16798, 416, 16800, 8610, 8611, 8612, 421, 16805, 425, 8617, 16809, 16810, 429, 16811, 8623, 16815, 8625, 16818, 435, 437, 439, 442, 443, 8634, 445, 16827, 16828, 16832, 16833, 451, 452, 453, 16836, 16837, 456, 16841, 8650, 459, 8651, 16842, 8654, 16845, 16847, 465, 16848, 8659, 16852, 471, 474, 475, 8667, 16377, 478, 479, 8671, 481, 8672, 16858, 16860, 485, 16861, 16864, 16865, 489, 490, 491, 492, 8681, 8683, 495, 496, 8684, 8689, 16878, 8692, 501, 502, 503, 8694, 8696, 16881, 16884, 508, 509, 8701, 511, 8704, 513, 515, 516, 518, 519, 526, 8718, 532, 536, 541, 8734, 8737, 546, 548, 8741, 551, 552, 8744, 554, 555, 8749, 559, 8753, 8755, 564, 565, 566, 567, 568, 8756, 8758, 8766, 8768, 581, 594, 596, 602, 603, 606, 607, 608, 609, 614, 615, 8809, 623, 625, 632, 635, 637, 638, 639, 643, 646, 647, 648, 651, 653, 655, 659, 661, 8854, 665, 671, 672, 676, 677, 8872, 681, 683, 8875, 685, 686, 8876, 8878, 691, 8884, 8885, 696, 8889, 8895, 705, 8898, 707, 715, 8909, 718, 719, 8912, 8913, 8918, 8919, 8920, 729, 734, 8930, 8937, 8944, 8945, 8946, 8947, 8952, 8957, 8961, 8966, 8968, 8972, 8974, 8975, 8979, 8989, 8993, 8998, 9001, 9002, 9003, 9011, 9015, 9020, 9021, 9028, 9032, 9040, 9048, 9050, 9058, 9061, 9063, 872, 9064, 9067, 9068, 9070, 882, 9079, 9085, 896, 9093, 9096, 9098, 9108, 9109, 9110, 9117, 931, 9127, 9128, 9130, 17327, 9139, 17331, 9141, 17334, 9143, 17335, 9145, 17336, 17345, 9156, 9158, 17350, 17354, 17355, 9165, 9166, 17357, 9169, 17363, 980, 9173, 17364, 17366, 17370, 9179, 17371, 17375, 17378, 17379, 9188, 9189, 18110, 9197, 17390, 17391, 17393, 17395, 9205, 17400, 9209, 17401, 17402, 1020, 1021, 9215, 1024, 17407, 17408, 17412, 9221, 1030, 17414, 9224, 17415, 17418, 9227, 17419, 17421, 17422, 9232, 17425, 9234, 1048, 1051, 9245, 17437, 17438, 17439, 1065, 1069, 9262, 9265, 9270, 9272, 9273, 9279, 1090, 9282, 9283, 9285, 9286, 9287, 9289, 1098, 9292, 9294, 17489, 17490, 17492, 17495, 17496, 9305, 17498, 17499, 1117, 9310, 17501, 17504, 9313, 17505, 1123, 9315, 9316, 17508, 9319, 17509, 9321, 9322, 17511, 1132, 17513, 9326, 17514, 9328, 9329, 17516, 17518, 17520, 9333, 17521, 17528, 17530, 17531, 1148, 17532, 17533, 17535, 17536, 9346, 17540, 9349, 17543, 17544, 9354, 9355, 17547, 17548, 9358, 17552, 17553, 1173, 9366, 9368, 9371, 9372, 9373, 9374, 9375, 9386, 9388, 1201, 9394, 9396, 9397, 1206, 9398, 9402, 9403, 9405, 1216, 9409, 9411, 9412, 9419, 9421, 9423, 1234, 9428, 9435, 1244, 9436, 9439, 9440, 9442, 1255, 9449, 9453, 9454, 1263, 9456, 9458, 9461, 9464, 9465, 9473, 1284, 9478, 9479, 9480, 9485, 9487, 9490, 9493, 9496, 9505, 9507, 9516, 1326, 9520, 1330, 9522, 1332, 17718, 9527, 1336, 9529, 1338, 1339, 9531, 9532, 1342, 1343, 1344, 1345, 9533, 9534, 9539, 1349, 1354, 9546, 1359, 1363, 17747, 1365, 17750, 17751, 1368, 9561, 1373, 1381, 1385, 1387, 1388, 9583, 1396, 9592, 9596, 1406, 1413, 9608, 1419, 1422, 9615, 9616, 1427, 1428, 9621, 9622, 1433, 1436, 1439, 9631, 1446, 1447, 1451, 1452, 9647, 1459, 1460, 1461, 1462, 1463, 9651, 1465, 1466, 9656, 1468, 9660, 9661, 1472, 1473, 17856, 1475, 9667, 1478, 1480, 1484, 9676, 9677, 1487, 9680, 1490, 1491, 1492, 1493, 9683, 9686, 9687, 9691, 1500, 1501, 9693, 9694, 1504, 17883, 1506, 9698, 17894, 9703, 17895, 1513, 1518, 1519, 9711, 1521, 9712, 9714, 17906, 1525, 17909, 9720, 9721, 17912, 9723, 1533, 17918, 17919, 1537, 9729, 1539, 9730, 9732, 1542, 17922, 9736, 1545, 17926, 1547, 9739, 1549, 9740, 17927, 17931, 17937, 17939, 1557, 1558, 17943, 17944, 1561, 9754, 17946, 9756, 9757, 1566, 17950, 1568, 17954, 1571, 9764, 1574, 1575, 1576, 1577, 17958, 17962, 1580, 17963, 1582, 1583, 9774, 1585, 1586, 9775, 9780, 17968, 1590, 1591, 17970, 1593, 9785, 17976, 17979, 17980, 1599, 9792, 1601, 17984, 1604, 9796, 1606, 1607, 1608, 1609, 17994, 17995, 1613, 1614, 9805, 9806, 1617, 9807, 9809, 9810, 1621, 17998, 17999, 18000, 18005, 1626, 1627, 18007, 1629, 1635, 1641, 1643, 18029, 1647, 1650, 18036, 1654, 1655, 1657, 1658, 1660, 18044, 1665, 1666, 18050, 1668, 18054, 1672, 1673, 18058, 18062, 1681, 1682, 1683, 1684, 1685, 1686, 18068, 1688, 1689, 18071, 18073, 19875, 1694, 1695, 18081, 18084, 1702, 1703, 18089, 18090, 19878, 18094, 1713, 18101, 1718, 1719, 1721, 9913, 9914, 1724, 9915, 9917, 9918, 1728, 9919, 1730, 9921, 1732, 9923, 1734, 9925, 1736, 18115, 9930, 18117, 18123, 1742, 18126, 1746, 9939, 9940, 18132, 1751, 1753, 1754, 1755, 1757, 9950, 18144, 18145, 1764, 1765, 1766, 18151, 1771, 1772, 18155, 18156, 18163, 1783, 1785, 1786, 1789, 1791, 1794, 9988, 1799, 1801, 1802, 1809, 18195, 10007, 18199, 1817, 1821, 18214, 1831, 1833, 10026, 18219, 1837, 1838, 18222, 1840, 1841, 10035, 18228, 1845, 10038, 18230, 1848, 10040, 1851, 10043, 1854, 18239, 1856, 1857, 10048, 18252, 18255, 1873, 1874, 10066, 1876, 1879, 1881, 18267, 10082, 10084, 10086, 10093, 10094, 10097, 10099, 10103, 10105, 10107, 10108, 10115, 10116, 10120, 10122, 10123, 10126, 10133, 10139, 10146, 10147, 18341, 10152, 18346, 10155, 10158, 18354, 10174, 18366, 18375, 10188, 10191, 10192, 10193, 18387, 10196, 10201, 18394, 10203, 10205, 10206, 18403, 18405, 18408, 10217, 18411, 18412, 10222, 18414, 18421, 18431, 18435, 2054, 10246, 18439, 18443, 10253, 18446, 10256, 18448, 10258, 18450, 18452, 10262, 10264, 2074, 10266, 18458, 18460, 2078, 2080, 18464, 10275, 10276, 18467, 18471, 18474, 10286, 10287, 10288, 18481, 10293, 18485, 10295, 18486, 18487, 10298, 18488, 10300, 18491, 2110, 18492, 18495, 10310, 18504, 18505, 2122, 18506, 10317, 18511, 18513, 2140, 10334, 10335, 2144, 18528, 10338, 18530, 10340, 10343, 2155, 10347, 10353, 18545, 18547, 10356, 10357, 18548, 10359, 18550, 10361, 2170, 10363, 18554, 18556, 10366, 18558, 2176, 2177, 18559, 10371, 18560, 18562, 18568, 10379, 18572, 18573, 18574, 18577, 10387, 18582, 18584, 2204, 2208, 10405, 18597, 10409, 10410, 10411, 10412, 18601, 10414, 2223, 2224, 10416, 18608, 2227, 10422, 10423, 2232, 10424, 2234, 10427, 10428, 18614, 10430, 10431, 18615, 18616, 18621, 10435, 18622, 18629, 2247, 10439, 18633, 2250, 18636, 10446, 18638, 18639, 18640, 10452, 18645, 2262, 18648, 10457, 10458, 2268, 10460, 10461, 10462, 10463, 10465, 10466, 18654, 18657, 18658, 18659, 2279, 10474, 10475, 10476, 10477, 10478, 18671, 2288, 2289, 2292, 18677, 2295, 2296, 10488, 10491, 2300, 2302, 2303, 18689, 2306, 10501, 2311, 2312, 10504, 10506, 2318, 10514, 10518, 10521, 10523, 2334, 10527, 2337, 10533, 10535, 10538, 10539, 2348, 10541, 2351, 2352, 2353, 10548, 10549, 10550, 2359, 10552, 10553, 2364, 2366, 2367, 10560, 10561, 2371, 2373, 10566, 10567, 2376, 2377, 2378, 10568, 10569, 10571, 2383, 10578, 10583, 2393, 2394, 2395, 10588, 2397, 10590, 2400, 10593, 2404, 10600, 10601, 10602, 2411, 10604, 2413, 2414, 10607, 18798, 10609, 10610, 2420, 10612, 2422, 10613, 10615, 10616, 10617, 18807, 2429, 2430, 10621, 2435, 2436, 10631, 10632, 16767, 2442, 10634, 18824, 16768, 18825, 18831, 2449, 10641, 2451, 2452, 10642, 10644, 16769, 10648, 2457, 10650, 18837, 10652, 18840, 18846, 10655, 2465, 10659, 2468, 18852, 18853, 10663, 18856, 10665, 18859, 10670, 18863, 10672, 18865, 10678, 10681, 18873, 2491, 18875, 10688, 10689, 2498, 10690, 10691, 18880, 18882, 18885, 2504, 2505, 18886, 2507, 10703, 2513, 2514, 2515, 18898, 2518, 2521, 10716, 18909, 2526, 2531, 10723, 2533, 10725, 10727, 18916, 18917, 18920, 18922, 2542, 18926, 18928, 2546, 10740, 2549, 10742, 2551, 10743, 10744, 10746, 18934, 2556, 2557, 10748, 2559, 18936, 2561, 2562, 10754, 18939, 18944, 10758, 2567, 2568, 10759, 10761, 18947, 18950, 2573, 10766, 2575, 10767, 10768, 2578, 2579, 2580, 10769, 10770, 10771, 10773, 18960, 2586, 2587, 10780, 2589, 18966, 2591, 10783, 18968, 18969, 2595, 18974, 18975, 2598, 10791, 2600, 2601, 2602, 18978, 18979, 18983, 2606, 10799, 2608, 18985, 2610, 10802, 10803, 2613, 18989, 18995, 10808, 18996, 10810, 19001, 2620, 10812, 2622, 2624, 2626, 10819, 19013, 2630, 10822, 2632, 10824, 2634, 10825, 19014, 10829, 19015, 19018, 19019, 19023, 2642, 2643, 19025, 2645, 19032, 19034, 10844, 2656, 10848, 10849, 19040, 19044, 10853, 2662, 2663, 2664, 2665, 10856, 2667, 19046, 19047, 19048, 19051, 10864, 19052, 19054, 19059, 19060, 2677, 10871, 19063, 2683, 19068, 19073, 10884, 19076, 10886, 2695, 10887, 10889, 10890, 19078, 10892, 19081, 10894, 10895, 19085, 10897, 10898, 10899, 10900, 19086, 19088, 19095, 10904, 19098, 10907, 10909, 19102, 19104, 10916, 10917, 19108, 19114, 10924, 19116, 10927, 10928, 19119, 19121, 10931, 19122, 19130, 10939, 10941, 19138, 10948, 19142, 10951, 19144, 10953, 10954, 10955, 19146, 10957, 10958, 19151, 10960, 10961, 10962, 19152, 19161, 19164, 10975, 10985, 10986, 10992, 2809, 2814, 11008, 19207, 19209, 19213, 19214, 19216, 11025, 19220, 11029, 19225, 11036, 11039, 19233, 19236, 19241, 19242, 2860, 19245, 2862, 2863, 2864, 11059, 19251, 19252, 19253, 19254, 19256, 2873, 19258, 19259, 2879, 19272, 11083, 11084, 11085, 2897, 11090, 19281, 19287, 11096, 19289, 11098, 2907, 11100, 19291, 2910, 19292, 2913, 2914, 11107, 19298, 19299, 2918, 2920, 19304, 2923, 2924, 2925, 11117, 19312, 2938, 11130, 16866, 2941, 11133, 19327, 11137, 2947, 11149, 11156, 2966, 11164, 16873, 11166, 2975, 2979, 2984, 11177, 2986, 2987, 11180, 11182, 2994, 2995, 2996, 3006, 11199, 11202, 3012, 11210, 11212, 3023, 3029, 11221, 11222, 11223, 3033, 3037, 11230, 3039, 11237, 3047, 3048, 11240, 11241, 11243, 3053, 3054, 3055, 11245, 3057, 11249, 3059, 11250, 3061, 3067, 3068, 3069, 3070, 11259, 11260, 3074, 3075, 11266, 11267, 11268, 11269, 11270, 11272, 3082, 19463, 3085, 11278, 11280, 3089, 11282, 19474, 3092, 11291, 19483, 11296, 19489, 11298, 11300, 19493, 11302, 11303, 19494, 11313, 11317, 11319, 19512, 11326, 11328, 11331, 19526, 11337, 11338, 11339, 11340, 11341, 11346, 11347, 19538, 19541, 11351, 19545, 11354, 11355, 11359, 11360, 19552, 19553, 19555, 11365, 11370, 3180, 19565, 3185, 3186, 3188, 11381, 19574, 3192, 11388, 11389, 19583, 11392, 19587, 19589, 3206, 11399, 19590, 19593, 11405, 19597, 3218, 3222, 19606, 11417, 3227, 11420, 11424, 3233, 19616, 19618, 11428, 11429, 11430, 11431, 19622, 11439, 11444, 11446, 19640, 11449, 19645, 11457, 11460, 19653, 11470, 11473, 19666, 19668, 11477, 11479, 11481, 11482, 11485, 19677, 19678, 19679, 11489, 11490, 19683, 19684, 19687, 19688, 19689, 11499, 19691, 11501, 19692, 11503, 19696, 19698, 11507, 11512, 19704, 19705, 11519, 19714, 11523, 19716, 3334, 11527, 19719, 11530, 19723, 19726, 11535, 11536, 11538, 19732, 11545, 11546, 19741, 19748, 19750, 3369, 3370, 19755, 19756, 3374, 11566, 3377, 19762, 3382, 3383, 19767, 3389, 19774, 19777, 3397, 19782, 3401, 19786, 3405, 19790, 19794, 19797, 19801, 19803, 19804, 19809, 3428, 3432, 19817, 3435, 19823, 3441, 3442, 3444, 3448, 19832, 3451, 19835, 3454, 19840, 3457, 3460, 19844, 11655, 19851, 11661, 11664, 3478, 19863, 11672, 3482, 19867, 11676, 3489, 3490, 3491, 11684, 19873, 3494, 3495, 3496, 11686, 11688, 11689, 3500, 3501, 11691, 3503, 11692, 11697, 11701, 11703, 19898, 11709, 19901, 11711, 19903, 11715, 19908, 3526, 19910, 11720, 19911, 11725, 19917, 3537, 11729, 11730, 3542, 3546, 11739, 11740, 3550, 11743, 3552, 3558, 11750, 11751, 3561, 3564, 3565, 11758, 11759, 3568, 3571, 3572, 11766, 3576, 11768, 3578, 11769, 11771, 11775, 11776, 3586, 3587, 3588, 3592, 11785, 11786, 3596, 11789, 3599, 11792, 11794, 3604, 11797, 3608, 3613, 3615, 11807, 3617, 11811, 3624, 3625, 3626, 11817, 3628, 3629, 11818, 11819, 3632, 11824, 11826, 3635, 11828, 11829, 3641, 11834, 3644, 11838, 3647, 3648, 3649, 11839, 3652, 3658, 3659, 3660, 11855, 3664, 11856, 11859, 11860, 11861, 3670, 3672, 3673, 3674, 11873, 3685, 11878, 11882, 11884, 11886, 11888, 11889, 3698, 11891, 20080, 11893, 11894, 20085, 3704, 3710, 3711, 11905, 20097, 3715, 11908, 3717, 3718, 20099, 11912, 3721, 3722, 20102, 3724, 3725, 11916, 3727, 11921, 3730, 11925, 3736, 20120, 11930, 3742, 20127, 3745, 11937, 3748, 11940, 20132, 20134, 3752, 20136, 3755, 20140, 20142, 20143, 3760, 3761, 3764, 3767, 20151, 3769, 11961, 3771, 11962, 11964, 20157, 3775, 20158, 3778, 3779, 3781, 11973, 20166, 20172, 20173, 11983, 11984, 3793, 20177, 11989, 20182, 11992, 20184, 11994, 11995, 11996, 20185, 20186, 20187, 12000, 12001, 20188, 12003, 12004, 20193, 12006, 12007, 12008, 20194, 20196, 20199, 20200, 20203, 12014, 12015, 20205, 12017, 20206, 12019, 20207, 20210, 20213, 20214, 12024, 12025, 20215, 20217, 12028, 12029, 20218, 20220, 3841, 12033, 20226, 12037, 20232, 12043, 12044, 20236, 12046, 20241, 12050, 20242, 20243, 12055, 20250, 12062, 12063, 20258, 12070, 12071, 12072, 20263, 20264, 12075, 20266, 20267, 20269, 12080, 12081, 20277, 20278, 12087, 12088, 20279, 12090, 20281, 12093, 12094, 12095, 20290, 20291, 20292, 20295, 12105, 12106, 20300, 12109, 12110, 20302, 20303, 20307, 12120, 20312, 20314, 12124, 20316, 12126, 12128, 20321, 20323, 3942, 20328, 3946, 20331, 12140, 3952, 12147, 12148, 3957, 12149, 12151, 12152, 20340, 3962, 12154, 12155, 20342, 12158, 12159, 12160, 12161, 20348, 12163, 12164, 3974, 20358, 20361, 20364, 3983, 3984, 12175, 20369, 20370, 3988, 20372, 3990, 12182, 20373, 3993, 20376, 3995, 12188, 20379, 3998, 20383, 12193, 20387, 20388, 12197, 4006, 4007, 4008, 12198, 4010, 12200, 12201, 20393, 4014, 12206, 12208, 12209, 4018, 20394, 20397, 20399, 20401, 20405, 20406, 12217, 12218, 12219, 4028, 20413, 12222, 12223, 4032, 12224, 20414, 4035, 12228, 20421, 20422, 12231, 20423, 4041, 12233, 4043, 12234, 20425, 20427, 12239, 4048, 20343, 20432, 20435, 12244, 20436, 20437, 12248, 12249, 4058, 4059, 12250, 12252, 20441, 20442, 4064, 12257, 20443, 12259, 4068, 20444, 20448, 20450, 20453, 4073, 12266, 12267, 4076, 12269, 20457, 20461, 4083, 12276, 4085, 20467, 4087, 4088, 20469, 4090, 4091, 12284, 12285, 20470, 12287, 20471, 4097, 12290, 20474, 4100, 12292, 20479, 4103, 20482, 4105, 4106, 20486, 4108, 4109, 12301, 20491, 20493, 20494, 20501, 12310, 20502, 12312, 20503, 20504, 12315, 20505, 20506, 4126, 4127, 12318, 4129, 12321, 12322, 12324, 20510, 12326, 12327, 4136, 20518, 20522, 12331, 4141, 12333, 4143, 20529, 20530, 4147, 12340, 4149, 4150, 4151, 20538, 12348, 12349, 12350, 4159, 12352, 20542, 12354, 4163, 20543, 20546, 20548, 20550, 12360, 4169, 12361, 12362, 20555, 4173, 20557, 4176, 20560, 20565, 4182, 20570, 4189, 20576, 4193, 4194, 4195, 20578, 4200, 20586, 4203, 20587, 4205, 20588, 4207, 4208, 20589, 20590, 20595, 20596, 4214, 12407, 4216, 4217, 12409, 12411, 12412, 20600, 4222, 12415, 4224, 4225, 20603, 20604, 20610, 4232, 4233, 12425, 20616, 12428, 20620, 4238, 4239, 20624, 4242, 4244, 12437, 20628, 4247, 20631, 20636, 20638, 20639, 4260, 4262, 4267, 4268, 4269, 12460, 12466, 12468, 4277, 4282, 12475, 12476, 4285, 12479, 4288, 4289, 4290, 4293, 4294, 12485, 12488, 12489, 4299, 12492, 4302, 4304, 12497, 4306, 4307, 4309, 4310, 4311, 4312, 4313, 12504, 4315, 12506, 12507, 4320, 4323, 4324, 4325, 4328, 4329, 4330, 4337, 12529, 12531, 4340, 12533, 4344, 4345, 12536, 4352, 4354, 12548, 4365, 4367, 4368, 12563, 12565, 12578, 12579, 12580, 12591, 12594, 12595, 12598, 12601, 12602, 12612, 12617, 12618, 12621, 12623, 12625, 12627, 12636, 12642, 12643, 12644, 12647, 12652, 12654, 12657, 20850, 12659, 12662, 12664, 12665, 12668, 4480, 12675, 12679, 12680, 4490, 12684, 4493, 12686, 12687, 12693, 12702, 12703, 4512, 4514, 12706, 12710, 12713, 12714, 12715, 4524, 4525, 12718, 4527, 4528, 12722, 12725, 12726, 12727, 20919, 4538, 4540, 12736, 12738, 4548, 12740, 12742, 4551, 12744, 4554, 12746, 12748, 12750, 12756, 12758, 12759, 12764, 4574, 4575, 12766, 4577, 12769, 12772, 12773, 12778, 4587, 12779, 12780, 4590, 12783, 20972, 12786, 4598, 4599, 12791, 4602, 4603, 4605, 12799, 4608, 4609, 4610, 4611, 12800, 4613, 12805, 12807, 4616, 12808, 20998, 12817, 12821, 4630, 12823, 12825, 4634, 12828, 12830, 4640, 12833, 4644, 4647, 12839, 12841, 4650, 12842, 4652, 12846, 4656, 12849, 12850, 12861, 4671, 12863, 12864, 12865, 12866, 4676, 4677, 12868, 4679, 4680, 12869, 4682, 12870, 12872, 12873, 4686, 12874, 12876, 12877, 4690, 12880, 12882, 4693, 12884, 4695, 12886, 12892, 12895, 4704, 12898, 12900, 4711, 12903, 12904, 4714, 4716, 4717, 12908, 12909, 12910, 12912, 12914, 4723, 12916, 12918, 12923, 4733, 12925, 12927, 4736, 12929, 4743, 12939, 4748, 12943, 12944, 4753, 12945, 12946, 4758, 4759, 12952, 4762, 4763, 12954, 12955, 4768, 4769, 4771, 4772, 4773, 12964, 4775, 12968, 4779, 4780, 12973, 4782, 4784, 4786, 4787, 12982, 12983, 4793, 4794, 12988, 12990, 4799, 12991, 4801, 12992, 4803, 4804, 4805, 4806, 12994, 13000, 13001, 13002, 13003, 13005, 21198, 13007, 13010, 13011, 13012, 4822, 13014, 4829, 13021, 13023, 13035, 13037, 13045, 13048, 13049, 13052, 13063, 13065, 13067, 13068, 13069, 13074, 13076, 13080, 13086, 13087, 13090, 13092, 13093, 13097, 13102, 13104, 13105, 13108, 4917, 13111, 13115, 13116, 13117, 13121, 4930, 13123, 13124, 4933, 13134, 4944, 13137, 13147, 13149, 13150, 13151, 13152, 13153, 13154, 4966, 13158, 13161, 4970, 13162, 13164, 13168, 13169, 13170, 13175, 13181, 13184, 13185, 13187, 13189, 13190, 13193, 13194, 13197, 13207, 13208, 13209, 13212, 13215, 13218, 13219, 13220, 13231, 13232, 13238, 13242, 13245, 13246, 13247, 13252, 13253, 13255, 13259, 13267, 13268, 13269, 13270, 13274, 5092, 13290, 13292, 13297, 5110, 13305, 13307, 13311, 13315, 5125, 13320, 13322, 5131, 13324, 5133, 13326, 13328, 5137, 5139, 5141, 13333, 13335, 5145, 13337, 5147, 5148, 13341, 5153, 13346, 13347, 5157, 13350, 5159, 5160, 13353, 5163, 13355, 5166, 5169, 5170, 13372, 13373, 13375, 13377, 13380, 13383, 13384, 13385, 13386, 13387, 13390, 13391, 13395, 13397, 18945, 13399, 13401, 13402, 13404, 5213, 13405, 5217, 5223, 5226, 5227, 13420, 13422, 5234, 13426, 13427, 5237, 5241, 5242, 5243, 13435, 13437, 5246, 13438, 18953, 5249, 13441, 5251, 13442, 13444, 13446, 5255, 13447, 13448, 5258, 13449, 18954, 18956, 13458, 13461, 5271, 13463, 5273, 5274, 13471, 13473, 13476, 13480, 13481, 5290, 5291, 13483, 5293, 18962, 13487, 13488, 13494, 5303, 13496, 13497, 5309, 13501, 13508, 5317, 5318, 13510, 5320, 5322, 5323, 5326, 5328, 5331, 5343, 5345, 5348, 5366, 18977, 5372, 5375, 5376, 5379, 5391, 5397, 5402, 5404, 5407, 5416, 18988, 5423, 5426, 5427, 5533, 5539, 5551, 5553, 5559, 5561, 5564, 5567, 5570, 5580, 5582, 5589, 5596, 5602, 5605, 5606, 5607, 5613, 13805, 5620, 5621, 5622, 5623, 5625, 5626, 13818, 5629, 5630, 5633, 5634, 5636, 5645, 5647, 5652, 5655, 5659, 5661, 5662, 5663, 5665, 5666, 5667, 5668, 5670, 5689, 5697, 5715, 5720, 5722, 5725, 5727, 5728, 5729, 5730, 5731, 5737, 5741, 5743, 5744, 5747, 5748, 5752, 5760, 5767, 5771, 5773, 5775, 5779, 5784, 5786, 5795, 5801, 5804, 5808, 5810, 5812, 5814, 5815, 5833, 5835, 5841, 5842, 5843, 5846, 5849, 5850, 5851, 5857, 5872, 5873, 5875, 5878, 5880, 5881, 5883, 5889, 5890, 5892, 5896, 5909, 5910, 5921, 5927, 6060, 6061, 14262, 6078, 6082, 6090, 6097, 6098, 6101, 6105, 6108, 14301, 6110, 6111, 6112, 6113, 14305, 6118, 14312, 6121, 14314, 6123, 6124, 6125, 14317, 6127, 14318, 14321, 14322, 14323, 6133, 6137, 14334, 6143, 6144, 14335, 6147, 14339, 14341, 14343, 6152, 6158, 14350, 14354, 6163, 6164, 14359, 6169, 14361, 14363, 14369, 14372, 6183, 14378, 6189, 14381, 6194, 6196, 6197, 6198, 14388, 6201, 6203, 14395, 14397, 6206, 6207, 14399, 14401, 6210, 6211, 14402, 6213, 6214, 6215, 14403, 14408, 14411, 14413, 6222, 6226, 6227, 14420, 6229, 14421, 6231, 14423, 6236, 14430, 14432, 6242, 14436, 6245, 14437, 14438, 6249, 14441, 14443, 6252, 14444, 14446, 14448, 14449, 6259, 6260, 14453, 6262, 14454, 6264, 14458, 14459, 14464, 6276, 14470, 14471, 14477, 14479, 14484, 6294, 6296, 6300, 6302, 6304, 6308, 6310, 6313, 6322, 6323, 6327, 6328, 6330, 6331, 6335, 6337, 14530, 6339, 6340, 14533, 6342, 14534, 14537, 6347, 14539, 6350, 6354, 14546, 14548, 6359, 14553, 14558, 6368, 14561, 14562, 14564, 6373, 14565, 14567, 6376, 14568, 6379, 14573, 14576, 6385, 6386, 6387, 6388, 6391, 14583, 6393, 14584, 6395, 6396, 14587, 14591, 6400, 14594, 6403, 14595, 6405, 14596, 14597, 6408, 14598, 14600, 6411, 6412, 6413, 14603, 14606, 6416, 6417, 6424, 6430, 6431, 6434, 6446, 6452, 6453, 6455, 6456, 6457, 6464, 6470, 6480, 6486, 6497, 6501, 6506, 14709, 14710, 14712, 14717, 14719, 14722, 14729, 14730, 14734, 14736, 14737, 14742, 14752, 14753, 14755, 14756, 14757, 14758, 14768, 14773, 14777, 14780, 14783, 14785, 14786, 14789, 14790, 14792, 14799, 14802, 14809, 14810, 14819, 14821, 14822, 14823, 14825, 14830, 14831, 6645, 6646, 14838, 6650, 14843, 14845, 14847, 6656, 6658, 6663, 14857, 14864, 6673, 14865, 6676, 14869, 14872, 6683, 14875, 14876, 14878, 14879, 6688, 14881, 14882, 14885, 14888, 14893, 14894, 6704, 14899, 6709, 14901, 14903, 6712, 14905, 6714, 14910, 6724, 6726, 14921, 14924, 14927, 14928, 14930, 14931, 14933, 6742, 14935, 14936, 6746, 14941, 14944, 6754, 14949, 6758, 14950, 6760, 14951, 6762, 6763, 14952, 14954, 14957, 6767, 6768, 14959, 6771, 14970, 6779, 6780, 14971, 14972, 14979, 14981, 6795, 14988, 14992, 14993, 14996, 6805, 6807, 6808, 6810, 15002, 15005, 6817, 6818, 15010, 6820, 6821, 15011, 6823, 15014, 15022, 15027, 15029, 15031, 15032, 15034, 6844, 15036, 6848, 15041, 6853, 15045, 15047, 15051, 15052, 15054, 6863, 15057, 15060, 6872, 15064, 6877, 15069, 6879, 6882, 15075, 6892, 15084, 6895, 6897, 6908, 6912, 6919, 6920, 6923, 6926, 6974, 6980, 6989, 6997, 7008, 7052, 7057, 7060, 7066, 7069, 7073, 7074, 7076, 7077, 7079, 7080, 7084, 7093, 7094, 7099, 7102, 7103, 7104, 7108, 7111, 7119, 7124, 7128, 7132, 7136, 7137, 7142, 7144, 7148, 7152, 7156, 7159, 7167, 7172, 7182, 7184, 7186, 7189, 7194, 7195, 7196, 17724, 7306, 7307, 7309, 7312, 7320, 7321, 7322, 7333, 7335, 7336, 7339, 7340, 7342, 7348, 7351, 7353, 7355, 7362, 7363, 7372, 7374, 7378, 7382, 7393, 7399, 7401, 7403, 7406, 7408, 7414, 7422, 7423, 7425, 7426, 7428, 7429, 7431, 7433, 7440, 7441, 7444, 7446, 7451, 7456, 7458, 7461, 7465, 7468, 7473, 7479, 7482, 7485, 7489, 7491, 7492, 7493, 7501, 7507, 7510, 7511, 7522, 7526, 7528, 7530, 7536, 7540, 7548, 7550, 7558, 7566, 7567, 7569, 7570, 7571, 7573, 7576, 7579, 7581, 7582, 7586, 7588, 7589, 7590, 7592, 7597, 7603, 7613, 7614, 7617, 7618, 7619, 7622, 7624, 7625, 7629, 7630, 7631, 7632, 7637, 7640, 7643, 7645, 7646, 7651, 7652, 7654, 7656, 7662, 7665, 7670, 7673, 7675, 7685, 7689, 7691, 7692, 7693, 15885, 15886, 15887, 15890, 7700, 15892, 7704, 7707, 15901, 15902, 15903, 15906, 7721, 15915, 15916, 7732, 7733, 15926, 15928, 15930, 15931, 15933, 15935, 15936, 15938, 15939, 15942, 15946, 15947, 15951, 15952, 15953, 15957, 15960, 15971, 15973, 15976, 15985, 15990, 15991, 15992, 15994, 16014, 16015, 16018, 16024, 7834, 16028, 16030, 16036, 7846, 16038, 16039, 16042, 7855, 16048, 7860, 7861, 7862, 16054, 7865, 7866, 7869, 16062, 16065, 16067, 16070, 7882, 7885, 16079, 7888, 7891, 7895, 7897, 16091, 7901, 16094, 7905, 16099, 7909, 7911, 7915, 7916, 7917, 16107, 16108, 16111, 16116, 16118, 16119, 7928, 16120, 16122, 16126, 7935, 7937, 16129, 7940, 7942, 16134, 7944, 16135, 7946, 16137, 16140, 7953, 7954, 16146, 7956, 16147, 16154, 16155, 7966, 16160, 7970, 7971, 7972, 7973, 16164, 16165, 16166, 7977, 7979, 7984, 7991, 7995, 7996, 8006, 8008, 8009, 8015, 16211, 8020, 8021, 8022, 16213, 16216, 8026, 8027, 8028, 16220, 16222, 8034, 16236, 16237, 16238, 16239, 16241, 16247, 16249, 16250, 8059, 16251, 8061, 16252, 16255, 8065, 16257, 16259, 8070, 16263, 8072, 8073, 8074, 16265, 8076, 16268, 8078, 16271, 8080, 8081, 16280, 16284, 16285, 16286, 16288, 16289, 8100, 8103, 16296, 8106, 16299, 16303, 16308, 16309, 16310, 16311, 16314, 8123, 16315, 8125, 16316, 8127, 16319, 8130, 16322, 16323, 16325, 16326, 16328, 8138, 16332, 16333, 8142, 8147, 8150, 16343, 8154, 8155, 8157, 8159, 8161, 16353, 8163, 16355, 16356, 8167, 8169, 8170, 16364, 16366, 8175, 8177, 8180, 16372, 8185, 16378, 8190]\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.09610176086425781 seconds\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "No train dataset, no duplicate detection\n",
      "No test dataset, no duplicate detection\n",
      "Deduplication done -- CPU time: 0.0003719329833984375 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "No outlier detection for train dataset\n",
      "No outlier detection for test dataset\n",
      "Outlier detection and removal done -- CPU time: 0.0003192424774169922 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Error: Need at least one continous variable and  10  observations for regression\n",
      "Regression done -- CPU time: 0.003384113311767578 seconds\n",
      "End Pipeline CPU time: 0.10035371780395508 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> LOF -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.0596768856048584 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 outlying rows have been removed\n",
      "with indexes: [5, 642, 1109, 2609, 8139, 9175, 11904, 12011, 13229, 14545, 18070, 20212, 22086, 22281, 23201, 24871, 24876, 25214, 25460, 26620, 26929, 28049, 30543, 30992, 31495, 33580, 41218, 42843, 43065, 43066]\n",
      "\n",
      "Outliers:\n",
      "      Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "5             3            0.388889                0.000000   \n",
      "642           3            0.388889                0.000000   \n",
      "1109          3            0.388889                0.000000   \n",
      "2609          3            0.388889                0.000000   \n",
      "8139          2            0.851852                0.925926   \n",
      "9175          3            0.388889                0.000000   \n",
      "11904         2            0.888889                0.680400   \n",
      "12011         3            0.388889                0.000000   \n",
      "13229         2            0.911111                1.000000   \n",
      "14545         3            0.388889                0.000000   \n",
      "18070         3            0.388889                0.000000   \n",
      "20212         2            0.655447                0.574055   \n",
      "22086         1            0.388889                0.000000   \n",
      "22281         3            0.388889                0.000000   \n",
      "23201         3            0.388889                0.000000   \n",
      "24871         3            0.388889                0.000000   \n",
      "24876         1            0.388889                0.000000   \n",
      "25214         3            0.388889                0.000000   \n",
      "25460         3            0.388889                0.000000   \n",
      "26620         3            0.388889                0.000000   \n",
      "26929         3            0.388889                0.000000   \n",
      "28049         2            0.859708                0.876039   \n",
      "30543         1            0.388889                0.000000   \n",
      "30992         2            1.000000                1.000000   \n",
      "31495         3            0.388889                0.000000   \n",
      "33580         3            0.388889                0.000000   \n",
      "41218         2            0.577154                0.735331   \n",
      "42843         2            1.000000                0.543201   \n",
      "43065         3            0.388889                0.000000   \n",
      "43066         3            0.388889                0.000000   \n",
      "\n",
      "                                                                                       App  \\\n",
      "5                                                                    10 Best Foods for You   \n",
      "642                                                          2ndLine - Second Phone Number   \n",
      "1109                                                         7 Cups: Anxiety & Stress Chat   \n",
      "2609                                                       AC - Tips & News for Androidâ¢   \n",
      "8139                                     Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "9175                                                         Asana: organize team projects   \n",
      "11904                                                                          Bad Piggies   \n",
      "12011                                                       Badoo - Free Chat & Dating App   \n",
      "13229                                                                  Be A Legend: Soccer   \n",
      "14545                                                             BeyondMenu Food Delivery   \n",
      "18070                                                                       Bubble Shooter   \n",
      "20212                                                                  CMB Free Dating App   \n",
      "22086                                                       Calorie Counter - MyFitnessPal   \n",
      "22281                                                         Calorie Counter - MyNetDiary   \n",
      "23201                                   Candy Camera - selfie, beauty camera, photo editor   \n",
      "24871                                                       Cat Sim Online: Play with Cats   \n",
      "24876                                                       Cat Sim Online: Play with Cats   \n",
      "25214                                                            ChatVideo Meet new people   \n",
      "25460                                                         Checkout 51: Grocery coupons   \n",
      "26620                                                                        Citi MobileÂ®   \n",
      "26929                                                                         Clash Royale   \n",
      "28049                                                Color by Number â New Coloring Book   \n",
      "30543                                                                         Credit Karma   \n",
      "30992                                                       Crunchyroll - Everything Anime   \n",
      "31495                                   Cymera Camera- Photo Editor, Filter,Collage,Layout   \n",
      "33580  Delivery ClubâÐÐ¾ÑÑÐ°Ð²ÐºÐ° ÐµÐ´Ñ:Ð¿Ð¸ÑÑÐ°,ÑÑÑÐ¸,Ð±ÑÑÐ³ÐµÑ,ÑÐ°Ð»Ð°Ñ   \n",
      "41218                                    Evernote â Organizer, Planner for Notes & Memos   \n",
      "42843                                                                             Facebook   \n",
      "43065                                                                       Facebook Local   \n",
      "43066                                                                       Facebook Local   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "5                                                                                                 Best way   \n",
      "642    Thanks fixing notification problem new recent update I give 5 stars cause I miss calls texts any...   \n",
      "1109                                          Yeah 7 cups fine, glitchy sometimes, less features available   \n",
      "2609                                                    New TOS data collection.. I'm out!!! (Uninstalled)   \n",
      "8139                                                                                 One best apps. â¤ï¸   \n",
      "9175   The amazing user friendly. My concers receiving notifications gmail inbox becomes like mess. I w...   \n",
      "11904  great game. I completed ground hog day rise swine.brought little pig adventure found fifteen sku...   \n",
      "12011  The self works fine, intended purpose works. There real people. HOWEVER scam feeling still stron...   \n",
      "13229  Server Downloaded yesterday still able get past first loading screen cuz says server maintenance...   \n",
      "14545                                                                      Super easy order always correct   \n",
      "18070                                                                                      Nice good games   \n",
      "20212                             Invited two friends watched set profiles, never received beans inviting.   \n",
      "22086                                                              In 1 week I feet fitter healthier ever!   \n",
      "22281         Easiest way calorie count honest. Down 2lbs week since I started. Also, reliable motivating.   \n",
      "23201  New version candy camera bad want old candy camera ..once reset phn nd dt candy camera removed t...   \n",
      "24871                Love family tree generations! dragon sim u 2 children here... TONS!!!!! LOVED IT 100%   \n",
      "24876  It's cute I throw kittens make make pregnant baby cute I'll cute cute cute cute cute cute like b...   \n",
      "25214  Well wanna tell guys make rules dont follow. No nudity etc...then dont banned people whos showin...   \n",
      "25460  I like app. It gives back money daily groceries I like tha different brands variety yht items fa...   \n",
      "26620  The got stuck today login phase, I clear data reinstall. Even start-up incredibly slow. (Even \"r...   \n",
      "26929  Plz make compatible Mali G72 MP3. I playing game old Redmi note 3 adreno 510 GPU & phone running...   \n",
      "28049  Brilliant way relax keeps saying internet access. So disconnect device reconnect continue. Bit a...   \n",
      "30543  This Best. Credit Karma check scores everyday matter many times also dispute Direct check credit...   \n",
      "30992  Upgrading rating two stars four stars. The bug fixes seem resolved quite issues I facing app. A ...   \n",
      "31495                                                                                            Good like   \n",
      "33580                                                         I never managed to enter a promotional code.   \n",
      "41218  Pretty unhappy note taking allow simple printing let alone exporting pdf. I regret used thinking...   \n",
      "42843  This lot problems. The irritating thing tag someone video post, reply, go notifications pops vid...   \n",
      "43065  I decided give try hope keeping track summer events going on. At first confusing difficult use, ...   \n",
      "43066         Did show thing I wanted see literally show anything read going outside town. Totally useless   \n",
      "\n",
      "       New_ID  \\\n",
      "5           5   \n",
      "642       418   \n",
      "1109      509   \n",
      "2609     1156   \n",
      "8139     3456   \n",
      "9175     3877   \n",
      "11904    5147   \n",
      "12011    5215   \n",
      "13229    5925   \n",
      "14545    6265   \n",
      "18070    7756   \n",
      "20212    8561   \n",
      "22086    9247   \n",
      "22281    9369   \n",
      "23201    9445   \n",
      "24871    9996   \n",
      "24876    9999   \n",
      "25214   10215   \n",
      "25460   10371   \n",
      "26620   10598   \n",
      "26929   10804   \n",
      "28049   11015   \n",
      "30543   11918   \n",
      "30992   12215   \n",
      "31495   12432   \n",
      "33580   13075   \n",
      "41218   15815   \n",
      "42843   16539   \n",
      "43065   16671   \n",
      "43066   16672   \n",
      "\n",
      "                                                                                                       row  \n",
      "5      3*0.3888888888888889*0.0*10BestFoodsforYou*Bestway*5*3*0.3888888888888889*0.0*10BestFoodsforYou*...  \n",
      "642    3*0.3888888888888889*0.0*2ndLine-SecondPhoneNumber*Thanksfixingnotificationproblemnewrecentupdat...  \n",
      "1109   3*0.3888888888888889*0.0*7Cups:Anxiety&StressChat*Yeah7cupsfine,glitchysometimes,lessfeaturesava...  \n",
      "2609   3*0.3888888888888889*0.0*AC-Tips&NewsforAndroidâ¢*NewTOSdatacollection..I'mout!!!(Uninstalled)*...  \n",
      "8139   2*0.8518518518518517*0.9259259259259259*Any.do:To-dolist,Calendar,Reminders&Planner*Onebestapps....  \n",
      "9175   3*0.3888888888888889*0.0*Asana:organizeteamprojects*Theamazinguserfriendly.Myconcersreceivingnot...  \n",
      "11904  2*0.8888888888888888*0.6803995006242197*BadPiggies*greatgame.Icompletedgroundhogdayriseswine.bro...  \n",
      "12011  3*0.3888888888888889*0.0*Badoo-FreeChat&DatingApp*Theselfworksfine,intendedpurposeworks.Thererea...  \n",
      "13229  2*0.9111111111111111*1.0*BeALegend:Soccer*ServerDownloadedyesterdaystillablegetpastfirstloadings...  \n",
      "14545  3*0.3888888888888889*0.0*BeyondMenuFoodDelivery*Supereasyorderalwayscorrect*6265*3*0.38888888888...  \n",
      "18070  3*0.3888888888888889*0.0*BubbleShooter*Nicegoodgames*7756*3*0.3888888888888889*0.0*BubbleShooter...  \n",
      "20212  2*0.6554468637144565*0.5740550181793233*CMBFreeDatingApp*Invitedtwofriendswatchedsetprofiles,nev...  \n",
      "22086  1*0.3888888888888889*0.0*CalorieCounter-MyFitnessPal*In1weekIfeetfitterhealthierever!*9247*1*0.3...  \n",
      "22281  3*0.3888888888888889*0.0*CalorieCounter-MyNetDiary*Easiestwaycaloriecounthonest.Down2lbsweeksinc...  \n",
      "23201  3*0.3888888888888889*0.0*CandyCamera-selfie,beautycamera,photoeditor*Newversioncandycamerabadwan...  \n",
      "24871  3*0.3888888888888889*0.0*CatSimOnline:PlaywithCats*Lovefamilytreegenerations!dragonsimu2children...  \n",
      "24876  1*0.3888888888888889*0.0*CatSimOnline:PlaywithCats*It'scuteIthrowkittensmakemakepregnantbabycute...  \n",
      "25214  3*0.3888888888888889*0.0*ChatVideoMeetnewpeople*Wellwannatellguysmakerulesdontfollow.Nonudityetc...  \n",
      "25460  3*0.3888888888888889*0.0*Checkout51:Grocerycoupons*Ilikeapp.ItgivesbackmoneydailygroceriesIliket...  \n",
      "26620  3*0.3888888888888889*0.0*CitiMobileÂ®*Thegotstucktodayloginphase,Icleardatareinstall.Evenstart-u...  \n",
      "26929  3*0.3888888888888889*0.0*ClashRoyale*PlzmakecompatibleMaliG72MP3.IplayinggameoldRedminote3adreno...  \n",
      "28049  2*0.8597081930415263*0.8760393046107332*ColorbyNumberâNewColoringBook*Brilliantwayrelaxkeepssa...  \n",
      "30543  1*0.3888888888888889*0.0*CreditKarma*ThisBest.CreditKarmacheckscoreseverydaymattermanytimesalsod...  \n",
      "30992  2*1.0*1.0*Crunchyroll-EverythingAnime*Upgradingratingtwostarsfourstars.Thebugfixesseemresolvedqu...  \n",
      "31495  3*0.3888888888888889*0.0*CymeraCamera-PhotoEditor,Filter,Collage,Layout*Goodlike*12432*3*0.38888...  \n",
      "33580  3*0.3888888888888889*0.0*DeliveryClubâÐÐ¾ÑÑÐ°Ð²ÐºÐ°ÐµÐ´Ñ:Ð¿Ð¸ÑÑÐ°,ÑÑÑÐ¸,Ð±ÑÑÐ³ÐµÑ,...  \n",
      "41218  2*0.5771536762385612*0.7353308364544319*EvernoteâOrganizer,PlannerforNotes&Memos*Prettyunhappy...  \n",
      "42843  2*1.0*0.543200845322279*Facebook*Thislotproblems.Theirritatingthingtagsomeonevideopost,reply,gon...  \n",
      "43065  3*0.3888888888888889*0.0*FacebookLocal*Idecidedgivetryhopekeepingtracksummereventsgoingon.Atfirs...  \n",
      "43066  3*0.3888888888888889*0.0*FacebookLocal*DidshowthingIwantedseeliterallyshowanythingreadgoingoutsi...  \n",
      "\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "with indexes: [27, 314, 1330, 1751, 2587, 3673, 4512, 4525, 5170, 6923, 6955, 8201, 8875, 9110, 9165, 9368, 10602, 12149, 12340, 13023, 13045, 13150, 13471, 17167, 17425, 17777, 18481, 19767, 20850, 20919]\n",
      "\n",
      "Outliers:\n",
      "      Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "27            2            0.955556                0.907407   \n",
      "314           2            0.933333                0.790123   \n",
      "1330          3            0.388889                0.000000   \n",
      "1751          3            0.388889                0.000000   \n",
      "2587          2            0.918519                0.790123   \n",
      "3673          3            0.388889                0.000000   \n",
      "4512          3            0.388889                0.000000   \n",
      "4525          2            0.829958                0.735972   \n",
      "5170          1            0.388889                0.000000   \n",
      "6923          3            0.388889                0.000000   \n",
      "6955          3            0.388889                0.000000   \n",
      "8201          2            0.955556                0.888889   \n",
      "8875          3            0.388889                0.000000   \n",
      "9110          3            0.388889                0.000000   \n",
      "9165          3            0.388889                0.000000   \n",
      "9368          2            0.627714                0.582426   \n",
      "10602         2            0.785956                0.894356   \n",
      "12149         1            0.388889                0.000000   \n",
      "12340         3            0.388889                0.000000   \n",
      "13023         3            0.388889                0.000000   \n",
      "13045         1            0.388889                0.000000   \n",
      "13150         3            0.388889                0.000000   \n",
      "13471         3            0.388889                0.000000   \n",
      "17167         3            0.388889                0.000000   \n",
      "17425         3            0.388889                0.000000   \n",
      "17777         3            0.388889                0.000000   \n",
      "18481         3            0.388889                0.000000   \n",
      "19767         3            0.388889                0.000000   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "\n",
      "                                                     App  \\\n",
      "27                                 10 Best Foods for You   \n",
      "314                           1800 Contacts - Lens Store   \n",
      "1330                                         8 Ball Pool   \n",
      "1751                        8fit Workouts & Meal Planner   \n",
      "2587                     AC - Tips & News for Androidâ¢   \n",
      "3673                         Accounting App - Zoho Books   \n",
      "4512                                             Agar.io   \n",
      "4525                                             Agar.io   \n",
      "5170           Airway Ex - Intubate. Anesthetize. Train.   \n",
      "6923                        Amino: Communities and Chats   \n",
      "6955                                              Amtrak   \n",
      "8201   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "8875                               AppLock - Fingerprint   \n",
      "9110                                            Arrow.io   \n",
      "9165                       Asana: organize team projects   \n",
      "9368                                 Asphalt 8: Airborne   \n",
      "10602                          BBWCupid - BBW Dating App   \n",
      "12149                                        Banco ItaÃº   \n",
      "12340                   Bangla Newspaper â Prothom Alo   \n",
      "13023                                   Basketball Stars   \n",
      "13045                          Bathroom Decorating Ideas   \n",
      "13150                                 Battlelands Royale   \n",
      "13471                      Beauty Camera - Selfie Camera   \n",
      "17167                                         Bowmasters   \n",
      "17425                       Brain Waves - Binaural Beats   \n",
      "17777                                          Brilliant   \n",
      "18481                                  Buienradar - weer   \n",
      "19767  CBS Sports App - Scores, News, Stats & Watch Live   \n",
      "20850                        Calculator - unit converter   \n",
      "20919                     Calculator with Percent (Free)   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "27                                                                                          Healthy Eating   \n",
      "314                                               Took 5 seconds find rx get contacts ordered, convenient.   \n",
      "1330   I 700 hundred coins I new I 300 even I winning games player backing I played I waited player bac...   \n",
      "1751           Short intense workouts, perfect someone who's ready spend hours gym lots cash fitness plan!   \n",
      "2587                               The ads much flashing jumping around cannot even read articles. Deleted   \n",
      "3673                                                                                               Awesome   \n",
      "4512   All game great! I really enjoy years now. But thing keeping rating 5 stars. When \"create skin\" u...   \n",
      "4525   Your connection VERY VERY VERY BAD. When I home, I full connectio yet tell connection connection...   \n",
      "5170   Great detail! Might I ask , user could connect joystick app? If yes, help simulate airway evalua...   \n",
      "6923   This great! It's really fun mess around talk fellow people like things u! The downside logs rand...   \n",
      "6955                                                    Tickets itineraries load logging in. What good it?   \n",
      "8201   Not intuitive. Not even little bit. Share collaborate broken/badly bugged. Very easy make big me...   \n",
      "8875   Not reliable! When I reboot phone stops working. I start work making ur protected vulnerable. Pl...   \n",
      "9110                                                               It's good problems internet connections   \n",
      "9165                                                                                            It's mess.   \n",
      "9368   I can't seem continue progress new phone.I old samsung I bought another phone different brand tr...   \n",
      "10602                                    It's great view I hope y'all keep good work keep beautiful coming   \n",
      "12149                           Quick, handy is Copy / Paste's function of lines of code for easy payment.   \n",
      "12340                                                                         Too much ads . Too much ads.   \n",
      "13023                    Its great! But theres alot areas improve gameplay! Looking forward future updates   \n",
      "13045                                                                                           Waste time   \n",
      "13150  Really amazing game couple things still missing. Adding squad mode would awesome! Also make get ...   \n",
      "13471  I like except ads make impossible get much accomplished. I uninstall twice 'wish shopping app' a...   \n",
      "17167  Really like game far. Great gameplay lots fun. Edit: I took away star constant asking rate even ...   \n",
      "17425  Meh. I tried it. Frankly without lot blind testing I buy helpful brown noise appropriate music. ...   \n",
      "17777  It fun solving problems becomes money You guys take money presentation collection knowledge made...   \n",
      "18481       I need radar map. Lost days, found answer little upper right arrows. And works again. Perfect.   \n",
      "19767  This great recently. Now locks closes every single time open it. I've sent feedback couple weeks...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "\n",
      "       New_ID  \\\n",
      "27          5   \n",
      "314       101   \n",
      "1330      261   \n",
      "1751      401   \n",
      "2587      544   \n",
      "3673      743   \n",
      "4512      902   \n",
      "4525      905   \n",
      "5170     1036   \n",
      "6923     1369   \n",
      "6955     1380   \n",
      "8201     1663   \n",
      "8875     1779   \n",
      "9110     1837   \n",
      "9165     1848   \n",
      "9368     1897   \n",
      "10602    2190   \n",
      "12149    2556   \n",
      "12340    2617   \n",
      "13023    2821   \n",
      "13045    2824   \n",
      "13150    2857   \n",
      "13471    2960   \n",
      "17167    3565   \n",
      "17425    3644   \n",
      "17777    3706   \n",
      "18481    3820   \n",
      "19767    4079   \n",
      "20850    4281   \n",
      "20919    4282   \n",
      "\n",
      "                                                                                                       row  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "314    2*0.9333333333333333*0.7901234567901234*1800Contacts-LensStore*Took5secondsfindrxgetcontactsorde...  \n",
      "1330   3*0.3888888888888889*0.0*8BallPool*I700hundredcoinsInewI300evenIwinninggamesplayerbackingIplayed...  \n",
      "1751   3*0.3888888888888889*0.0*8fitWorkouts&MealPlanner*Shortintenseworkouts,perfectsomeonewho'sreadys...  \n",
      "2587   2*0.9185185185185185*0.7901234567901233*AC-Tips&NewsforAndroidâ¢*Theadsmuchflashingjumpingaroun...  \n",
      "3673   3*0.3888888888888889*0.0*AccountingApp-ZohoBooks*Awesome*743*3*0.3888888888888889*0.0*Accounting...  \n",
      "4512   3*0.3888888888888889*0.0*Agar.io*Allgamegreat!Ireallyenjoyyearsnow.Butthingkeepingrating5stars.W...  \n",
      "4525   2*0.8299580624542039*0.7359717577108886*Agar.io*YourconnectionVERYVERYVERYBAD.WhenIhome,Ifullcon...  \n",
      "5170   1*0.3888888888888889*0.0*AirwayEx-Intubate.Anesthetize.Train.*Greatdetail!MightIask,usercouldcon...  \n",
      "6923   3*0.3888888888888889*0.0*Amino:CommunitiesandChats*Thisgreat!It'sreallyfunmessaroundtalkfellowpe...  \n",
      "6955   3*0.3888888888888889*0.0*Amtrak*Ticketsitinerariesloadloggingin.Whatgoodit?*1380*3*0.38888888888...  \n",
      "8201   2*0.9555555555555555*0.8888888888888888*Any.do:To-dolist,Calendar,Reminders&Planner*Notintuitive...  \n",
      "8875   3*0.3888888888888889*0.0*AppLock-Fingerprint*Notreliable!WhenIrebootphonestopsworking.Istartwork...  \n",
      "9110   3*0.3888888888888889*0.0*Arrow.io*It'sgoodproblemsinternetconnections*1837*3*0.3888888888888889*...  \n",
      "9165   3*0.3888888888888889*0.0*Asana:organizeteamprojects*It'smess.*1848*3*0.3888888888888889*0.0*Asan...  \n",
      "9368   2*0.6277136970960085*0.5824264409512296*Asphalt8:Airborne*Ican'tseemcontinueprogressnewphone.Iol...  \n",
      "10602  2*0.7859563787163059*0.8943562610229276*BBWCupid-BBWDatingApp*It'sgreatviewIhopey'allkeepgoodwor...  \n",
      "12149  1*0.3888888888888889*0.0*BancoItaÃº*Quick,handyisCopy/Paste'sfunctionoflinesofcodeforeasypayment...  \n",
      "12340  3*0.3888888888888889*0.0*BanglaNewspaperâProthomAlo*Toomuchads.Toomuchads.*2617*3*0.3888888888...  \n",
      "13023  3*0.3888888888888889*0.0*BasketballStars*Itsgreat!Buttheresalotareasimprovegameplay!Lookingforwa...  \n",
      "13045  1*0.3888888888888889*0.0*BathroomDecoratingIdeas*Wastetime*2824*1*0.3888888888888889*0.0*Bathroo...  \n",
      "13150  3*0.3888888888888889*0.0*BattlelandsRoyale*Reallyamazinggamecouplethingsstillmissing.Addingsquad...  \n",
      "13471  3*0.3888888888888889*0.0*BeautyCamera-SelfieCamera*Ilikeexceptadsmakeimpossiblegetmuchaccomplish...  \n",
      "17167  3*0.3888888888888889*0.0*Bowmasters*Reallylikegamefar.Greatgameplaylotsfun.Edit:Itookawaystarcon...  \n",
      "17425  3*0.3888888888888889*0.0*BrainWaves-BinauralBeats*Meh.Itriedit.FranklywithoutlotblindtestingIbuy...  \n",
      "17777  3*0.3888888888888889*0.0*Brilliant*ItfunsolvingproblemsbecomesmoneyYouguystakemoneypresentationc...  \n",
      "18481  3*0.3888888888888889*0.0*Buienradar-weer*Ineedradarmap.Lostdays,foundanswerlittleupperrightarrow...  \n",
      "19767  3*0.3888888888888889*0.0*CBSSportsApp-Scores,News,Stats&WatchLive*Thisgreatrecently.Nowlocksclos...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "\n",
      "Outlier detection and removal done -- CPU time: 0.3392598628997803 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.371483\n",
       "Sentiment_Polarity        0.039849\n",
       "Sentiment_Subjectivity   -0.005547\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818172</td>\n",
       "      <td>0.855967</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738622</td>\n",
       "      <td>0.636168</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792242</td>\n",
       "      <td>0.660352</td>\n",
       "      <td>4279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.516755</td>\n",
       "      <td>4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4255 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "23       1.0            0.818172                0.855967       4\n",
       "28       1.0            0.738622                0.636168       6\n",
       "...      ...                 ...                     ...     ...\n",
       "20638    1.0            0.792242                0.660352    4279\n",
       "20639    1.0            0.911111                1.000000    4280\n",
       "20972    1.0            0.148148                0.516755    4283\n",
       "20998    1.0            0.388889                0.000000    4284\n",
       "21198    1.0            0.388889                0.000000    4285\n",
       "\n",
       "[4255 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4255, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4255, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.823\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0373\n",
      "Time:                        11:43:09   Log-Likelihood:                -20505.\n",
      "No. Observations:               16646   AIC:                         4.102e+04\n",
      "Df Residuals:                   16642   BIC:                         4.105e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3715      0.018     75.469      0.000       1.336       1.407\n",
      "Sentiment_Polarity         0.0398      0.029      1.395      0.163      -0.016       0.096\n",
      "Sentiment_Subjectivity    -0.0055      0.019     -0.290      0.772      -0.043       0.032\n",
      "New_ID                  3.369e-06   1.34e-06      2.523      0.012    7.52e-07    5.99e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4418.237   Durbin-Watson:                   1.752\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2888.526\n",
      "Skew:                          -0.907   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.065   Cond. No.                     4.86e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.86e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7091286823663995\n",
      "Regression done -- CPU time: 0.03788113594055176 seconds\n",
      "End Pipeline CPU time: 0.4372129440307617 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> OLS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 1.9108860492706299 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.399892\n",
       "Sentiment_Polarity        0.040653\n",
       "Sentiment_Subjectivity   -0.006129\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818172</td>\n",
       "      <td>0.855967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.790123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.516755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity\n",
       "10       1.0            0.715793                0.735972\n",
       "16       1.0            0.388889                0.000000\n",
       "20       1.0            0.388889                0.000000\n",
       "23       1.0            0.818172                0.855967\n",
       "27       1.0            0.955556                0.907407\n",
       "...      ...                 ...                     ...\n",
       "20850    1.0            0.388889                0.000000\n",
       "20919    1.0            0.962963                0.790123\n",
       "20972    1.0            0.148148                0.516755\n",
       "20998    1.0            0.388889                0.000000\n",
       "21198    1.0            0.388889                0.000000\n",
       "\n",
       "[4285 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.100\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):              0.333\n",
      "Time:                        11:43:11   Log-Likelihood:                -20541.\n",
      "No. Observations:               16676   AIC:                         4.109e+04\n",
      "Df Residuals:                   16673   BIC:                         4.111e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3999      0.014     97.901      0.000       1.372       1.428\n",
      "Sentiment_Polarity         0.0407      0.029      1.423      0.155      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0061      0.019     -0.320      0.749      -0.044       0.031\n",
      "==============================================================================\n",
      "Omnibus:                     4424.227   Durbin-Watson:                   1.753\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2898.833\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.065   Cond. No.                         6.04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7090029971778065\n",
      "Regression done -- CPU time: 0.03754901885986328 seconds\n",
      "End Pipeline CPU time: 1.948911190032959 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.372401\n",
       "Sentiment_Polarity        0.040811\n",
       "Sentiment_Subjectivity   -0.005926\n",
       "New_ID                    0.000003\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.735972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818172</td>\n",
       "      <td>0.855967</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>4282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.516755</td>\n",
       "      <td>4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
       "10       1.0            0.715793                0.735972       1\n",
       "16       1.0            0.388889                0.000000       2\n",
       "20       1.0            0.388889                0.000000       3\n",
       "23       1.0            0.818172                0.855967       4\n",
       "27       1.0            0.955556                0.907407       5\n",
       "...      ...                 ...                     ...     ...\n",
       "20850    1.0            0.388889                0.000000    4281\n",
       "20919    1.0            0.962963                0.790123    4282\n",
       "20972    1.0            0.148148                0.516755    4283\n",
       "20998    1.0            0.388889                0.000000    4284\n",
       "21198    1.0            0.388889                0.000000    4285\n",
       "\n",
       "[4285 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4285, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              Sentiment   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.746\n",
      "Date:                Thu, 09 Jun 2022   Prob (F-statistic):             0.0414\n",
      "Time:                        11:43:11   Log-Likelihood:                -20538.\n",
      "No. Observations:               16676   AIC:                         4.108e+04\n",
      "Df Residuals:                   16672   BIC:                         4.111e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      1.3724      0.018     75.599      0.000       1.337       1.408\n",
      "Sentiment_Polarity         0.0408      0.029      1.429      0.153      -0.015       0.097\n",
      "Sentiment_Subjectivity    -0.0059      0.019     -0.310      0.757      -0.043       0.032\n",
      "New_ID                  3.278e-06   1.33e-06      2.457      0.014    6.63e-07    5.89e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4396.236   Durbin-Watson:                   1.754\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2897.242\n",
      "Skew:                          -0.908   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.067   Cond. No.                     4.87e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.87e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7085140234413241\n",
      "Regression done -- CPU time: 0.03992581367492676 seconds\n",
      "End Pipeline CPU time: 0.04010319709777832 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> AD -> OLS', 'MM -> LOF -> OLS', 'ZS -> IQR -> OLS', 'WR -> IQR -> OLS', 'LC -> IQR -> OLS', 'Tree -> IQR -> OLS', 'ZSB -> Tree -> IQR -> OLS', 'LOF -> OLS', 'IQR -> OLS', 'CC -> OLS', 'PC -> ED -> LOF -> OLS', 'ED -> LOF -> OLS', 'AD -> OLS']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.7090616625839601}, {'quality_metric': 0.7098646330792925}, {'quality_metric': 0.7097725841264618}, {'quality_metric': 0.7085140234413241}, {'quality_metric': 8176.870637302701}, {'quality_metric': 0.7085140234413241}, {'quality_metric': 0.7061822160225694}, {'quality_metric': 0.7091286823663995}, {'quality_metric': 0.7085140234413241}, {'quality_metric': 0.7085140234413241}, {'quality_metric': None}, {'quality_metric': 0.7091286823663995}, {'quality_metric': 0.7090029971778065}, {'quality_metric': 0.7085140234413241}]\n",
      "\n",
      "Strategy ZSB -> Tree -> IQR -> OLS for minimal MSE  0.7061822160225694 for OLS\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 5.913940906524658 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'OLS', 'Sentiment', None, 'ZSB -> Tree -> IQR -> OLS', 'MSE', 0.7061822160225694, 5.913940906524658)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='OLS',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = True)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.1443009376525879 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> LOF -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02811908721923828 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.2717099189758301 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5707391881041924\n",
      "Regression done -- CPU time: 2.270158052444458 seconds\n",
      "End Pipeline CPU time: 2.5701870918273926 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> LOF -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.029079914093017578 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.2864110469818115 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5646384692022199\n",
      "Regression done -- CPU time: 2.2691750526428223 seconds\n",
      "End Pipeline CPU time: 2.5848708152770996 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> AD -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.0223081111907959 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.1054770946502686 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.448183406219679\n",
      "Regression done -- CPU time: 1.424440860748291 seconds\n",
      "End Pipeline CPU time: 3.5527539253234863 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> MM -> LOF -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.016108036041259766 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02296590805053711 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.28919386863708496 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5646384692022199\n",
      "Regression done -- CPU time: 2.250092029571533 seconds\n",
      "End Pipeline CPU time: 2.5802059173583984 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> ZS -> AD -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.014003992080688477 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02048492431640625 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.005669116973877 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Error: Need at least one continous variable and  10  observations for regression\n",
      "Regression done -- CPU time: 0.00398707389831543 seconds\n",
      "End Pipeline CPU time: 2.046253204345703 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> ZSB -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.03144502639770508 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.45084006967552287\n",
      "Regression done -- CPU time: 3.8212950229644775 seconds\n",
      "End Pipeline CPU time: 3.8528099060058594 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.031736135482788086 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.45084006967552287\n",
      "Regression done -- CPU time: 3.836669921875 seconds\n",
      "End Pipeline CPU time: 3.8684890270233154 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.34847211837768555 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5721745727871003\n",
      "Regression done -- CPU time: 2.292546272277832 seconds\n",
      "End Pipeline CPU time: 2.6410861015319824 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.03215789794921875 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5696421430412768\n",
      "Regression done -- CPU time: 2.322467088699341 seconds\n",
      "End Pipeline CPU time: 2.3546972274780273 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.11174893379211426 seconds\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5696421430412768\n",
      "Regression done -- CPU time: 2.306980848312378 seconds\n",
      "End Pipeline CPU time: 2.4187910556793213 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> IQR -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.08009600639343262 seconds\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "No outlier detection for train dataset\n",
      "No outlier detection for test dataset\n",
      "Outlier detection and removal done -- CPU time: 9.703636169433594e-05 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Error: Need at least one continous variable and  10  observations for regression\n",
      "Regression done -- CPU time: 0.002003908157348633 seconds\n",
      "End Pipeline CPU time: 0.08230304718017578 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> PC -> IQR -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.05595088005065918 seconds\n",
      "\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.08056497573852539 seconds\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "No outlier detection for train dataset\n",
      "No outlier detection for test dataset\n",
      "Outlier detection and removal done -- CPU time: 9.083747863769531e-05 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Error: Need at least one continous variable and  10  observations for regression\n",
      "Regression done -- CPU time: 0.001956939697265625 seconds\n",
      "End Pipeline CPU time: 0.13871216773986816 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> MARS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.0832700729370117 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.448183406219679\n",
      "Regression done -- CPU time: 1.4197850227355957 seconds\n",
      "End Pipeline CPU time: 3.5032808780670166 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5696421430412768\n",
      "Regression done -- CPU time: 2.320935010910034 seconds\n",
      "End Pipeline CPU time: 2.320965051651001 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> LOF -> MARS', 'MM -> LOF -> MARS', 'ZS -> AD -> MARS', 'WR -> MM -> LOF -> MARS', 'LC -> ZS -> AD -> MARS', 'Tree -> ZSB -> MARS', 'ZSB -> MARS', 'LOF -> MARS', 'IQR -> MARS', 'CC -> MARS', 'PC -> IQR -> MARS', 'ED -> PC -> IQR -> MARS', 'AD -> MARS']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.5707391881041924}, {'quality_metric': 0.5646384692022199}, {'quality_metric': 0.448183406219679}, {'quality_metric': 0.5646384692022199}, {'quality_metric': None}, {'quality_metric': 0.45084006967552287}, {'quality_metric': 0.45084006967552287}, {'quality_metric': 0.5721745727871003}, {'quality_metric': 0.5696421430412768}, {'quality_metric': 0.5696421430412768}, {'quality_metric': None}, {'quality_metric': None}, {'quality_metric': 0.448183406219679}, {'quality_metric': 0.5696421430412768}]\n",
      "\n",
      "Strategy LOF -> MARS for maximal MSE : 0.5721745727871003 for MARS\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 34.52398371696472 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'MARS', 'Sentiment', None, 'LOF -> MARS', 'MSE', 0.5721745727871003, 34.52398371696472)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='MARS',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.17999577522277832 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> AD -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03656506538391113 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.415724992752075 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.85  for k= 3\n",
      "Quality of clustering 0.85\n",
      "Clustering done -- CPU time: 46.33231019973755 seconds\n",
      "End Pipeline CPU time: 48.78771996498108 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> LOF -> AD -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02909684181213379 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.28160810470581055 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.098701000213623 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8313  for k= 3\n",
      "Quality of clustering 0.8313\n",
      "Clustering done -- CPU time: 44.03174901008606 seconds\n",
      "End Pipeline CPU time: 46.44431185722351 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> IQR -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.021338224411010742 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02475595474243164 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.5099  for k= 3\n",
      "Quality of clustering 0.5099\n",
      "Clustering done -- CPU time: 37.09937000274658 seconds\n",
      "End Pipeline CPU time: 37.14858794212341 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> IQR -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.015429019927978516 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.025788068771362305 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6263  for k= 2\n",
      "Quality of clustering 0.6263\n",
      "Clustering done -- CPU time: 31.076488971710205 seconds\n",
      "End Pipeline CPU time: 31.121659755706787 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> IQR -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.015314817428588867 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.0347447395324707 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6261  for k= 2\n",
      "Quality of clustering 0.6261\n",
      "Clustering done -- CPU time: 30.40576410293579 seconds\n",
      "End Pipeline CPU time: 30.461148977279663 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> IQR -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02937602996826172 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6263  for k= 2\n",
      "Quality of clustering 0.6263\n",
      "Clustering done -- CPU time: 30.98159098625183 seconds\n",
      "End Pipeline CPU time: 31.01486086845398 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> Tree -> IQR -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.03041696548461914 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.028097152709960938 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.5767  for k= 3\n",
      "Quality of clustering 0.5767\n",
      "Clustering done -- CPU time: 20.074506998062134 seconds\n",
      "End Pipeline CPU time: 20.137582778930664 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> AD -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.32490086555480957 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.160115957260132 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8314  for k= 3\n",
      "Quality of clustering 0.8314\n",
      "Clustering done -- CPU time: 44.098849058151245 seconds\n",
      "End Pipeline CPU time: 46.58683705329895 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.029878854751586914 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6263  for k= 2\n",
      "Quality of clustering 0.6263\n",
      "Clustering done -- CPU time: 30.94772696495056 seconds\n",
      "End Pipeline CPU time: 30.980618953704834 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.1000068187713623 seconds\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6263  for k= 2\n",
      "Quality of clustering 0.6263\n",
      "Clustering done -- CPU time: 30.86827802658081 seconds\n",
      "End Pipeline CPU time: 30.968367099761963 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> ED -> LOF -> AD -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.07440805435180664 seconds\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "No train dataset, no duplicate detection\n",
      "No test dataset, no duplicate detection\n",
      "Deduplication done -- CPU time: 9.799003601074219e-05 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "No outlier detection for train dataset\n",
      "No outlier detection for test dataset\n",
      "Outlier detection and removal done -- CPU time: 9.489059448242188e-05 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "No train dataset, no duplicate detection\n",
      "No test dataset, no duplicate detection\n",
      "Deduplication done -- CPU time: 5.507469177246094e-05 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Error: There are too few observations\n",
      "Quality of clustering None\n",
      "Clustering done -- CPU time: 0.0013229846954345703 seconds\n",
      "End Pipeline CPU time: 0.07610702514648438 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> LOF -> AD -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.04710221290588379 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.3233058452606201 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.2991838455200195 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8314  for k= 3\n",
      "Quality of clustering 0.8314\n",
      "Clustering done -- CPU time: 43.76087403297424 seconds\n",
      "End Pipeline CPU time: 46.434041023254395 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> HCA\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.237467050552368 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8315  for k= 3\n",
      "Quality of clustering 0.8315\n",
      "Clustering done -- CPU time: 43.9974730014801 seconds\n",
      "End Pipeline CPU time: 46.23840308189392 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6263  for k= 2\n",
      "Quality of clustering 0.6263\n",
      "Clustering done -- CPU time: 32.032461166381836 seconds\n",
      "End Pipeline CPU time: 32.03249502182007 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> AD -> HCA', 'MM -> LOF -> AD -> HCA', 'ZS -> IQR -> HCA', 'WR -> IQR -> HCA', 'LC -> IQR -> HCA', 'Tree -> IQR -> HCA', 'ZSB -> Tree -> IQR -> HCA', 'LOF -> AD -> HCA', 'IQR -> HCA', 'CC -> HCA', 'PC -> ED -> LOF -> AD -> HCA', 'ED -> LOF -> AD -> HCA', 'AD -> HCA']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.85, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.857349                0.903060           1\n",
      "1                1.000000                0.553142           1\n",
      "3                0.222222                0.000000           0\n",
      "4                0.222222                0.000000           0\n",
      "5                0.222222                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43066            0.222222                0.000000           0\n",
      "43070            0.911111                1.000000           1\n",
      "43072            0.802910                0.794576           1\n",
      "43075            0.222222                0.000000           0\n",
      "43076            0.933333                0.919144           1\n",
      "\n",
      "[16676 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.719660                0.724321         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.819807                0.852755         2   \n",
      "27               0.955556                0.907407         2   \n",
      "...                   ...                     ...       ...   \n",
      "20850            0.388889                0.000000         3   \n",
      "20919            0.962963                0.780488         2   \n",
      "20972            0.111111                0.548125         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "27                                                                                          Healthy Eating  \n",
      "...                                                                                                    ...  \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?  \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4285 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8313, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           2\n",
      "1                1.000000                0.543201           2\n",
      "3                0.388889                0.000000           0\n",
      "4                0.388889                0.000000           0\n",
      "5                0.388889                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43066            0.388889                0.000000           0\n",
      "43070            0.911111                1.000000           2\n",
      "43072            0.805298                0.789116           2\n",
      "43075            0.388889                0.000000           0\n",
      "43076            0.933333                0.916667           2\n",
      "\n",
      "[16646 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.715793                0.735972         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.818172                0.855967         2   \n",
      "27               0.955556                0.907407         2   \n",
      "...                   ...                     ...       ...   \n",
      "20850            0.388889                0.000000         3   \n",
      "20919            0.962963                0.790123         2   \n",
      "20972            0.148148                0.516755         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "27                                                                                          Healthy Eating  \n",
      "...                                                                                                    ...  \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?  \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4253 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.5099, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID  cluster_ID\n",
      "0                1.355292                1.362734 -1.731895           1\n",
      "1                1.907740                0.431451 -1.731687           1\n",
      "3               -0.473548               -0.986005 -1.731480           0\n",
      "4               -0.473548               -0.986005 -1.731272           0\n",
      "5               -0.473548               -0.986005 -1.731064           0\n",
      "...                   ...                     ...       ...         ...\n",
      "43066           -0.473548               -0.986005  1.731064           0\n",
      "43070            1.561371                1.623445  1.731272           1\n",
      "43072            1.149055                1.073153  1.731480           1\n",
      "43075           -0.473548               -0.986005  1.731687           0\n",
      "43076            1.647963                1.405991  1.731895           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID Sentiment  \\\n",
      "10               0.807272                0.918389 -1.731445         2   \n",
      "16396            1.697853                1.250214  0.995864         2   \n",
      "16398            0.191978                0.798182  0.996672         2   \n",
      "16              -0.465994               -0.986172 -1.730636         3   \n",
      "20              -0.465994               -0.986172 -1.729828         3   \n",
      "...                   ...                     ...       ...       ...   \n",
      "16364           -0.465994               -0.986172  0.991822         3   \n",
      "16366            0.777633                0.774141  0.992630         2   \n",
      "16372            1.568022                1.362034  0.993439         2   \n",
      "16377           -0.465994               -0.986172  0.994247         3   \n",
      "16378           -1.616249                1.101122  0.995055         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6263, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID\n",
      "10               0.715793                0.735972       1\n",
      "16396            0.944444                0.864198    3375\n",
      "16398            0.557819                0.689521    3376\n",
      "16               0.388889                0.000000       2\n",
      "20               0.388889                0.000000       3\n",
      "...                   ...                     ...     ...\n",
      "16364            0.388889                0.000000    3370\n",
      "16366            0.708183                0.680230    3371\n",
      "16372            0.911111                0.907407    3372\n",
      "16377            0.388889                0.000000    3373\n",
      "16378            0.093567                0.806584    3374\n",
      "\n",
      "[4285 rows x 3 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6261, 'result': {'train':        Sentiment_Polarity  New_ID  cluster_ID\n",
      "0                0.858225       1           1\n",
      "1                1.000000       2           1\n",
      "3                0.388889       3           1\n",
      "4                0.388889       4           1\n",
      "5                0.388889       5           1\n",
      "...                   ...     ...         ...\n",
      "43066            0.388889   16672           0\n",
      "43070            0.911111   16673           0\n",
      "43072            0.805298   16674           0\n",
      "43075            0.388889   16675           0\n",
      "43076            0.933333   16676           0\n",
      "\n",
      "[16676 rows x 3 columns], 'test':        New_ID  Sentiment_Polarity Sentiment                           App  \\\n",
      "10          1            0.715793         2         10 Best Foods for You   \n",
      "16396    3375            0.944444         2      Blood Pressure(BP) Diary   \n",
      "16398    3376            0.557819         2      Blood Pressure(BP) Diary   \n",
      "16          2            0.388889         3         10 Best Foods for You   \n",
      "20          3            0.388889         3         10 Best Foods for You   \n",
      "...       ...                 ...       ...                           ...   \n",
      "16364    3370            0.388889         3  Blood Pressure Log - MyDiary   \n",
      "16366    3371            0.708183         2  Blood Pressure Log - MyDiary   \n",
      "16372    3372            0.911111         2      Blood Pressure(BP) Diary   \n",
      "16377    3373            0.388889         3      Blood Pressure(BP) Diary   \n",
      "16378    3374            0.093567         0      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 6 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6263, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID Sentiment  \\\n",
      "10               0.715793                0.735972       1         2   \n",
      "16396            0.944444                0.864198    3375         2   \n",
      "16398            0.557819                0.689521    3376         2   \n",
      "16               0.388889                0.000000       2         3   \n",
      "20               0.388889                0.000000       3         3   \n",
      "...                   ...                     ...     ...       ...   \n",
      "16364            0.388889                0.000000    3370         3   \n",
      "16366            0.708183                0.680230    3371         2   \n",
      "16372            0.911111                0.907407    3372         2   \n",
      "16377            0.388889                0.000000    3373         3   \n",
      "16378            0.093567                0.806584    3374         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.5767, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "3                0.388889                0.000000       3           2\n",
      "4                0.388889                0.000000       4           2\n",
      "5                0.388889                0.000000       5           2\n",
      "6                0.388889                0.000000       6           2\n",
      "8                0.711375                0.895833       7           2\n",
      "...                   ...                     ...     ...         ...\n",
      "32698            0.109029                0.623007   13012           1\n",
      "32699            0.388889                0.000000   13013           1\n",
      "32705            0.388889                0.000000   13014           1\n",
      "32716            0.388889                0.000000   13017           1\n",
      "32722            0.084156                0.595664   13018           1\n",
      "\n",
      "[12672 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID Sentiment  \\\n",
      "8192             0.388889                0.000000    1661         3   \n",
      "8196             0.388889                0.000000    1662         3   \n",
      "10               0.715793                0.735972       1         2   \n",
      "8202             0.388889                0.000000    1664         3   \n",
      "16398            0.557819                0.689521    3376         2   \n",
      "...                   ...                     ...     ...       ...   \n",
      "8175             0.388889                0.000000    1656         3   \n",
      "8177             0.738622                0.507937    1657         2   \n",
      "16377            0.388889                0.000000    3373         3   \n",
      "16378            0.093567                0.806584    3374         0   \n",
      "8190             0.388889                0.000000    1660         1   \n",
      "\n",
      "                                                     App  \\\n",
      "8192   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "8196   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "10                                 10 Best Foods for You   \n",
      "8202   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "16398                           Blood Pressure(BP) Diary   \n",
      "...                                                  ...   \n",
      "8175   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "8177   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "16377                           Blood Pressure(BP) Diary   \n",
      "16378                           Blood Pressure(BP) Diary   \n",
      "8190   Any.do: To-do list, Calendar, Reminders & Planner   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "8192   It's amazing app, easy helped keep responsibilities. There's detail bothers me, glitch. When I e...   \n",
      "8196   I told I free 7 days. My subscription due expire tomorrow deducted entire year fees 1-day I coul...   \n",
      "10                                                                                               good you.   \n",
      "8202                         Great app! The thing bothers crossing done task often mistakes underneath it.   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "...                                                                                                    ...   \n",
      "8175                                                                   Quick easy way organize activities.   \n",
      "8177                                                                     Been using couple weeks, love it!   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "8190   I told I free 7 days. My subscription due expire tomorrow deducted entire year fees 1-day I coul...   \n",
      "\n",
      "                                                                                                       row  \n",
      "8192   3*0.3888888888888889*0.0*Any.do:To-dolist,Calendar,Reminders&Planner*It'samazingapp,easyhelpedke...  \n",
      "8196   3*0.3888888888888889*0.0*Any.do:To-dolist,Calendar,Reminders&Planner*ItoldIfree7days.Mysubscript...  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "8202   3*0.3888888888888889*0.0*Any.do:To-dolist,Calendar,Reminders&Planner*Greatapp!Thethingbotherscro...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "...                                                                                                    ...  \n",
      "8175   3*0.3888888888888889*0.0*Any.do:To-dolist,Calendar,Reminders&Planner*Quickeasywayorganizeactivit...  \n",
      "8177   2*0.7386220123177936*0.5079365079365079*Any.do:To-dolist,Calendar,Reminders&Planner*Beenusingcou...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "8190   1*0.3888888888888889*0.0*Any.do:To-dolist,Calendar,Reminders&Planner*ItoldIfree7days.Mysubscript...  \n",
      "\n",
      "[3321 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8314, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           2\n",
      "1                1.000000                0.543201           2\n",
      "3                0.388889                0.000000           0\n",
      "4                0.388889                0.000000           0\n",
      "6                0.388889                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43064            0.096731                0.499309           1\n",
      "43070            0.911111                1.000000           2\n",
      "43072            0.805298                0.789116           2\n",
      "43075            0.388889                0.000000           0\n",
      "43076            0.933333                0.916667           2\n",
      "\n",
      "[16646 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.715793                0.735972         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.818172                0.855967         2   \n",
      "28               0.738622                0.636168         2   \n",
      "...                   ...                     ...       ...   \n",
      "20638            0.792242                0.660352         2   \n",
      "20639            0.911111                1.000000         2   \n",
      "20972            0.148148                0.516755         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                                      App  \\\n",
      "10                                  10 Best Foods for You   \n",
      "16                                  10 Best Foods for You   \n",
      "20                                  10 Best Foods for You   \n",
      "23                                  10 Best Foods for You   \n",
      "28                                  10 Best Foods for You   \n",
      "...                                                   ...   \n",
      "20638  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20639  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20972                      Calendar Widget Month + Agenda   \n",
      "20998                      Calendar+ Schedule Planner App   \n",
      "21198                      Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "28                                                                                   Very good Simply good  \n",
      "...                                                                                                    ...  \n",
      "20638                                                          Please add something scan protect browsers.  \n",
      "20639                          Good actually works. It enhances net speed great extent. Really useful app.  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4255 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6263, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID Sentiment  \\\n",
      "10               0.715793                0.735972       1         2   \n",
      "16396            0.944444                0.864198    3375         2   \n",
      "16398            0.557819                0.689521    3376         2   \n",
      "16               0.388889                0.000000       2         3   \n",
      "20               0.388889                0.000000       3         3   \n",
      "...                   ...                     ...     ...       ...   \n",
      "16364            0.388889                0.000000    3370         3   \n",
      "16366            0.708183                0.680230    3371         2   \n",
      "16372            0.911111                0.907407    3372         2   \n",
      "16377            0.388889                0.000000    3373         3   \n",
      "16378            0.093567                0.806584    3374         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6263, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "10            2            0.715793                0.735972   \n",
      "16            3            0.388889                0.000000   \n",
      "20            3            0.388889                0.000000   \n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "...         ...                 ...                     ...   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "20972         0            0.148148                0.516755   \n",
      "20998         3            0.388889                0.000000   \n",
      "21198         3            0.388889                0.000000   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.   \n",
      "27                                                                                          Healthy Eating   \n",
      "...                                                                                                    ...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "20972                                My problem I already purchased cannot can't update setting appearance   \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...   \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...   \n",
      "\n",
      "       New_ID  \\\n",
      "10          1   \n",
      "16          2   \n",
      "20          3   \n",
      "23          4   \n",
      "27          5   \n",
      "...       ...   \n",
      "20850    4281   \n",
      "20919    4282   \n",
      "20972    4283   \n",
      "20998    4284   \n",
      "21198    4285   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "23     2*0.8181718971672669*0.8559670781893003*10BestFoodsforYou*HEALTHSHOULDALWAYSBETOPPRIORITY.!!.ONM...  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "...                                                                                                    ...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "20972  0*0.14814814814814814*0.5167548500881834*CalendarWidgetMonth+Agenda*MyproblemIalreadypurchasedca...  \n",
      "20998  3*0.3888888888888889*0.0*Calendar+SchedulePlannerApp*Updated2015:STILapp,stilllovestillhighlyrec...  \n",
      "21198  3*0.3888888888888889*0.0*CallofDuty:BlackOpsZombies*ThisGAMEDOESN'TEVENLAUNCH!!!,everytimeIgopla...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': None, 'result': {'train': Empty DataFrame\n",
      "Columns: [Sentiment, App, Translated_Review, row]\n",
      "Index: [], 'test': Empty DataFrame\n",
      "Columns: [Sentiment, App, Translated_Review, row]\n",
      "Index: [], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8314, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           2\n",
      "1                1.000000                0.543201           2\n",
      "3                0.388889                0.000000           0\n",
      "4                0.388889                0.000000           0\n",
      "6                0.388889                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43064            0.096731                0.499309           1\n",
      "43070            0.911111                1.000000           2\n",
      "43072            0.805298                0.789116           2\n",
      "43075            0.388889                0.000000           0\n",
      "43076            0.933333                0.916667           2\n",
      "\n",
      "[16646 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.715793                0.735972         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.818172                0.855967         2   \n",
      "28               0.738622                0.636168         2   \n",
      "...                   ...                     ...       ...   \n",
      "20638            0.792242                0.660352         2   \n",
      "20639            0.911111                1.000000         2   \n",
      "20972            0.148148                0.516755         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                                      App  \\\n",
      "10                                  10 Best Foods for You   \n",
      "16                                  10 Best Foods for You   \n",
      "20                                  10 Best Foods for You   \n",
      "23                                  10 Best Foods for You   \n",
      "28                                  10 Best Foods for You   \n",
      "...                                                   ...   \n",
      "20638  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20639  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20972                      Calendar Widget Month + Agenda   \n",
      "20998                      Calendar+ Schedule Planner App   \n",
      "21198                      Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "28                                                                                   Very good Simply good  \n",
      "...                                                                                                    ...  \n",
      "20638                                                          Please add something scan protect browsers.  \n",
      "20639                          Good actually works. It enhances net speed great extent. Really useful app.  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4255 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8315, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           2\n",
      "1                1.000000                0.543201           2\n",
      "3                0.388889                0.000000           0\n",
      "4                0.388889                0.000000           0\n",
      "5                0.388889                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43066            0.388889                0.000000           0\n",
      "43070            0.911111                1.000000           2\n",
      "43072            0.805298                0.789116           2\n",
      "43075            0.388889                0.000000           0\n",
      "43076            0.933333                0.916667           2\n",
      "\n",
      "[16676 rows x 3 columns], 'test':       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "10            2            0.715793                0.735972   \n",
      "16            3            0.388889                0.000000   \n",
      "20            3            0.388889                0.000000   \n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "...         ...                 ...                     ...   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "20972         0            0.148148                0.516755   \n",
      "20998         3            0.388889                0.000000   \n",
      "21198         3            0.388889                0.000000   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "27                                                                                          Healthy Eating  \n",
      "...                                                                                                    ...  \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?  \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4285 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6263, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "10            2            0.715793                0.735972   \n",
      "16            3            0.388889                0.000000   \n",
      "20            3            0.388889                0.000000   \n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "...         ...                 ...                     ...   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "20972         0            0.148148                0.516755   \n",
      "20998         3            0.388889                0.000000   \n",
      "21198         3            0.388889                0.000000   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.   \n",
      "27                                                                                          Healthy Eating   \n",
      "...                                                                                                    ...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "20972                                My problem I already purchased cannot can't update setting appearance   \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...   \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...   \n",
      "\n",
      "       New_ID  \\\n",
      "10          1   \n",
      "16          2   \n",
      "20          3   \n",
      "23          4   \n",
      "27          5   \n",
      "...       ...   \n",
      "20850    4281   \n",
      "20919    4282   \n",
      "20972    4283   \n",
      "20998    4284   \n",
      "21198    4285   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "23     2*0.8181718971672669*0.8559670781893003*10BestFoodsforYou*HEALTHSHOULDALWAYSBETOPPRIORITY.!!.ONM...  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "...                                                                                                    ...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "20972  0*0.14814814814814814*0.5167548500881834*CalendarWidgetMonth+Agenda*MyproblemIalreadypurchasedca...  \n",
      "20998  3*0.3888888888888889*0.0*Calendar+SchedulePlannerApp*Updated2015:STILapp,stilllovestillhighlyrec...  \n",
      "21198  3*0.3888888888888889*0.0*CallofDuty:BlackOpsZombies*ThisGAMEDOESN'TEVENLAUNCH!!!,everytimeIgopla...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}]\n",
      "\n",
      "Strategy DS -> AD -> HCA for maximal silhouette : 0.85 for HCA\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 478.5266408920288 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'HCA', 'Sentiment', None, 'DS -> AD -> HCA', 'silhouette', 0.85, 478.5266408920288)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='HCA',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start DoubleLearn2Clean\n",
      "DoubleLearn2Clean - Pipeline construction -- CPU time: 0.14678382873535156 seconds\n",
      "=== Start Pipeline Execution ===\n",
      "\n",
      "\n",
      "Strategy# 0 : Greedy traversal for starting state DS\n",
      "DS -> LOF -> AD -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03138399124145508 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.28371095657348633 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.4037559032440186 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8499  for k= 3\n",
      "Quality of clustering 0.8499\n",
      "Clustering done -- CPU time: 15.006830930709839 seconds\n",
      "End Pipeline CPU time: 17.726470947265625 seconds\n",
      "\n",
      "\n",
      "Strategy# 1 : Greedy traversal for starting state MM\n",
      "MM -> AD -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03237175941467285 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.5299439430236816 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8315  for k= 3\n",
      "Quality of clustering 0.8315\n",
      "Clustering done -- CPU time: 15.261153936386108 seconds\n",
      "End Pipeline CPU time: 17.8240749835968 seconds\n",
      "\n",
      "\n",
      "Strategy# 2 : Greedy traversal for starting state ZS\n",
      "ZS -> IQR -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.021988868713378906 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.02842092514038086 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.5195  for k= 5\n",
      "Quality of clustering 0.5195\n",
      "Clustering done -- CPU time: 15.664610147476196 seconds\n",
      "End Pipeline CPU time: 15.718593120574951 seconds\n",
      "\n",
      "\n",
      "Strategy# 3 : Greedy traversal for starting state WR\n",
      "WR -> ZS -> IQR -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.01660299301147461 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.01706218719482422 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.020318984985351562 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.5195  for k= 5\n",
      "Quality of clustering 0.5195\n",
      "Clustering done -- CPU time: 16.335705995559692 seconds\n",
      "End Pipeline CPU time: 16.391356945037842 seconds\n",
      "\n",
      "\n",
      "Strategy# 4 : Greedy traversal for starting state LC\n",
      "LC -> LOF -> AD -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.013684988021850586 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.3198568820953369 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.4707088470458984 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8519  for k= 3\n",
      "Quality of clustering 0.8519\n",
      "Clustering done -- CPU time: 16.643585920333862 seconds\n",
      "End Pipeline CPU time: 19.450326919555664 seconds\n",
      "\n",
      "\n",
      "Strategy# 5 : Greedy traversal for starting state Tree\n",
      "Tree -> IQR -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.03690075874328613 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6267  for k= 2\n",
      "Quality of clustering 0.6267\n",
      "Clustering done -- CPU time: 16.6425940990448 seconds\n",
      "End Pipeline CPU time: 16.683066844940186 seconds\n",
      "\n",
      "\n",
      "Strategy# 6 : Greedy traversal for starting state ZSB\n",
      "ZSB -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.0328524112701416 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6261  for k= 2\n",
      "Quality of clustering 0.6261\n",
      "Clustering done -- CPU time: 10.454693794250488 seconds\n",
      "End Pipeline CPU time: 10.488080263137817 seconds\n",
      "\n",
      "\n",
      "Strategy# 7 : Greedy traversal for starting state LOF\n",
      "LOF -> AD -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.33904480934143066 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.442333936691284 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8314  for k= 3\n",
      "Quality of clustering 0.8314\n",
      "Clustering done -- CPU time: 14.922677040100098 seconds\n",
      "End Pipeline CPU time: 17.704613208770752 seconds\n",
      "\n",
      "\n",
      "Strategy# 8 : Greedy traversal for starting state IQR\n",
      "IQR -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.030189037322998047 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6267  for k= 2\n",
      "Quality of clustering 0.6267\n",
      "Clustering done -- CPU time: 16.679910898208618 seconds\n",
      "End Pipeline CPU time: 16.714733839035034 seconds\n",
      "\n",
      "\n",
      "Strategy# 9 : Greedy traversal for starting state CC\n",
      "CC -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "* For test dataset\n",
      "Constraints from the file: gpsu_example_constraints.tdda\n",
      "Constraints passing: 16\n",
      "\n",
      "Constraints failing: 2\n",
      "\n",
      "Consistency checking done -- CPU time: 0.10971689224243164 seconds\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6267  for k= 2\n",
      "Quality of clustering 0.6267\n",
      "Clustering done -- CPU time: 16.62291669845581 seconds\n",
      "End Pipeline CPU time: 16.732694149017334 seconds\n",
      "\n",
      "\n",
      "Strategy# 10 : Greedy traversal for starting state PC\n",
      "PC -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Consistency checking\n",
      "* For train dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 15366\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 16676\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "* For test dataset\n",
      "Number of pattern violations on variable ' App 'for pattern# 0 : 3898\n",
      "Number of pattern violations on variable ' Sentiment 'for pattern# 0 : 4285\n",
      "No record from the dataset satisfied the patterns!\n",
      "Will return empty dataset - please change our patterns\n",
      "Consistency checking done -- CPU time: 0.07553291320800781 seconds\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Error: There are too few observations\n",
      "Quality of clustering None\n",
      "Clustering done -- CPU time: 0.00144195556640625 seconds\n",
      "End Pipeline CPU time: 0.07702898979187012 seconds\n",
      "\n",
      "\n",
      "Strategy# 11 : Greedy traversal for starting state ED\n",
      "ED -> ZS -> IQR -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.06014895439147949 seconds\n",
      "\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.020090103149414062 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.022881031036376953 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best silhouette = 0.5195  for k= 5\n",
      "Quality of clustering 0.5195\n",
      "Clustering done -- CPU time: 15.185890913009644 seconds\n",
      "End Pipeline CPU time: 15.29233193397522 seconds\n",
      "\n",
      "\n",
      "Strategy# 12 : Greedy traversal for starting state AD\n",
      "AD -> KMEANS\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "* For test dataset\n",
      "Metric is not considered for 'AD'.\n",
      "Number of duplicate rows removed: 0\n",
      "Deduplication done -- CPU time: 2.359890937805176 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.8315  for k= 3\n",
      "Quality of clustering 0.8315\n",
      "Clustering done -- CPU time: 15.88570499420166 seconds\n",
      "End Pipeline CPU time: 18.246298789978027 seconds\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.6267  for k= 2\n",
      "Quality of clustering 0.6267\n",
      "Clustering done -- CPU time: 16.502613067626953 seconds\n",
      "End Pipeline CPU time: 16.50264000892639 seconds\n",
      "\n",
      "==== Recap ====\n",
      "\n",
      "List of strategies tried by DoubleLearn2Clean:\n",
      "['DS -> LOF -> AD -> KMEANS', 'MM -> AD -> KMEANS', 'ZS -> IQR -> KMEANS', 'WR -> ZS -> IQR -> KMEANS', 'LC -> LOF -> AD -> KMEANS', 'Tree -> IQR -> KMEANS', 'ZSB -> KMEANS', 'LOF -> AD -> KMEANS', 'IQR -> KMEANS', 'CC -> KMEANS', 'PC -> KMEANS', 'ED -> ZS -> IQR -> KMEANS', 'AD -> KMEANS']\n",
      "\n",
      "List of corresponding quality metrics ****\n",
      " [{'quality_metric': 0.8499, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.857349                0.903060           0\n",
      "1                1.000000                0.553142           0\n",
      "3                0.222222                0.000000           1\n",
      "4                0.222222                0.000000           1\n",
      "5                0.222222                0.000000           1\n",
      "...                   ...                     ...         ...\n",
      "43066            0.222222                0.000000           1\n",
      "43070            0.911111                1.000000           0\n",
      "43072            0.802910                0.794576           0\n",
      "43075            0.222222                0.000000           1\n",
      "43076            0.933333                0.919144           0\n",
      "\n",
      "[16646 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.719660                0.724321         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.819807                0.852755         2   \n",
      "27               0.955556                0.907407         2   \n",
      "...                   ...                     ...       ...   \n",
      "20850            0.388889                0.000000         3   \n",
      "20919            0.962963                0.780488         2   \n",
      "20972            0.111111                0.548125         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "27                                                                                          Healthy Eating  \n",
      "...                                                                                                    ...  \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?  \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4255 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8315, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           1\n",
      "1                1.000000                0.543201           1\n",
      "3                0.388889                0.000000           0\n",
      "4                0.388889                0.000000           0\n",
      "5                0.388889                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43066            0.388889                0.000000           0\n",
      "43070            0.911111                1.000000           1\n",
      "43072            0.805298                0.789116           1\n",
      "43075            0.388889                0.000000           0\n",
      "43076            0.933333                0.916667           1\n",
      "\n",
      "[16676 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.715793                0.735972         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.818172                0.855967         2   \n",
      "27               0.955556                0.907407         2   \n",
      "...                   ...                     ...       ...   \n",
      "20850            0.388889                0.000000         3   \n",
      "20919            0.962963                0.790123         2   \n",
      "20972            0.148148                0.516755         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "27                                                                                          Healthy Eating  \n",
      "...                                                                                                    ...  \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?  \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4285 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.5195, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID  cluster_ID\n",
      "0                1.355292                1.362734 -1.731895           4\n",
      "1                1.907740                0.431451 -1.731687           4\n",
      "3               -0.473548               -0.986005 -1.731480           2\n",
      "4               -0.473548               -0.986005 -1.731272           2\n",
      "5               -0.473548               -0.986005 -1.731064           2\n",
      "...                   ...                     ...       ...         ...\n",
      "43066           -0.473548               -0.986005  1.731064           0\n",
      "43070            1.561371                1.623445  1.731272           1\n",
      "43072            1.149055                1.073153  1.731480           1\n",
      "43075           -0.473548               -0.986005  1.731687           0\n",
      "43076            1.647963                1.405991  1.731895           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID Sentiment  \\\n",
      "10               0.807272                0.918389 -1.731445         2   \n",
      "16396            1.697853                1.250214  0.995864         2   \n",
      "16398            0.191978                0.798182  0.996672         2   \n",
      "16              -0.465994               -0.986172 -1.730636         3   \n",
      "20              -0.465994               -0.986172 -1.729828         3   \n",
      "...                   ...                     ...       ...       ...   \n",
      "16364           -0.465994               -0.986172  0.991822         3   \n",
      "16366            0.777633                0.774141  0.992630         2   \n",
      "16372            1.568022                1.362034  0.993439         2   \n",
      "16377           -0.465994               -0.986172  0.994247         3   \n",
      "16378           -1.616249                1.101122  0.995055         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.5195, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID  cluster_ID\n",
      "0                1.355292                1.362734 -1.731895           3\n",
      "1                1.907740                0.431451 -1.731687           3\n",
      "3               -0.473548               -0.986005 -1.731480           0\n",
      "4               -0.473548               -0.986005 -1.731272           0\n",
      "5               -0.473548               -0.986005 -1.731064           0\n",
      "...                   ...                     ...       ...         ...\n",
      "43066           -0.473548               -0.986005  1.731064           2\n",
      "43070            1.561371                1.623445  1.731272           1\n",
      "43072            1.149055                1.073153  1.731480           1\n",
      "43075           -0.473548               -0.986005  1.731687           2\n",
      "43076            1.647963                1.405991  1.731895           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID\n",
      "10               0.807272                0.918389 -1.731445\n",
      "16396            1.697853                1.250214  0.995864\n",
      "16398            0.191978                0.798182  0.996672\n",
      "16              -0.465994               -0.986172 -1.730636\n",
      "20              -0.465994               -0.986172 -1.729828\n",
      "...                   ...                     ...       ...\n",
      "16364           -0.465994               -0.986172  0.991822\n",
      "16366            0.777633                0.774141  0.992630\n",
      "16372            1.568022                1.362034  0.993439\n",
      "16377           -0.465994               -0.986172  0.994247\n",
      "16378           -1.616249                1.101122  0.995055\n",
      "\n",
      "[4285 rows x 3 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8519, 'result': {'train':        Sentiment_Polarity  cluster_ID\n",
      "0                0.858225           0\n",
      "1                1.000000           0\n",
      "3                0.388889           1\n",
      "8                0.711375           0\n",
      "9                0.388889           1\n",
      "...                   ...         ...\n",
      "43062            0.388889           1\n",
      "43064            0.096731           2\n",
      "43072            0.805298           0\n",
      "43075            0.388889           1\n",
      "43076            0.933333           0\n",
      "\n",
      "[16646 rows x 2 columns], 'test':        Sentiment_Polarity Sentiment  \\\n",
      "10               0.715793         2   \n",
      "16               0.388889         3   \n",
      "20               0.388889         3   \n",
      "29               0.672671         2   \n",
      "30               0.093567         0   \n",
      "...                   ...       ...   \n",
      "20636            0.700573         2   \n",
      "20638            0.792242         2   \n",
      "20972            0.148148         0   \n",
      "20998            0.388889         3   \n",
      "21198            0.388889         3   \n",
      "\n",
      "                                                      App  \\\n",
      "10                                  10 Best Foods for You   \n",
      "16                                  10 Best Foods for You   \n",
      "20                                  10 Best Foods for You   \n",
      "29                                  10 Best Foods for You   \n",
      "30                                  10 Best Foods for You   \n",
      "...                                                   ...   \n",
      "20636  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20638  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20972                      Calendar Widget Month + Agenda   \n",
      "20998                      Calendar+ Schedule Planner App   \n",
      "21198                      Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "29                                                                                             On test....  \n",
      "30                                                                                                 Good.!!  \n",
      "...                                                                                                    ...  \n",
      "20636                                                                                   Robert Martinez Jr  \n",
      "20638                                                          Please add something scan protect browsers.  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4255 rows x 4 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6267, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID Sentiment  \\\n",
      "10               0.715793                0.735972       1         2   \n",
      "16396            0.944444                0.864198    3375         2   \n",
      "16398            0.557819                0.689521    3376         2   \n",
      "16               0.388889                0.000000       2         3   \n",
      "20               0.388889                0.000000       3         3   \n",
      "...                   ...                     ...     ...       ...   \n",
      "16364            0.388889                0.000000    3370         3   \n",
      "16366            0.708183                0.680230    3371         2   \n",
      "16372            0.911111                0.907407    3372         2   \n",
      "16377            0.388889                0.000000    3373         3   \n",
      "16378            0.093567                0.806584    3374         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6261, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "3                0.388889                0.000000       3           1\n",
      "4                0.388889                0.000000       4           1\n",
      "5                0.388889                0.000000       5           1\n",
      "6                0.388889                0.000000       6           1\n",
      "8                0.711375                0.895833       7           1\n",
      "...                   ...                     ...     ...         ...\n",
      "43062            0.388889                0.000000   16669           0\n",
      "43064            0.096731                0.499309   16670           0\n",
      "43065            0.388889                0.000000   16671           0\n",
      "43066            0.388889                0.000000   16672           0\n",
      "43075            0.388889                0.000000   16675           0\n",
      "\n",
      "[12672 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID Sentiment  \\\n",
      "10               0.715793                0.735972       1         2   \n",
      "16398            0.557819                0.689521    3376         2   \n",
      "16               0.388889                0.000000       2         3   \n",
      "20               0.388889                0.000000       3         3   \n",
      "16408            0.388889                0.000000    3378         3   \n",
      "...                   ...                     ...     ...       ...   \n",
      "16356            0.720359                0.879012    3369         2   \n",
      "16364            0.388889                0.000000    3370         3   \n",
      "16366            0.708183                0.680230    3371         2   \n",
      "16377            0.388889                0.000000    3373         3   \n",
      "16378            0.093567                0.806584    3374         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "16408        Bloomberg Professional   \n",
      "...                             ...   \n",
      "16356  Blood Pressure Log - MyDiary   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "16408                                                             Very poor performance Android devices!!!   \n",
      "...                                                                                                    ...   \n",
      "16356                                                       Icons weird, clunky use. Overall good program.   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "16408  3*0.3888888888888889*0.0*BloombergProfessional*VerypoorperformanceAndroiddevices!!!*3378*3*0.388...  \n",
      "...                                                                                                    ...  \n",
      "16356  2*0.7203587164693114*0.8790123456790124*BloodPressureLog-MyDiary*Iconsweird,clunkyuse.Overallgoo...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[3321 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8314, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           1\n",
      "1                1.000000                0.543201           1\n",
      "3                0.388889                0.000000           0\n",
      "4                0.388889                0.000000           0\n",
      "6                0.388889                0.000000           0\n",
      "...                   ...                     ...         ...\n",
      "43064            0.096731                0.499309           2\n",
      "43070            0.911111                1.000000           1\n",
      "43072            0.805298                0.789116           1\n",
      "43075            0.388889                0.000000           0\n",
      "43076            0.933333                0.916667           1\n",
      "\n",
      "[16646 rows x 3 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity Sentiment  \\\n",
      "10               0.715793                0.735972         2   \n",
      "16               0.388889                0.000000         3   \n",
      "20               0.388889                0.000000         3   \n",
      "23               0.818172                0.855967         2   \n",
      "28               0.738622                0.636168         2   \n",
      "...                   ...                     ...       ...   \n",
      "20638            0.792242                0.660352         2   \n",
      "20639            0.911111                1.000000         2   \n",
      "20972            0.148148                0.516755         0   \n",
      "20998            0.388889                0.000000         3   \n",
      "21198            0.388889                0.000000         3   \n",
      "\n",
      "                                                      App  \\\n",
      "10                                  10 Best Foods for You   \n",
      "16                                  10 Best Foods for You   \n",
      "20                                  10 Best Foods for You   \n",
      "23                                  10 Best Foods for You   \n",
      "28                                  10 Best Foods for You   \n",
      "...                                                   ...   \n",
      "20638  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20639  Cache Cleaner-DU Speed Booster (booster & cleaner)   \n",
      "20972                      Calendar Widget Month + Agenda   \n",
      "20998                      Calendar+ Schedule Planner App   \n",
      "21198                      Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "28                                                                                   Very good Simply good  \n",
      "...                                                                                                    ...  \n",
      "20638                                                          Please add something scan protect browsers.  \n",
      "20639                          Good actually works. It enhances net speed great extent. Really useful app.  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4255 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6267, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID Sentiment  \\\n",
      "10               0.715793                0.735972       1         2   \n",
      "16396            0.944444                0.864198    3375         2   \n",
      "16398            0.557819                0.689521    3376         2   \n",
      "16               0.388889                0.000000       2         3   \n",
      "20               0.388889                0.000000       3         3   \n",
      "...                   ...                     ...     ...       ...   \n",
      "16364            0.388889                0.000000    3370         3   \n",
      "16366            0.708183                0.680230    3371         2   \n",
      "16372            0.911111                0.907407    3372         2   \n",
      "16377            0.388889                0.000000    3373         3   \n",
      "16378            0.093567                0.806584    3374         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6267, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           1\n",
      "1                1.000000                0.543201       2           1\n",
      "3                0.388889                0.000000       3           1\n",
      "4                0.388889                0.000000       4           1\n",
      "5                0.388889                0.000000       5           1\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           0\n",
      "43070            0.911111                1.000000   16673           0\n",
      "43072            0.805298                0.789116   16674           0\n",
      "43075            0.388889                0.000000   16675           0\n",
      "43076            0.933333                0.916667   16676           0\n",
      "\n",
      "[16676 rows x 4 columns], 'test':       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "10            2            0.715793                0.735972   \n",
      "16            3            0.388889                0.000000   \n",
      "20            3            0.388889                0.000000   \n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "...         ...                 ...                     ...   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "20972         0            0.148148                0.516755   \n",
      "20998         3            0.388889                0.000000   \n",
      "21198         3            0.388889                0.000000   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.   \n",
      "27                                                                                          Healthy Eating   \n",
      "...                                                                                                    ...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "20972                                My problem I already purchased cannot can't update setting appearance   \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...   \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...   \n",
      "\n",
      "       New_ID  \\\n",
      "10          1   \n",
      "16          2   \n",
      "20          3   \n",
      "23          4   \n",
      "27          5   \n",
      "...       ...   \n",
      "20850    4281   \n",
      "20919    4282   \n",
      "20972    4283   \n",
      "20998    4284   \n",
      "21198    4285   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "23     2*0.8181718971672669*0.8559670781893003*10BestFoodsforYou*HEALTHSHOULDALWAYSBETOPPRIORITY.!!.ONM...  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "...                                                                                                    ...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "20972  0*0.14814814814814814*0.5167548500881834*CalendarWidgetMonth+Agenda*MyproblemIalreadypurchasedca...  \n",
      "20998  3*0.3888888888888889*0.0*Calendar+SchedulePlannerApp*Updated2015:STILapp,stilllovestillhighlyrec...  \n",
      "21198  3*0.3888888888888889*0.0*CallofDuty:BlackOpsZombies*ThisGAMEDOESN'TEVENLAUNCH!!!,everytimeIgopla...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': None, 'result': {'train': Empty DataFrame\n",
      "Columns: [Sentiment, App, Translated_Review, row]\n",
      "Index: [], 'test': Empty DataFrame\n",
      "Columns: [Sentiment, App, Translated_Review, row]\n",
      "Index: [], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.5195, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID  cluster_ID\n",
      "0                1.355292                1.362734 -1.731895           3\n",
      "1                1.907740                0.431451 -1.731687           3\n",
      "3               -0.473548               -0.986005 -1.731480           4\n",
      "4               -0.473548               -0.986005 -1.731272           4\n",
      "5               -0.473548               -0.986005 -1.731064           4\n",
      "...                   ...                     ...       ...         ...\n",
      "43066           -0.473548               -0.986005  1.731064           1\n",
      "43070            1.561371                1.623445  1.731272           0\n",
      "43072            1.149055                1.073153  1.731480           0\n",
      "43075           -0.473548               -0.986005  1.731687           1\n",
      "43076            1.647963                1.405991  1.731895           0\n",
      "\n",
      "[16676 rows x 4 columns], 'test':        Sentiment_Polarity  Sentiment_Subjectivity    New_ID Sentiment  \\\n",
      "10               0.807272                0.918389 -1.731445         2   \n",
      "16396            1.697853                1.250214  0.995864         2   \n",
      "16398            0.191978                0.798182  0.996672         2   \n",
      "16              -0.465994               -0.986172 -1.730636         3   \n",
      "20              -0.465994               -0.986172 -1.729828         3   \n",
      "...                   ...                     ...       ...       ...   \n",
      "16364           -0.465994               -0.986172  0.991822         3   \n",
      "16366            0.777633                0.774141  0.992630         2   \n",
      "16372            1.568022                1.362034  0.993439         2   \n",
      "16377           -0.465994               -0.986172  0.994247         3   \n",
      "16378           -1.616249                1.101122  0.995055         0   \n",
      "\n",
      "                                App  \\\n",
      "10            10 Best Foods for You   \n",
      "16396      Blood Pressure(BP) Diary   \n",
      "16398      Blood Pressure(BP) Diary   \n",
      "16            10 Best Foods for You   \n",
      "20            10 Best Foods for You   \n",
      "...                             ...   \n",
      "16364  Blood Pressure Log - MyDiary   \n",
      "16366  Blood Pressure Log - MyDiary   \n",
      "16372      Blood Pressure(BP) Diary   \n",
      "16377      Blood Pressure(BP) Diary   \n",
      "16378      Blood Pressure(BP) Diary   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16396  I installed year ago integration S-health Damsung Galaxy. It worked well now. The recent auto-up...   \n",
      "16398                      great thank you ...i have omron bp device bp786n bluetooth supported pls update   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "...                                                                                                    ...   \n",
      "16364      Table displaying count percentage category reflect actual data. Developers must adddress issue.   \n",
      "16366  Excellent app, really easy understand. The colour codes make easy see glance, blood pressure doi...   \n",
      "16372                                                      Does blood pressure need access contacts calls?   \n",
      "16377                                                           Connected Facebook account nothing else...   \n",
      "16378  Terms Service Privacy Policy incomprehensible unenforceable. Retaining everyone's personal infor...   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16396  2*0.9444444444444444*0.8641975308641976*BloodPressure(BP)Diary*IinstalledyearagointegrationS-hea...  \n",
      "16398  2*0.5578193403881972*0.689520624303234*BloodPressure(BP)Diary*greatthankyou...ihaveomronbpdevice...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "...                                                                                                    ...  \n",
      "16364  3*0.3888888888888889*0.0*BloodPressureLog-MyDiary*Tabledisplayingcountpercentagecategoryreflecta...  \n",
      "16366  2*0.7081831859036566*0.6802303976217031*BloodPressureLog-MyDiary*Excellentapp,reallyeasyundersta...  \n",
      "16372  2*0.9111111111111111*0.9074074074074074*BloodPressure(BP)Diary*Doesbloodpressureneedaccesscontac...  \n",
      "16377  3*0.3888888888888889*0.0*BloodPressure(BP)Diary*ConnectedFacebookaccountnothingelse...*3373*3*0....  \n",
      "16378  0*0.0935672514619883*0.8065843621399176*BloodPressure(BP)Diary*TermsServicePrivacyPolicyincompre...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.8315, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  cluster_ID\n",
      "0                0.858225                0.900089           2\n",
      "1                1.000000                0.543201           2\n",
      "3                0.388889                0.000000           1\n",
      "4                0.388889                0.000000           1\n",
      "5                0.388889                0.000000           1\n",
      "...                   ...                     ...         ...\n",
      "43066            0.388889                0.000000           1\n",
      "43070            0.911111                1.000000           2\n",
      "43072            0.805298                0.789116           2\n",
      "43075            0.388889                0.000000           1\n",
      "43076            0.933333                0.916667           2\n",
      "\n",
      "[16676 rows x 3 columns], 'test':       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "10            2            0.715793                0.735972   \n",
      "16            3            0.388889                0.000000   \n",
      "20            3            0.388889                0.000000   \n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "...         ...                 ...                     ...   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "20972         0            0.148148                0.516755   \n",
      "20998         3            0.388889                0.000000   \n",
      "21198         3            0.388889                0.000000   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \n",
      "10                                                                                               good you.  \n",
      "16                                                     Health It's important world either life . think? :)  \n",
      "20                                                                                               good nice  \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.  \n",
      "27                                                                                          Healthy Eating  \n",
      "...                                                                                                    ...  \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?  \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...  \n",
      "20972                                My problem I already purchased cannot can't update setting appearance  \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...  \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...  \n",
      "\n",
      "[4285 rows x 5 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, {'quality_metric': 0.6267, 'result': {'train':        Sentiment_Polarity  Sentiment_Subjectivity  New_ID  cluster_ID\n",
      "0                0.858225                0.900089       1           0\n",
      "1                1.000000                0.543201       2           0\n",
      "3                0.388889                0.000000       3           0\n",
      "4                0.388889                0.000000       4           0\n",
      "5                0.388889                0.000000       5           0\n",
      "...                   ...                     ...     ...         ...\n",
      "43066            0.388889                0.000000   16672           1\n",
      "43070            0.911111                1.000000   16673           1\n",
      "43072            0.805298                0.789116   16674           1\n",
      "43075            0.388889                0.000000   16675           1\n",
      "43076            0.933333                0.916667   16676           1\n",
      "\n",
      "[16676 rows x 4 columns], 'test':       Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \\\n",
      "10            2            0.715793                0.735972   \n",
      "16            3            0.388889                0.000000   \n",
      "20            3            0.388889                0.000000   \n",
      "23            2            0.818172                0.855967   \n",
      "27            2            0.955556                0.907407   \n",
      "...         ...                 ...                     ...   \n",
      "20850         3            0.388889                0.000000   \n",
      "20919         2            0.962963                0.790123   \n",
      "20972         0            0.148148                0.516755   \n",
      "20998         3            0.388889                0.000000   \n",
      "21198         3            0.388889                0.000000   \n",
      "\n",
      "                                  App  \\\n",
      "10              10 Best Foods for You   \n",
      "16              10 Best Foods for You   \n",
      "20              10 Best Foods for You   \n",
      "23              10 Best Foods for You   \n",
      "27              10 Best Foods for You   \n",
      "...                               ...   \n",
      "20850     Calculator - unit converter   \n",
      "20919  Calculator with Percent (Free)   \n",
      "20972  Calendar Widget Month + Agenda   \n",
      "20998  Calendar+ Schedule Planner App   \n",
      "21198  Call of Duty:Black Ops Zombies   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.   \n",
      "27                                                                                          Healthy Eating   \n",
      "...                                                                                                    ...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "20972                                My problem I already purchased cannot can't update setting appearance   \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...   \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...   \n",
      "\n",
      "       New_ID  \\\n",
      "10          1   \n",
      "16          2   \n",
      "20          3   \n",
      "23          4   \n",
      "27          5   \n",
      "...       ...   \n",
      "20850    4281   \n",
      "20919    4282   \n",
      "20972    4283   \n",
      "20998    4284   \n",
      "21198    4285   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "23     2*0.8181718971672669*0.8559670781893003*10BestFoodsforYou*HEALTHSHOULDALWAYSBETOPPRIORITY.!!.ONM...  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "...                                                                                                    ...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "20972  0*0.14814814814814814*0.5167548500881834*CalendarWidgetMonth+Agenda*MyproblemIalreadypurchasedca...  \n",
      "20998  3*0.3888888888888889*0.0*Calendar+SchedulePlannerApp*Updated2015:STILapp,stilllovestillhighlyrec...  \n",
      "21198  3*0.3888888888888889*0.0*CallofDuty:BlackOpsZombies*ThisGAMEDOESN'TEVENLAUNCH!!!,everytimeIgopla...  \n",
      "\n",
      "[4285 rows x 7 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}]\n",
      "\n",
      "Strategy LC -> LOF -> AD -> KMEANS for maximal silhouette : 0.8519 for KMEANS\n",
      "\n",
      "=== End of DoubleLearn2Clean - Pipeline execution -- CPU time: 215.64500212669373 seconds\n",
      "\n",
      "**** Best strategy ****\n",
      "('gpsu_example', 'doublelearn2clean', 'KMEANS', 'Sentiment', None, 'LC -> LOF -> AD -> KMEANS', 'silhouette', 0.8519, 215.64500212669373)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import learn2clean.qlearning.qlearner as ql\n",
    "# Learn2clean finds the best strategy 'ZS -> ED -> NB'for maximal accuracy : 0.0.6408668730650154 for NB\n",
    "# in 4.58 seconds\n",
    "# The best strategy is stored in EOF of 'gpsu_example_results.txt' in 'save' directory as\n",
    "# ('gpsu_example', 'learn2clean', 'NB', 'Sentiment', None, 'ZS -> ED -> NB', 'accuracy', 0.6408668730650154, 4.58355188369751)\n",
    "l2c_c1assification1=ql.Qlearner(dataset = gpsu_encoded,goal='KMEANS',target_goal='Sentiment',\n",
    "                                target_prepare=None, file_name = 'gpsu_example', verbose = False)\n",
    "l2c_c1assification1.learn2clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random data preprocessing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " ZS -> ZSB -> CART\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.0259702205657959 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "4004 outlying rows have been removed:\n",
      "* For test dataset\n",
      "964 outlying rows have been removed:\n",
      "Outlier detection and removal done -- CPU time: 0.030617713928222656 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Avg accuracy of CART classification for 10 cross-validation : 0.6388875955771228\n",
      "\n",
      "Classification done -- CPU time: 62.52108907699585 seconds\n",
      "End Pipeline CPU time: 62.57785892486572 seconds\n",
      "('gpsu_example', 'random', 'CART', 'Sentiment', None, 'ZS -> ZSB -> CART', 'accuracy', ({'quality_metric': 0.6388875955771228}, 62.57785892486572))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " MM -> WR -> IQR -> LDA\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.024878263473510742 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n",
      "After feature selection:\n",
      "3 features remain\n",
      "['Sentiment_Polarity', 'Sentiment_Subjectivity', 'New_ID']\n",
      "Feature selection done -- CPU time: 0.01248311996459961 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.023132801055908203 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "\n",
      "Accuracy of LDA result for 10 cross-validation : 0.6405612856800191\n",
      "\n",
      "Classification done -- CPU time: 0.053460121154785156 seconds\n",
      "End Pipeline CPU time: 0.1153879165649414 seconds\n",
      "('gpsu_example', 'random', 'LDA', 'Sentiment', None, 'MM -> WR -> IQR -> LDA', 'accuracy', ({'quality_metric': 0.6405612856800191}, 0.1153879165649414))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " DS -> IQR -> ED -> NB\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.031944990158081055 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "0 outlying rows have been removed\n",
      "* For test dataset\n",
      "0 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.026526927947998047 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.07117009162902832 seconds\n",
      "\n",
      "\n",
      ">>Classification task\n",
      "Accuracy of Naive Naive Bayes classification for 10 cross-validation : 0.6405613121979921\n",
      "\n",
      "Classification done -- CPU time: 0.07953596115112305 seconds\n",
      "End Pipeline CPU time: 0.20951485633850098 seconds\n",
      "('gpsu_example', 'random', 'NB', 'Sentiment', None, 'DS -> IQR -> ED -> NB', 'accuracy', ({'quality_metric': 0.6405613121979921}, 0.20951390266418457))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " MM -> LC -> LOF -> LASSO\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03963589668273926 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.01630401611328125 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.1326899528503418 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "Best alpha =  0.01\n",
      "MSE of LASSO with 10  folds for cross-validation: 0.9793096008674566\n",
      "Regression done -- CPU time: 0.04485583305358887 seconds\n",
      "End Pipeline CPU time: 0.23574519157409668 seconds\n",
      "('gpsu_example', 'random', 'LASSO', 'Sentiment', None, 'MM -> LC -> LOF -> LASSO', 'MSE', ({'quality_metric': 0.9793096008674566}, 0.23574399948120117))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " DS -> LOF -> OLS\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.042485952377319336 seconds\n",
      "\n",
      "\n",
      ">>Outlier detection and removal:\n",
      "* For train dataset\n",
      "30 outlying rows have been removed\n",
      "* For test dataset\n",
      "30 outlying rows have been removed\n",
      "Outlier detection and removal done -- CPU time: 0.29847002029418945 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                     1.380619\n",
       "New_ID                    0.053081\n",
       "Sentiment_Polarity        0.040765\n",
       "Sentiment_Subjectivity   -0.015406\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>New_ID</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719660</td>\n",
       "      <td>0.724321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.819807</td>\n",
       "      <td>0.852755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20919</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.548125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4255 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const    New_ID  Sentiment_Polarity  Sentiment_Subjectivity\n",
       "10       1.0  0.000000            0.719660                0.724321\n",
       "16       1.0  0.000233            0.388889                0.000000\n",
       "20       1.0  0.000467            0.388889                0.000000\n",
       "23       1.0  0.000700            0.819807                0.852755\n",
       "27       1.0  0.000934            0.955556                0.907407\n",
       "...      ...       ...                 ...                     ...\n",
       "20850    1.0  0.999066            0.388889                0.000000\n",
       "20919    1.0  0.999300            0.962963                0.780488\n",
       "20972    1.0  0.999533            0.111111                0.548125\n",
       "20998    1.0  0.999767            0.388889                0.000000\n",
       "21198    1.0  1.000000            0.388889                0.000000\n",
       "\n",
       "[4255 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4255, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4255, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFICATION\n",
      "MSE of OLS with 10  folds for cross-validation: 0.7097222292350561\n",
      "Regression done -- CPU time: 0.02734994888305664 seconds\n",
      "End Pipeline CPU time: 0.3685438632965088 seconds\n",
      "('gpsu_example', 'random', 'OLS', 'Sentiment', None, 'DS -> LOF -> OLS', 'MSE', ({'quality_metric': 0.7097222292350561}, 0.3685438632965088))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " DS -> ED -> MARS\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.03989291191101074 seconds\n",
      "\n",
      "\n",
      ">>Duplicate detection and removal:\n",
      "* For train dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 16676\n",
      "After deduplication: Number of rows: 16676\n",
      "* For test dataset\n",
      "Metric is not considered for 'ED'.\n",
      "Initial number of rows: 4285\n",
      "After deduplication: Number of rows: 4285\n",
      "Deduplication done -- CPU time: 0.0705101490020752 seconds\n",
      "\n",
      "\n",
      ">>Regression task\n",
      "MSE of MARS with 10 folds for cross-validation: 0.5695313510821147\n",
      "Regression done -- CPU time: 2.417901039123535 seconds\n",
      "End Pipeline CPU time: 2.528506278991699 seconds\n",
      "('gpsu_example', 'random', 'MARS', 'Sentiment', None, 'DS -> ED -> MARS', 'MSE', ({'quality_metric': 0.5695313510821147}, 2.528506278991699))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " MM -> LC -> HCA\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.030756235122680664 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply LC feature selection with threshold= 0.3\n",
      "1 features with linear correlation greater than 0.30.\n",
      "\n",
      "List of correlated variables to be removed : ['Sentiment_Subjectivity']\n",
      "After feature selection:\n",
      "6 features remain\n",
      "['Sentiment', 'App', 'New_ID', 'Translated_Review', 'Sentiment_Polarity', 'row']\n",
      "Feature selection done -- CPU time: 0.01547098159790039 seconds\n",
      "\n",
      "\n",
      ">>Clustering task\n",
      "Note: The clustering is applied on the training dataset only.\n",
      "Best silhouette = 0.4272  for k= 4\n",
      "Quality of clustering 0.4272\n",
      "Clustering done -- CPU time: 36.72931718826294 seconds\n",
      "End Pipeline CPU time: 36.77855610847473 seconds\n",
      "('gpsu_example', 'random', 'HCA', 'Sentiment', None, 'MM -> LC -> HCA', 'silhouette', ({'quality_metric': 0.4272, 'result': {'train':        Sentiment_Polarity   New_ID  cluster_ID\n",
      "0                0.858225  0.00000           3\n",
      "1                1.000000  0.00006           3\n",
      "3                0.388889  0.00012           0\n",
      "4                0.388889  0.00018           0\n",
      "5                0.388889  0.00024           0\n",
      "...                   ...      ...         ...\n",
      "43066            0.388889  0.99976           1\n",
      "43070            0.911111  0.99982           2\n",
      "43072            0.805298  0.99988           2\n",
      "43075            0.388889  0.99994           1\n",
      "43076            0.933333  1.00000           2\n",
      "\n",
      "[16676 rows x 3 columns], 'test':       Sentiment                             App    New_ID  \\\n",
      "10            2           10 Best Foods for You  0.000000   \n",
      "16            3           10 Best Foods for You  0.000233   \n",
      "20            3           10 Best Foods for You  0.000467   \n",
      "23            2           10 Best Foods for You  0.000700   \n",
      "27            2           10 Best Foods for You  0.000934   \n",
      "...         ...                             ...       ...   \n",
      "20850         3     Calculator - unit converter  0.999066   \n",
      "20919         2  Calculator with Percent (Free)  0.999300   \n",
      "20972         0  Calendar Widget Month + Agenda  0.999533   \n",
      "20998         3  Calendar+ Schedule Planner App  0.999767   \n",
      "21198         3  Call of Duty:Black Ops Zombies  1.000000   \n",
      "\n",
      "                                                                                         Translated_Review  \\\n",
      "10                                                                                               good you.   \n",
      "16                                                     Health It's important world either life . think? :)   \n",
      "20                                                                                               good nice   \n",
      "23                                                     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON MYSG5.   \n",
      "27                                                                                          Healthy Eating   \n",
      "...                                                                                                    ...   \n",
      "20850      Its great calculator India India different number system , usually comma two digit , help that?   \n",
      "20919  Really nice app. Does least basics probably lot I'm mathematician I fairly basic calculations. E...   \n",
      "20972                                My problem I already purchased cannot can't update setting appearance   \n",
      "20998  Updated 2015: STIL app, still love still highly recommend! *** I've short time, impressed enough...   \n",
      "21198  This GAME DOESN'T EVEN LAUNCH!!! , every time I go play it, goes black home screen says \"restart...   \n",
      "\n",
      "       Sentiment_Polarity  \\\n",
      "10               0.715793   \n",
      "16               0.388889   \n",
      "20               0.388889   \n",
      "23               0.818172   \n",
      "27               0.955556   \n",
      "...                   ...   \n",
      "20850            0.388889   \n",
      "20919            0.962963   \n",
      "20972            0.148148   \n",
      "20998            0.388889   \n",
      "21198            0.388889   \n",
      "\n",
      "                                                                                                       row  \n",
      "10     2*0.7157928925071908*0.7359717577108886*10BestFoodsforYou*goodyou.*1*2*0.7157928925071908*0.7359...  \n",
      "16     3*0.3888888888888889*0.0*10BestFoodsforYou*HealthIt'simportantworldeitherlife.think?:)*2*3*0.388...  \n",
      "20     3*0.3888888888888889*0.0*10BestFoodsforYou*goodnice*3*3*0.3888888888888889*0.0*10BestFoodsforYou...  \n",
      "23     2*0.8181718971672669*0.8559670781893003*10BestFoodsforYou*HEALTHSHOULDALWAYSBETOPPRIORITY.!!.ONM...  \n",
      "27     2*0.9555555555555555*0.9074074074074074*10BestFoodsforYou*HealthyEating*5*2*0.9555555555555555*0...  \n",
      "...                                                                                                    ...  \n",
      "20850  3*0.3888888888888889*0.0*Calculator-unitconverter*ItsgreatcalculatorIndiaIndiadifferentnumbersys...  \n",
      "20919  2*0.9629629629629629*0.7901234567901233*CalculatorwithPercent(Free)*Reallyniceapp.Doesleastbasic...  \n",
      "20972  0*0.14814814814814814*0.5167548500881834*CalendarWidgetMonth+Agenda*MyproblemIalreadypurchasedca...  \n",
      "20998  3*0.3888888888888889*0.0*Calendar+SchedulePlannerApp*Updated2015:STILapp,stilllovestillhighlyrec...  \n",
      "21198  3*0.3888888888888889*0.0*CallofDuty:BlackOpsZombies*ThisGAMEDOESN'TEVENLAUNCH!!!,everytimeIgopla...  \n",
      "\n",
      "[4285 rows x 6 columns], 'target': 38994    2\n",
      "9471     2\n",
      "337      2\n",
      "4440     3\n",
      "58427    3\n",
      "        ..\n",
      "23481    2\n",
      "57480    2\n",
      "50772    3\n",
      "24323    3\n",
      "30683    2\n",
      "Name: Sentiment, Length: 43077, dtype: int64, 'target_test': 2938     0\n",
      "50753    2\n",
      "14977    3\n",
      "51035    2\n",
      "15878    3\n",
      "        ..\n",
      "55777    2\n",
      "16239    1\n",
      "4305     3\n",
      "55518    3\n",
      "32218    2\n",
      "Name: Sentiment, Length: 21218, dtype: int64}}, 36.77855610847473))\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Random cleaning strategy:\n",
      " ZS -> WR -> ZSB -> KMEANS\n",
      "--------------------------\n",
      "\n",
      "Start pipeline\n",
      "-------------\n",
      ">>Normalization \n",
      "* For train dataset\n",
      "... train dataset\n",
      "* For test dataset\n",
      "... test dataset\n",
      "Normalization done -- CPU time: 0.02167510986328125 seconds\n",
      "\n",
      "\n",
      ">>Feature selection \n",
      "Before feature selection:\n",
      "7 features \n",
      "Apply WR feature selection\n",
      "Input variables must be non-negative. WR feature selection is only applied to positive variables.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e3df9a09c73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mrandom8\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQlearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpsu_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KMEANS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_goal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_prepare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mrandom8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpsu_example'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# gpsu_encoded['train']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/l2cbatates/lib/python3.6/site-packages/learn2clean/qlearning/qlearner.py\u001b[0m in \u001b[0;36mrandom_cleaning\u001b[0;34m(self, dataset_name)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# print(\"New list\", new_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         p = self.pipeline(self.dataset, new_list, self.target_goal,\n\u001b[0;32m--> 840\u001b[0;31m                           self.target_prepare, check_missing)\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         rr = (dataset_name, \"random\", goals[g], self.target_goal,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/l2cbatates/lib/python3.6/site-packages/learn2clean/qlearning/qlearner.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(self, dataset, actions_list, target_goal, target_prepare, check_missing)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     n = L2C_class[a](dataset=dataset, strategy=actions_name[a],\n\u001b[1;32m    329\u001b[0m                                      \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_prepare\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                                      verbose=self.verbose).transform()\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/l2cbatates/lib/python3.6/site-packages/learn2clean/feature_selection/feature_selector.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"WR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0mdn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFS_WR_identify_best_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SVC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/l2cbatates/lib/python3.6/site-packages/learn2clean/feature_selection/feature_selector.py\u001b[0m in \u001b[0;36mFS_WR_identify_best_subset\u001b[0;34m(self, df_train, df_target, k)\u001b[0m\n\u001b[1;32m    269\u001b[0m                       \"positive variables.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 Best_Flist = X.columns[selector.get_support(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/l2cbatates/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/l2cbatates/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "import learn2clean.loading.reader as rd \n",
    "import learn2clean.qlearning.qlearner as ql\n",
    "\n",
    "# d_enc = rd.Reader(sep=',',verbose=False, encoding=True) \n",
    "# gpsu  = [\"../datasets/googleplaystore_reviews.csv\"]\n",
    "# gpsu_encoded = d_enc.train_test_split(gpsu, 'Sentiment')\n",
    "\n",
    "# the results of random cleaning are stored in 'gpsu_example'_results_file.txt in 'save' directory\n",
    "# appended to the EOF \n",
    "# random pipeline for LDA classification\n",
    "random1=ql.Qlearner(gpsu_encoded.copy(),goal='CART',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random1.random_cleaning('gpsu_example')\n",
    "\n",
    "random2=ql.Qlearner(gpsu_encoded.copy(),goal='LDA',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random2.random_cleaning('gpsu_example')\n",
    "\n",
    "random3=ql.Qlearner(gpsu_encoded.copy(),goal='NB',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random3.random_cleaning('gpsu_example')\n",
    "\n",
    "random4=ql.Qlearner(gpsu_encoded.copy(),goal='LASSO',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random4.random_cleaning('gpsu_example')\n",
    "\n",
    "random5=ql.Qlearner(gpsu_encoded.copy(),goal='OLS',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random5.random_cleaning('gpsu_example')\n",
    "\n",
    "random6=ql.Qlearner(gpsu_encoded.copy(),goal='MARS',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random6.random_cleaning('gpsu_example')\n",
    "\n",
    "random7=ql.Qlearner(gpsu_encoded.copy(),goal='HCA',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random7.random_cleaning('gpsu_example')\n",
    "\n",
    "random8=ql.Qlearner(gpsu_encoded.copy(),goal='KMEANS',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "random8.random_cleaning('gpsu_example')\n",
    "# gpsu_encoded['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no preprocessing: results appended to the EOF 'gpsu_example'_results.txt \n",
    "\n",
    "no_prep1=ql.Qlearner(gpsu_encoded.copy(),goal='HCA',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "no_prep1.no_prep('gpsu_example')\n",
    "\n",
    "no_prep2=ql.Qlearner(gpsu_encoded.copy(),goal='LDA',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "no_prep2.no_prep('gpsu_example')\n",
    "\n",
    "no_prep3=ql.Qlearner(gpsu_encoded.copy(),goal='NB',target_goal='Sentiment',target_prepare=None, verbose = False)\n",
    "no_prep3.no_prep('gpsu_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
